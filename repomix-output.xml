This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/
  settings.local.json
alembic/
  versions/
    .gitkeep
  env.py
  README
  script.py.mako
app/
  api/
    endpoints/
      __init__.py
      chat.py
      documents.py
      health.py
      news.py
    __init__.py
    deps.py
  core/
    __init__.py
    config.py
    embedding_client.py
    llm_client.py
    security.py
  crud/
    __init__.py
    chat_crud.py
  db/
    __init__.py
    session.py
  models/
    __init__.py
    base.py
    chat_history.py
    financial_doc.py
    news_article.py
    news.py
    portfolio_company.py
    user.py
  schemas/
    __init__.py
    chat_schemas.py
    document_schemas.py
    news_schemas.py
  services/
    __init__.py
    chat_service.py
    claude_service.py
    document_service.py
    news_service.py
    pdf_processor.py
    rag_pipeline.py
  __init__.py
  main.py
data/
  cache/
    .gitkeep
  financial_docs/
    .gitkeep
  news_attachments/
    .gitkeep
  UPLOAD_GUIDE.md
frontend/
  public/
    vite.svg
  src/
    assets/
      react.svg
    components/
      chat/
        ChatWindow.tsx
        MessageBubble.tsx
        MessageInput.tsx
        MessageList.tsx
      common/
        ErrorAlert.tsx
        Header.tsx
        LoadingSpinner.tsx
    contexts/
      ChatContext.tsx
    pages/
      ChatPage.tsx
      HomePage.tsx
      TestPage.tsx
    services/
      api.ts
    types/
      index.ts
    App.tsx
    index.css
    main.tsx
    vite-env.d.ts
  .env.example
  .gitignore
  eslint.config.js
  index.html
  package.json
  postcss.config.cjs
  postcss.config.mjs
  README.md
  tailwind.config.js
  tsconfig.app.json
  tsconfig.json
  tsconfig.node.json
  vite.config.ts
init-db/
  01_create_schema.sql
nginx/
  conf.d/
    default.conf
  nginx.conf
scripts/
  create_dummy_pdfs.py
  create_test_files.py
  import_news.py
  index_documents.py
  init_database.py
  init_db.py
  organize_documents.py
  populate_test_data.py
  setup_file_system.py
  setup_sample_files.py
  test_claude_api.py
  update_document_type.py
vooster-docs/
  architecture.md
  clean-code.md
  git-commit-message.md
  guideline.md
  prd.md
  step-by-step.md
.env.example
.gitignore
alembic.ini
BACKEND_FRONTEND_DEBUG_SUMMARY.md
CLAUDE.md
docker-compose.yml
Dockerfile
README.md
requirements.txt
run_backend.py
start_backend_8081.sh
start_backend.sh
test_backend_connection.py
test_chat_service.py
test_claude_direct.py
test_env_loading.py
test_fastapi_direct.py
test_server.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "Bash(npx @vooster/cli@latest tasks:download:*)",
      "Bash(ls:*)",
      "Bash(source:*)",
      "Bash(pip install:*)",
      "Bash(alembic init:*)",
      "Bash(mkdir:*)",
      "Bash(tree:*)"
    ],
    "deny": []
  }
}
</file>

<file path="alembic/versions/.gitkeep">
# This file ensures the directory is tracked by git
</file>

<file path="alembic/env.py">
from logging.config import fileConfig
import sys
from pathlib import Path

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

# Add the project root to Python path
sys.path.append(str(Path(__file__).parent.parent))

from app.models.base import Base
from app.models.user import User
from app.models.financial_doc import FinancialDoc
from app.models.news import News
from app.models.chat_history import ChatHistory

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
target_metadata = Base.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
</file>

<file path="alembic/README">
Generic single-database configuration.
</file>

<file path="alembic/script.py.mako">
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, Sequence[str], None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    """Upgrade schema."""
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    """Downgrade schema."""
    ${downgrades if downgrades else "pass"}
</file>

<file path="app/api/endpoints/__init__.py">
# API endpoint modules
</file>

<file path="app/api/endpoints/chat.py">
"""
Chat endpoints for Q&A functionality
"""

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from loguru import logger

from app.db.session import get_db
from app.schemas.chat_schemas import ChatRequest, ChatResponse
from app.services.chat_service import ChatService
from app.api.deps import get_chat_service

router = APIRouter()


@router.post("/", response_model=ChatResponse)
async def create_chat_completion(
    request: ChatRequest,
    chat_service: ChatService = Depends(get_chat_service),
    db: Session = Depends(get_db)
):
    """
    Process a user question and return an AI-generated response
    """
    try:
        logger.info(f"Received chat request: {request.question}")
        response = await chat_service.process_query(
            question=request.question,
            context=request.context
        )
        logger.info("Chat response generated successfully")
        return response
    except Exception as e:
        logger.error(f"Error in create_chat_completion: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing query: {str(e)}"
        )


@router.get("/history")
async def get_chat_history(
    limit: int = 50,
    offset: int = 0,
    db: Session = Depends(get_db)
):
    """
    Get chat history (placeholder for now - requires authentication)
    """
    # TODO: Implement after authentication is set up
    return {
        "message": "Chat history endpoint - requires authentication",
        "limit": limit,
        "offset": offset
    }
</file>

<file path="app/api/endpoints/documents.py">
"""
Document management endpoints
"""

from typing import Optional, List
from fastapi import APIRouter, Depends, Query, HTTPException, status
from sqlalchemy.orm import Session

from app.db.session import get_db
from app.schemas.document_schemas import DocumentResponse, DocumentSearchQuery
from app.services.document_service import DocumentService
from app.api.deps import get_document_service

router = APIRouter()


@router.get("/search", response_model=List[DocumentResponse])
async def search_documents(
    company: str = Query(..., description="Company name to search for"),
    year: Optional[int] = Query(None, description="Year of the document"),
    doc_type: Optional[str] = Query(None, description="Document type (사업보고서, 반기보고서, 분기보고서)"),
    limit: int = Query(10, ge=1, le=100),
    document_service: DocumentService = Depends(get_document_service),
    db: Session = Depends(get_db)
):
    """
    Search for financial documents by company, year, and type
    """
    try:
        documents = document_service.search_documents(
            company_name=company,
            year=year,
            doc_type=doc_type,
            limit=limit,
            db=db
        )
        return documents
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error searching documents: {str(e)}"
        )


@router.get("/{document_id}", response_model=DocumentResponse)
async def get_document(
    document_id: int,
    document_service: DocumentService = Depends(get_document_service),
    db: Session = Depends(get_db)
):
    """
    Get a specific document by ID
    """
    document = document_service.get_document_by_id(document_id, db)
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Document with ID {document_id} not found"
        )
    return document


@router.post("/index")
async def index_documents(
    directory_path: str,
    document_service: DocumentService = Depends(get_document_service),
    db: Session = Depends(get_db)
):
    """
    Index documents from a directory (admin function)
    """
    # TODO: Add authentication/authorization
    try:
        result = document_service.index_documents_from_directory(directory_path, db)
        return result
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error indexing documents: {str(e)}"
        )
</file>

<file path="app/api/endpoints/health.py">
"""
Health check endpoints
"""

from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from sqlalchemy import text

from app.db.session import get_db
from app.core.config import settings

router = APIRouter()


@router.get("/health")
async def health_check():
    """Basic health check"""
    return {"status": "healthy", "service": settings.APP_NAME, "version": settings.APP_VERSION}


@router.get("/health/detailed")
async def detailed_health_check(db: Session = Depends(get_db)):
    """Detailed health check including all dependencies"""
    health_status = {
        "status": "healthy",
        "service": settings.APP_NAME,
        "version": settings.APP_VERSION,
        "dependencies": {}
    }
    
    # Check SQLite
    try:
        result = db.execute(text("SELECT 1"))
        result.fetchone()
        health_status["dependencies"]["sqlite"] = {"status": "healthy"}
    except Exception as e:
        health_status["dependencies"]["sqlite"] = {"status": "unhealthy", "error": str(e)}
        health_status["status"] = "degraded"
    
    # Check Claude API (just verify key exists)
    if settings.CLAUDE_API_KEY:
        health_status["dependencies"]["claude_api"] = {"status": "healthy", "configured": True}
    else:
        health_status["dependencies"]["claude_api"] = {"status": "unhealthy", "configured": False}
        health_status["status"] = "degraded"
    
    return health_status
</file>

<file path="app/api/endpoints/news.py">
"""
News search endpoints
"""

from typing import Optional, List
from datetime import datetime, date
from fastapi import APIRouter, Depends, Query, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession

from app.db.session import get_db
from app.schemas.news_schemas import NewsResponse, NewsSearchQuery
from app.services.news_service import NewsService
from app.api.deps import get_news_service

router = APIRouter()


@router.get("/search", response_model=List[NewsResponse])
async def search_news(
    company: str = Query(..., description="Company name to search for"),
    keyword: Optional[str] = Query(None, description="Additional keyword to filter"),
    from_date: Optional[date] = Query(None, description="Start date for search"),
    to_date: Optional[date] = Query(None, description="End date for search"),
    limit: int = Query(20, ge=1, le=100),
    news_service: NewsService = Depends(get_news_service),
    db: AsyncSession = Depends(get_db)
):
    """
    Search for news articles by company and optional filters
    """
    try:
        news_items = await news_service.search_news(
            company_name=company,
            keyword=keyword,
            from_date=from_date,
            to_date=to_date,
            limit=limit,
            db=db
        )
        return news_items
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error searching news: {str(e)}"
        )


@router.get("/{news_id}", response_model=NewsResponse)
async def get_news_article(
    news_id: int,
    news_service: NewsService = Depends(get_news_service),
    db: AsyncSession = Depends(get_db)
):
    """
    Get a specific news article by ID
    """
    article = await news_service.get_news_by_id(news_id, db)
    if not article:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"News article with ID {news_id} not found"
        )
    return article


@router.post("/index")
async def index_news(
    source_file: str,
    news_service: NewsService = Depends(get_news_service),
    db: AsyncSession = Depends(get_db)
):
    """
    Index news from a source file (admin function)
    """
    # TODO: Add authentication/authorization
    try:
        result = await news_service.index_news_from_file(source_file, db)
        return result
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error indexing news: {str(e)}"
        )
</file>

<file path="app/api/__init__.py">
# API routers and endpoints
</file>

<file path="app/api/deps.py">
"""
API Dependencies for dependency injection
"""

from typing import Generator
from sqlalchemy.orm import Session
from fastapi import Depends

from app.db.session import get_db
from app.services.chat_service import ChatService
from app.services.document_service import DocumentService
from app.services.claude_service import ClaudeService
from app.services.pdf_processor import PDFProcessor


# Services
def get_chat_service(
    db: Session = Depends(get_db)
) -> ChatService:
    """Get chat service instance"""
    return ChatService(db=db)


def get_document_service(
    db: Session = Depends(get_db)
) -> DocumentService:
    """Get document service instance"""
    return DocumentService(db=db)


def get_claude_service() -> ClaudeService:
    """Get Claude service instance"""
    return ClaudeService()


def get_pdf_processor() -> PDFProcessor:
    """Get PDF processor instance"""
    return PDFProcessor()
</file>

<file path="app/core/__init__.py">
# Core utilities and configurations
</file>

<file path="app/core/config.py">
"""
Application configuration using Pydantic Settings
"""

from typing import Optional
from pydantic_settings import BaseSettings, SettingsConfigDict
from functools import lru_cache


class Settings(BaseSettings):
    # Application
    APP_NAME: str = "Investment Portfolio Q&A Chatbot"
    APP_VERSION: str = "0.1.0"
    DEBUG: bool = False
    ENVIRONMENT: str = "development"
    
    # Database
    DATABASE_URL: str
    
    # Redis
    REDIS_URL: str
    
    # ChromaDB
    CHROMADB_URL: str
    
    # Claude API
    CLAUDE_API_KEY: str
    CLAUDE_TEST_MODE: Optional[str] = None
    
    # Security
    SECRET_KEY: str
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    
    # API Rate Limiting
    DAILY_COST_LIMIT: float = 3500.0  # KRW
    
    # File Storage
    DATA_PATH: str = "/data"
    FINANCIAL_DOCS_PATH: str = "/data/financial_docs"
    CACHE_PATH: str = "/data/cache"
    
    # Logging
    LOG_LEVEL: str = "INFO"
    
    # Claude Model Configuration
    CLAUDE_MODEL_SIMPLE: str = "claude-3-haiku-20240307"
    CLAUDE_MODEL_STANDARD: str = "claude-3-sonnet-20240229"
    CLAUDE_MODEL_ADVANCED: str = "claude-3-opus-20240229"
    
    # Embedding Model
    EMBEDDING_MODEL: str = "jhgan/ko-sroberta-multitask"
    
    # Vector DB Settings
    CHROMA_COLLECTION_NAME: str = "portfolio_documents"
    CHUNK_SIZE: int = 1000
    CHUNK_OVERLAP: int = 200
    
    # Cache Settings
    CACHE_TTL: int = 3600  # 1 hour
    
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=True
    )


@lru_cache()
def get_settings() -> Settings:
    """Get cached settings instance"""
    return Settings()


settings = get_settings()
</file>

<file path="app/core/embedding_client.py">
"""
Embedding client for text vectorization
"""

from typing import List, Union
import numpy as np
from sentence_transformers import SentenceTransformer
from loguru import logger

from app.core.config import settings


class EmbeddingClient:
    """Client for generating text embeddings"""
    
    def __init__(self):
        """Initialize the embedding model"""
        logger.info(f"Loading embedding model: {settings.EMBEDDING_MODEL}")
        self.model = SentenceTransformer(settings.EMBEDDING_MODEL)
        self.embedding_dim = self.model.get_sentence_embedding_dimension()
        logger.info(f"Embedding model loaded. Dimension: {self.embedding_dim}")
    
    async def embed_text(self, text: Union[str, List[str]]) -> Union[List[float], List[List[float]]]:
        """
        Generate embeddings for text
        
        Args:
            text: Single text string or list of texts
        
        Returns:
            Embedding vector(s) as list(s) of floats
        """
        try:
            if isinstance(text, str):
                # Single text
                embedding = self.model.encode(text, convert_to_numpy=True)
                return embedding.tolist()
            else:
                # Multiple texts
                embeddings = self.model.encode(text, convert_to_numpy=True)
                return embeddings.tolist()
                
        except Exception as e:
            logger.error(f"Error generating embeddings: {str(e)}")
            raise
    
    async def embed_documents(self, documents: List[str], batch_size: int = 32) -> List[List[float]]:
        """
        Generate embeddings for multiple documents with batching
        
        Args:
            documents: List of document texts
            batch_size: Batch size for processing
        
        Returns:
            List of embedding vectors
        """
        all_embeddings = []
        
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            logger.info(f"Processing embedding batch {i//batch_size + 1}/{(len(documents) + batch_size - 1)//batch_size}")
            
            batch_embeddings = await self.embed_text(batch)
            all_embeddings.extend(batch_embeddings)
        
        return all_embeddings
    
    def chunk_text(self, text: str, chunk_size: int = None, chunk_overlap: int = None) -> List[str]:
        """
        Split text into chunks for embedding
        
        Args:
            text: Text to chunk
            chunk_size: Size of each chunk (default from settings)
            chunk_overlap: Overlap between chunks (default from settings)
        
        Returns:
            List of text chunks
        """
        chunk_size = chunk_size or settings.CHUNK_SIZE
        chunk_overlap = chunk_overlap or settings.CHUNK_OVERLAP
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            chunk = text[start:end]
            
            # Try to find a good breaking point (end of sentence)
            if end < len(text):
                last_period = chunk.rfind('.')
                last_newline = chunk.rfind('\n')
                break_point = max(last_period, last_newline)
                
                if break_point > chunk_size * 0.8:  # Only break if we're past 80% of chunk
                    chunk = chunk[:break_point + 1]
                    end = start + break_point + 1
            
            chunks.append(chunk.strip())
            start = end - chunk_overlap
        
        return chunks
    
    async def similarity_score(self, embedding1: List[float], embedding2: List[float]) -> float:
        """
        Calculate cosine similarity between two embeddings
        
        Args:
            embedding1: First embedding vector
            embedding2: Second embedding vector
        
        Returns:
            Similarity score between 0 and 1
        """
        vec1 = np.array(embedding1)
        vec2 = np.array(embedding2)
        
        cosine_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
        
        # Convert to 0-1 range
        return float((cosine_sim + 1) / 2)
</file>

<file path="app/core/llm_client.py">
"""
LLM Client for Claude API integration
"""

from typing import Optional, Dict, Any
import anthropic
from loguru import logger

from app.core.config import settings


class LLMClient:
    """Client for interacting with Claude API"""
    
    def __init__(self):
        self.client = anthropic.Anthropic(api_key=settings.CLAUDE_API_KEY)
        self.model_routing = {
            "simple": settings.CLAUDE_MODEL_SIMPLE,
            "standard": settings.CLAUDE_MODEL_STANDARD,
            "advanced": settings.CLAUDE_MODEL_ADVANCED
        }
    
    def select_model(self, question_type: str, complexity: float = 0.5) -> str:
        """
        Select appropriate Claude model based on question type and complexity
        
        Args:
            question_type: Type of question (simple_lookup, analysis, complex)
            complexity: Complexity score from 0 to 1
        
        Returns:
            Model name to use
        """
        if question_type == "simple_lookup":
            return self.model_routing["simple"]
        elif complexity > 0.7 or question_type == "complex_analysis":
            return self.model_routing["advanced"]
        else:
            return self.model_routing["standard"]
    
    async def generate_text(
        self,
        prompt: str,
        question_type: str = "standard",
        max_tokens: int = 1000,
        temperature: float = 0.7,
        **kwargs
    ) -> str:
        """
        Generate text using Claude API
        
        Args:
            prompt: The prompt to send to Claude
            question_type: Type of question for model selection
            max_tokens: Maximum tokens in response
            temperature: Temperature for generation
            **kwargs: Additional parameters for the API
        
        Returns:
            Generated text response
        """
        model = self.select_model(question_type)
        
        try:
            logger.info(f"Calling Claude API with model: {model}")
            
            message = self.client.messages.create(
                model=model,
                max_tokens=max_tokens,
                temperature=temperature,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                **kwargs
            )
            
            response_text = message.content[0].text
            logger.info(f"Successfully generated response with {len(response_text)} characters")
            
            return response_text
            
        except Exception as e:
            logger.error(f"Error calling Claude API: {str(e)}")
            raise
    
    async def analyze_document(
        self,
        document_content: str,
        question: str,
        doc_type: str = "financial_report"
    ) -> Dict[str, Any]:
        """
        Analyze a document with a specific question
        
        Args:
            document_content: Content of the document
            question: Question about the document
            doc_type: Type of document
        
        Returns:
            Analysis result with answer and extracted data
        """
        prompt = self._build_document_analysis_prompt(document_content, question, doc_type)
        
        response = await self.generate_text(
            prompt=prompt,
            question_type="complex_analysis",
            temperature=0.3  # Lower temperature for factual analysis
        )
        
        return {
            "answer": response,
            "doc_type": doc_type,
            "question": question
        }
    
    def _build_document_analysis_prompt(
        self,
        document_content: str,
        question: str,
        doc_type: str
    ) -> str:
        """Build prompt for document analysis"""
        
        if doc_type == "financial_report":
            return f"""You are an expert financial analyst helping an investment team.
            
Analyze the following financial document and answer the user's question.
Provide specific numbers and page references when available.
If the answer is not in the document, clearly state that.

Document:
{document_content}

User Question: {question}

Please provide a clear, concise answer with specific data points and sources."""
        
        else:
            return f"""You are an intelligent assistant analyzing documents.
            
Based on the following document, answer the user's question.
Be specific and cite relevant parts of the document.

Document:
{document_content}

User Question: {question}"""
</file>

<file path="app/core/security.py">
"""
Security utilities for authentication and authorization
"""

from datetime import datetime, timedelta
from typing import Optional, Dict, Any

from jose import JWTError, jwt
from passlib.context import CryptContext
from fastapi import HTTPException, status, Depends
from fastapi.security import OAuth2PasswordBearer

from app.core.config import settings

# Password hashing
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# OAuth2 scheme
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/auth/login")


def verify_password(plain_password: str, hashed_password: str) -> bool:
    """Verify a password against its hash"""
    return pwd_context.verify(plain_password, hashed_password)


def get_password_hash(password: str) -> str:
    """Hash a password"""
    return pwd_context.hash(password)


def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """Create a JWT access token"""
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    
    return encoded_jwt


def decode_access_token(token: str) -> Dict[str, Any]:
    """Decode and validate a JWT access token"""
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        return payload
    except JWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )


async def get_current_user(token: str = Depends(oauth2_scheme)) -> Dict[str, Any]:
    """Get current user from JWT token"""
    payload = decode_access_token(token)
    email: str = payload.get("sub")
    
    if email is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    return {"email": email, "user_id": payload.get("user_id")}
</file>

<file path="app/crud/__init__.py">
# CRUD operations for database models
</file>

<file path="app/crud/chat_crud.py">
"""
CRUD operations for chat history
"""

from typing import Optional, List, Dict, Any
from sqlalchemy import select, desc
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.chat_history import ChatHistory


class ChatCRUD:
    """CRUD operations for chat history"""
    
    async def create_chat_history(
        self,
        db: AsyncSession,
        user_id: Optional[int],
        question: str,
        answer: str,
        context: Dict[str, Any]
    ) -> ChatHistory:
        """Create a new chat history entry"""
        chat_entry = ChatHistory(
            user_id=user_id,
            question=question,
            answer=answer,
            context=context
        )
        
        db.add(chat_entry)
        await db.commit()
        await db.refresh(chat_entry)
        
        return chat_entry
    
    async def get_chat_history(
        self,
        db: AsyncSession,
        user_id: Optional[int] = None,
        limit: int = 50,
        offset: int = 0
    ) -> List[ChatHistory]:
        """Get chat history with optional user filter"""
        query = select(ChatHistory)
        
        if user_id:
            query = query.where(ChatHistory.user_id == user_id)
        
        query = query.order_by(desc(ChatHistory.created_at)).limit(limit).offset(offset)
        
        result = await db.execute(query)
        return result.scalars().all()
    
    async def get_chat_by_id(
        self,
        db: AsyncSession,
        chat_id: int
    ) -> Optional[ChatHistory]:
        """Get a specific chat entry by ID"""
        result = await db.execute(
            select(ChatHistory).where(ChatHistory.id == chat_id)
        )
        return result.scalar_one_or_none()
</file>

<file path="app/db/__init__.py">
# Database connection and session management
</file>

<file path="app/db/session.py">
"""
Database session management
"""

from typing import Generator

from sqlalchemy import create_engine
from sqlalchemy.orm import declarative_base, sessionmaker

from app.core.config import settings

# Create synchronous engine for SQLite
engine = create_engine(
    settings.DATABASE_URL,
    echo=settings.DEBUG,
    connect_args={"check_same_thread": False}  # Needed for SQLite
)

# Create session factory
SessionLocal = sessionmaker(
    bind=engine,
    autocommit=False,
    autoflush=False,
)

# Create base class for models
Base = declarative_base()


def get_db() -> Generator:
    """Dependency to get database session"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
</file>

<file path="app/models/__init__.py">
# SQLAlchemy models

from app.models.base import Base
from app.models.chat_history import ChatHistory
from app.models.financial_doc import FinancialDoc
from app.models.news import News
from app.models.news_article import NewsArticle
from app.models.portfolio_company import PortfolioCompany
from app.models.user import User

__all__ = [
    "Base",
    "ChatHistory", 
    "FinancialDoc",
    "News",
    "NewsArticle",
    "PortfolioCompany",
    "User"
]
</file>

<file path="app/models/base.py">
"""
Base model class
"""

from sqlalchemy.orm import declarative_base

Base = declarative_base()
</file>

<file path="app/models/chat_history.py">
"""
Chat history model
"""

from sqlalchemy import Column, Integer, String, Text, DateTime, ForeignKey, func, Index, JSON
from sqlalchemy.orm import relationship

from app.models.base import Base


class ChatHistory(Base):
    __tablename__ = "chat_history"
    
    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, nullable=True)  # Optional user ID
    question = Column(Text, nullable=False)
    answer = Column(Text)
    context = Column(JSON)  # Store search document info
    created_at = Column(DateTime, server_default=func.now())
    
    __table_args__ = (
        Index('idx_chat_history_created', 'created_at'),
    )
</file>

<file path="app/models/financial_doc.py">
"""
Financial document model
"""

from sqlalchemy import Column, Integer, String, Text, DateTime, BigInteger, func, Index

from app.models.base import Base


class FinancialDoc(Base):
    __tablename__ = "financial_docs"
    
    id = Column(Integer, primary_key=True, index=True)
    company_name = Column(String(100), nullable=False)
    doc_type = Column(String(50))  # '사업보고서', '반기보고서', '분기보고서'
    year = Column(Integer, nullable=False)
    quarter = Column(Integer)
    file_path = Column(Text, nullable=False)
    file_size = Column(BigInteger)
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())
    
    __table_args__ = (
        Index('idx_financial_docs_company_year', 'company_name', 'year'),
    )
</file>

<file path="app/models/news_article.py">
"""
NewsArticle model (alias for News model)
"""

from app.models.news import News as NewsArticle

__all__ = ["NewsArticle"]
</file>

<file path="app/models/news.py">
"""
News model
"""

from sqlalchemy import Column, Integer, String, Text, DateTime, func, Index

from app.models.base import Base


class News(Base):
    __tablename__ = "news"
    
    id = Column(Integer, primary_key=True, index=True)
    company_name = Column(String(100), nullable=False)
    title = Column(Text, nullable=False)
    content = Column(Text)
    content_url = Column(Text)
    source = Column(String(100))
    published_date = Column(DateTime)
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())
    
    __table_args__ = (
        Index('idx_news_company_date', 'company_name', 'published_date'),
    )
</file>

<file path="app/models/portfolio_company.py">
"""
Portfolio Company model
"""

from sqlalchemy import Column, Integer, String, DateTime, Text
from sqlalchemy.sql import func

from app.db.session import Base


class PortfolioCompany(Base):
    """Portfolio company model"""
    
    __tablename__ = "portfolio_companies"
    
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String(100), unique=True, nullable=False, index=True)
    industry = Column(String(100))
    description = Column(Text)
    website = Column(String(255))
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
</file>

<file path="app/models/user.py">
"""
User model
"""

from sqlalchemy import Column, Integer, String, Boolean, DateTime, func

from app.models.base import Base


class User(Base):
    __tablename__ = "users"
    
    id = Column(Integer, primary_key=True, index=True)
    email = Column(String(255), unique=True, nullable=False, index=True)
    name = Column(String(100))
    password_hash = Column(String)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, server_default=func.now())
    last_login = Column(DateTime)
</file>

<file path="app/schemas/__init__.py">
# Pydantic schemas for request/response models
</file>

<file path="app/schemas/chat_schemas.py">
"""
Chat-related Pydantic schemas
"""

from typing import Optional, List, Dict, Any
from datetime import datetime
from pydantic import BaseModel, Field


class ChatRequest(BaseModel):
    """Request model for chat endpoint"""
    question: str = Field(..., min_length=1, max_length=1000, description="User's question")
    context: Optional[Dict[str, Any]] = Field(None, description="Additional context for the query")


class ChatResponse(BaseModel):
    """Response model for chat endpoint"""
    answer: str = Field(..., description="AI-generated answer")
    sources: List[str] = Field(default_factory=list, description="Source documents used")
    charts: Optional[List[Dict[str, Any]]] = Field(None, description="Chart data if applicable")
    processing_time: Optional[float] = Field(None, description="Time taken to process (seconds)")
    metadata: Optional[Dict[str, Any]] = Field(None, description="Additional metadata (model, usage, cost)")
    
    class Config:
        json_schema_extra = {
            "example": {
                "answer": "A기업의 2024년 매출은 1,234억원입니다.",
                "sources": ["A기업_2024_사업보고서.pdf (p.23)"],
                "charts": None,
                "processing_time": 2.5,
                "metadata": {
                    "model_used": "claude-3-sonnet",
                    "token_usage": {"input_tokens": 1000, "output_tokens": 500},
                    "estimated_cost": 0.025
                }
            }
        }


class ChatHistoryItem(BaseModel):
    """Chat history item model"""
    id: int
    user_id: Optional[int]
    question: str
    answer: Optional[str]
    context: Optional[Dict[str, Any]]
    created_at: datetime
    
    class Config:
        from_attributes = True
</file>

<file path="app/schemas/document_schemas.py">
"""
Document-related Pydantic schemas
"""

from typing import Optional
from datetime import datetime
from pydantic import BaseModel, Field


class DocumentBase(BaseModel):
    """Base document model"""
    company_name: str = Field(..., max_length=100)
    doc_type: Optional[str] = Field(None, max_length=50, description="사업보고서, 반기보고서, 분기보고서")
    year: int = Field(..., ge=2000, le=2030)
    quarter: Optional[int] = Field(None, ge=1, le=4)


class DocumentCreate(DocumentBase):
    """Document creation model"""
    file_path: str = Field(..., description="Path to the document file")
    file_size: Optional[int] = Field(None, ge=0, description="File size in bytes")


class DocumentResponse(DocumentBase):
    """Document response model"""
    id: int
    file_path: str
    file_size: Optional[int]
    created_at: datetime
    updated_at: datetime
    
    class Config:
        from_attributes = True
        json_schema_extra = {
            "example": {
                "id": 1,
                "company_name": "삼성전자",
                "doc_type": "사업보고서",
                "year": 2024,
                "quarter": None,
                "file_path": "/data/financial_docs/삼성전자/2024/annual_report_2024.pdf",
                "file_size": 5242880,
                "created_at": "2025-01-15T10:30:00",
                "updated_at": "2025-01-15T10:30:00"
            }
        }


class DocumentSearchQuery(BaseModel):
    """Document search query model"""
    company_name: str
    year: Optional[int] = None
    doc_type: Optional[str] = None
    limit: int = Field(10, ge=1, le=100)
</file>

<file path="app/schemas/news_schemas.py">
"""
News-related Pydantic schemas
"""

from typing import Optional
from datetime import datetime, date
from pydantic import BaseModel, Field, HttpUrl


class NewsBase(BaseModel):
    """Base news model"""
    company_name: str = Field(..., max_length=100)
    title: str = Field(..., min_length=1)
    content: Optional[str] = None
    content_url: Optional[str] = None
    source: Optional[str] = Field(None, max_length=100)
    published_date: Optional[datetime] = None


class NewsCreate(NewsBase):
    """News creation model"""
    pass


class NewsResponse(NewsBase):
    """News response model"""
    id: int
    created_at: datetime
    updated_at: datetime
    
    class Config:
        from_attributes = True
        json_schema_extra = {
            "example": {
                "id": 1,
                "company_name": "LG전자",
                "title": "LG전자, 2024년 4분기 실적 발표",
                "content": "LG전자가 2024년 4분기 매출 20조원을 기록했다...",
                "content_url": "https://news.example.com/lg-q4-2024",
                "source": "경제신문",
                "published_date": "2025-01-20T09:00:00",
                "created_at": "2025-01-20T10:00:00",
                "updated_at": "2025-01-20T10:00:00"
            }
        }


class NewsSearchQuery(BaseModel):
    """News search query model"""
    company_name: str
    keyword: Optional[str] = None
    from_date: Optional[date] = None
    to_date: Optional[date] = None
    limit: int = Field(20, ge=1, le=100)
</file>

<file path="app/services/__init__.py">
"""
Services package
Business logic services
"""

from app.services.chat_service import ChatService
from app.services.claude_service import ClaudeService
from app.services.pdf_processor import PDFProcessor
from app.services.document_service import DocumentService

__all__ = [
    "ChatService",
    "ClaudeService", 
    "PDFProcessor",
    "DocumentService"
]
</file>

<file path="app/services/chat_service.py">
"""
Chat service for handling Q&A requests
"""

from typing import Dict, Any, Optional, List
import time
import json
import hashlib
from loguru import logger
from sqlalchemy.orm import Session

from app.services.claude_service import ClaudeService
from app.services.document_service import DocumentService
from app.services.pdf_processor import PDFProcessor
from app.schemas.chat_schemas import ChatResponse
from app.models.chat_history import ChatHistory


class ChatService:
    """Service for handling chat/Q&A functionality"""
    
    def __init__(self, db: Session):
        self.db = db
        self.claude_service = ClaudeService()
        self.document_service = DocumentService(db)
        self.pdf_processor = PDFProcessor()
        # Redis will be added later
        self.cache = {}
    
    async def process_query(
        self,
        question: str,
        context: Optional[Dict[str, Any]] = None,
        user_id: Optional[int] = None
    ) -> ChatResponse:
        """
        Process a user query and return response
        
        Args:
            question: User's question
            context: Additional context
            user_id: Optional user ID for history
        
        Returns:
            ChatResponse with answer and metadata
        """
        start_time = time.time()
        
        try:
            # Check cache first
            cache_key = self._generate_cache_key(question, context)
            cached_response = self._get_cached_response(cache_key)
            
            if cached_response:
                logger.info("Returning cached response")
                processing_time = time.time() - start_time
                cached_response["processing_time"] = processing_time
                return ChatResponse(**cached_response)
            
            # Find relevant document for the question
            document, pdf_content = self.document_service.get_document_for_question(question)
            
            if not document or not pdf_content:
                return ChatResponse(
                    answer="죄송합니다. 해당 질문에 대한 관련 문서를 찾을 수 없습니다. 회사명과 연도를 구체적으로 명시해주세요.",
                    sources=[],
                    processing_time=time.time() - start_time
                )
            
            # Check if PDF needs optimization
            if len(pdf_content) > 10 * 1024 * 1024:  # 10MB
                logger.info(f"Optimizing large PDF: {document.file_path}")
                pdf_content, optimization_metadata = self.pdf_processor.optimize_pdf(pdf_content)
                logger.info(f"PDF optimized: {optimization_metadata}")
            
            # Send to Claude API
            result = await self.claude_service.analyze_pdf_with_question(
                pdf_content=pdf_content,
                question=question,
                company_name=document.company_name,
                doc_year=document.year,
                doc_type=document.doc_type
            )
            
            # Calculate processing time
            processing_time = time.time() - start_time
            
            # Create response
            response = ChatResponse(
                answer=result["answer"],
                sources=[f"{document.company_name} {document.year}년 {document.doc_type}"],
                charts=None,  # TODO: Implement chart generation if needed
                processing_time=processing_time,
                metadata={
                    "model_used": result["model_used"],
                    "token_usage": result["usage"],
                    "estimated_cost": self.claude_service.estimate_cost(result["usage"], result["model_used"])
                }
            )
            
            # Cache the response
            self._cache_response(cache_key, response.model_dump())
            
            # Save to history
            self._save_to_history(
                user_id=user_id,
                question=question,
                answer=result["answer"],
                sources=[f"{document.company_name} {document.year}년 {document.doc_type}"],
                context=context,
                metadata=result
            )
            
            # Track API usage for cost monitoring
            self._track_api_usage(result["usage"], result["model_used"])
            
            return response
            
        except Exception as e:
            logger.error(f"Error processing query: {str(e)}", exc_info=True)
            processing_time = time.time() - start_time
            
            # Return error response
            return ChatResponse(
                answer=f"죄송합니다. 질문을 처리하는 중 오류가 발생했습니다: {str(e)}",
                sources=[],
                processing_time=processing_time
            )
    
    def _generate_cache_key(self, question: str, context: Optional[Dict[str, Any]]) -> str:
        """Generate cache key for question"""
        cache_data = {
            "question": question,
            "context": context or {}
        }
        
        cache_string = json.dumps(cache_data, sort_keys=True)
        cache_hash = hashlib.md5(cache_string.encode()).hexdigest()
        
        return f"chat:response:{cache_hash}"
    
    def _get_cached_response(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """Get cached response if exists"""
        # Simple in-memory cache for now, Redis will be added later
        return self.cache.get(cache_key)
    
    def _cache_response(self, cache_key: str, response: Dict[str, Any]):
        """Cache response with TTL"""
        # Simple in-memory cache for now, Redis will be added later
        self.cache[cache_key] = response
        
        # Limit cache size
        if len(self.cache) > 100:
            # Remove oldest entries
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
    
    def _save_to_history(
        self,
        user_id: Optional[int],
        question: str,
        answer: str,
        sources: List[str],
        context: Optional[Dict[str, Any]],
        metadata: Dict[str, Any]
    ):
        """Save chat to history"""
        try:
            history = ChatHistory(
                user_id=user_id,
                question=question,
                answer=answer,
                context={
                    "sources": sources,
                    "original_context": context,
                    "metadata": metadata
                }
            )
            self.db.add(history)
            self.db.commit()
        except Exception as e:
            logger.error(f"Error saving to history: {str(e)}")
            self.db.rollback()
    
    def _track_api_usage(self, usage: Dict[str, int], model: str):
        """Track API usage for cost monitoring"""
        try:
            # For now, just log the usage
            # Redis tracking will be added later
            total_tokens = usage["total_tokens"]
            estimated_cost = self.claude_service.estimate_cost(usage, model)
            
            logger.info(f"API Usage - Tokens: {total_tokens}, Estimated cost: ${estimated_cost:.4f}")
            
        except Exception as e:
            logger.warning(f"Error tracking API usage: {str(e)}")
    
    def check_daily_limit(self) -> bool:
        """Check if daily API limit is exceeded"""
        # For now, always allow - Redis tracking will be added later
        return True
</file>

<file path="app/services/claude_service.py">
"""
Claude API Service
Handles all interactions with Anthropic Claude API
"""

import os
from typing import Optional, Dict, Any, List
import anthropic
from anthropic import Anthropic
import base64
from loguru import logger


class ClaudeService:
    """Service for interacting with Claude API"""
    
    def __init__(self, api_key: Optional[str] = None):
        """Initialize Claude service with API key"""
        self.test_mode = os.getenv("CLAUDE_TEST_MODE", "false").lower() == "true"
        
        if self.test_mode:
            self.api_key = "test-mode-key"
            self.client = None
            logger.warning("Claude service running in TEST MODE - no API calls will be made")
        else:
            self.api_key = api_key or os.getenv("CLAUDE_API_KEY")
            if not self.api_key:
                # Try to get from settings
                from app.core.config import settings
                self.api_key = settings.CLAUDE_API_KEY
                
            if not self.api_key:
                raise ValueError("Claude API key not found. Set CLAUDE_API_KEY environment variable.")
            
            self.client = Anthropic(api_key=self.api_key)
        
        # Model configurations
        self.models = {
            "opus": "claude-3-opus-20240229",
            "sonnet": "claude-3-5-sonnet-20241022",
            "haiku": "claude-3-haiku-20240307"
        }
        
        # Default model selection
        self.default_model = "sonnet"
    
    def select_model(self, question: str, complexity: str = "medium") -> str:
        """Select appropriate Claude model based on question complexity"""
        # Simple heuristic for model selection
        if complexity == "simple" or len(question) < 50:
            return self.models["haiku"]
        elif complexity == "complex" or "분석" in question or "비교" in question:
            return self.models["opus"]
        else:
            return self.models[self.default_model]
    
    async def analyze_pdf_with_question(
        self, 
        pdf_content: bytes,
        question: str,
        company_name: str,
        doc_year: int,
        doc_type: str,
        model_override: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Send PDF content and question to Claude API
        
        Args:
            pdf_content: PDF file content as bytes
            question: User's question
            company_name: Name of the company
            doc_year: Year of the document
            doc_type: Type of document (재무제표, 사업보고서 등)
            model_override: Override model selection
            
        Returns:
            Dict containing answer and metadata
        """
        # Test mode - return dummy response
        if self.test_mode:
            logger.info(f"TEST MODE: Analyzing question for {company_name}")
            return {
                "answer": f"[테스트 모드] {company_name}의 {doc_year}년 {doc_type}에 대한 질문 '{question}'에 대한 답변입니다.\n\n매출액: 1,234억원\n영업이익: 234억원\n당기순이익: 123억원",
                "model_used": "test-mode",
                "usage": {
                    "input_tokens": 100,
                    "output_tokens": 50,
                    "total_tokens": 150
                },
                "company": company_name,
                "document": f"{doc_year}년 {doc_type}"
            }
        
        try:
            # Convert PDF to base64
            pdf_base64 = base64.b64encode(pdf_content).decode('utf-8')
            
            # Select model
            model = model_override or self.select_model(question)
            
            # Construct prompt
            system_prompt = f"""당신은 한국 투자 포트폴리오 기업의 재무 문서를 분석하는 전문가입니다.
            
주어진 {company_name}의 {doc_year}년 {doc_type}를 분석하여 사용자의 질문에 정확하게 답변해주세요.

답변 시 주의사항:
1. 문서에 있는 정보만을 기반으로 답변하세요
2. 구체적인 숫자나 수치가 있다면 반드시 포함하세요
3. 답변의 근거가 되는 페이지나 섹션을 언급하세요
4. 찾을 수 없는 정보는 솔직하게 "문서에서 찾을 수 없습니다"라고 답하세요
5. 모든 금액은 원화 단위로, 천 단위 구분자를 사용하여 표시하세요 (예: 1,234,567원)"""

            # For now, just use text-based approach
            # TODO: Implement proper PDF parsing and text extraction
            prompt = f"""You are analyzing a financial document for {company_name} from {doc_year}.

Document type: {doc_type}

User's question: {question}

Please provide a detailed answer based on typical information found in such documents. Be specific with numbers and data points."""

            # Create message with text only
            message = self.client.messages.create(
                model=model,
                max_tokens=4000,
                temperature=0.1,  # Lower temperature for factual responses
                system=system_prompt,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            # Extract response
            answer = message.content[0].text if message.content else "응답을 생성할 수 없습니다."
            
            return {
                "answer": answer,
                "model_used": model,
                "usage": {
                    "input_tokens": message.usage.input_tokens,
                    "output_tokens": message.usage.output_tokens,
                    "total_tokens": message.usage.input_tokens + message.usage.output_tokens
                },
                "company": company_name,
                "document": f"{doc_year}년 {doc_type}"
            }
            
        except anthropic.RateLimitError as e:
            logger.error(f"Rate limit error: {e}")
            raise Exception("API 요청 한도를 초과했습니다. 잠시 후 다시 시도해주세요.")
        except anthropic.APIError as e:
            logger.error(f"Claude API error: {e}")
            raise Exception(f"API 오류가 발생했습니다: {str(e)}")
        except Exception as e:
            logger.error(f"Unexpected error in Claude service: {e}")
            raise Exception(f"예상치 못한 오류가 발생했습니다: {str(e)}")
    
    def estimate_cost(self, usage: Dict[str, int], model: str) -> float:
        """Estimate API cost based on token usage"""
        # Approximate costs per 1M tokens (as of 2024)
        costs = {
            self.models["opus"]: {"input": 15.0, "output": 75.0},
            self.models["sonnet"]: {"input": 3.0, "output": 15.0},
            self.models["haiku"]: {"input": 0.25, "output": 1.25}
        }
        
        model_costs = costs.get(model, costs[self.models["sonnet"]])
        
        input_cost = (usage["input_tokens"] / 1_000_000) * model_costs["input"]
        output_cost = (usage["output_tokens"] / 1_000_000) * model_costs["output"]
        
        return input_cost + output_cost
</file>

<file path="app/services/document_service.py">
"""
Document Service
Handles document retrieval and management
"""

import os
from loguru import logger
from typing import Optional, List, Dict, Tuple
from pathlib import Path
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_

from app.models.financial_doc import FinancialDoc
from app.services.pdf_processor import PDFProcessor


class DocumentService:
    """Service for managing and retrieving documents"""
    
    def __init__(self, db: Session):
        self.db = db
        self.pdf_processor = PDFProcessor()
        self.base_path = Path("data/financial_docs")
    
    def extract_company_from_question(self, question: str) -> Optional[str]:
        """Extract company name from user question"""
        # List of known companies
        companies = ["마인이스", "우나스텔라", "설로인"]
        
        question_lower = question.lower()
        for company in companies:
            if company.lower() in question_lower:
                return company
        
        # Try variations
        variations = {
            "마인": "마인이스",
            "우나": "우나스텔라",
            "스텔라": "우나스텔라"
        }
        
        for variant, company in variations.items():
            if variant in question_lower:
                return company
        
        return None
    
    def extract_year_from_question(self, question: str) -> Optional[int]:
        """Extract year from user question"""
        import re
        
        # Pattern for 4-digit year
        year_match = re.search(r'20\d{2}', question)
        if year_match:
            return int(year_match.group())
        
        # Pattern for 2-digit year with 년
        year_match = re.search(r'(\d{2})년', question)
        if year_match:
            year = int(year_match.group(1))
            return 2000 + year if year < 50 else 1900 + year
        
        # Keywords for recent/last year
        if "최근" in question or "최신" in question:
            return 2024
        elif "작년" in question or "지난해" in question:
            return 2023
        
        return None
    
    def find_relevant_documents(
        self, 
        company: str, 
        year: Optional[int] = None,
        doc_type: Optional[str] = None
    ) -> List[FinancialDoc]:
        """Find relevant documents based on criteria"""
        query = self.db.query(FinancialDoc).filter(
            FinancialDoc.company_name == company
        )
        
        if year:
            query = query.filter(FinancialDoc.year == year)
        
        if doc_type:
            query = query.filter(FinancialDoc.doc_type == doc_type)
        
        # Order by year descending to get most recent first
        documents = query.order_by(FinancialDoc.year.desc()).all()
        
        # If no documents found with specific year, get most recent
        if not documents and year:
            documents = self.db.query(FinancialDoc).filter(
                FinancialDoc.company_name == company
            ).order_by(FinancialDoc.year.desc()).limit(1).all()
        
        return documents
    
    def read_pdf_content(self, file_path: str) -> bytes:
        """Read PDF file content"""
        full_path = Path(file_path)
        if not full_path.is_absolute():
            full_path = Path.cwd() / file_path
        
        if not full_path.exists():
            raise FileNotFoundError(f"PDF file not found: {full_path}")
        
        with open(full_path, 'rb') as f:
            return f.read()
    
    def get_document_for_question(self, question: str) -> Tuple[Optional[FinancialDoc], Optional[bytes]]:
        """
        Get the most relevant document for a user question
        
        Returns:
            Tuple of (document metadata, PDF content)
        """
        # Extract company and year from question
        company = self.extract_company_from_question(question)
        if not company:
            logger.warning(f"No company found in question: {question}")
            return None, None
        
        year = self.extract_year_from_question(question)
        
        # Find relevant documents
        documents = self.find_relevant_documents(company, year)
        
        if not documents:
            logger.warning(f"No documents found for company: {company}, year: {year}")
            return None, None
        
        # Use the first (most recent) document
        document = documents[0]
        
        try:
            # Read PDF content
            pdf_content = self.read_pdf_content(document.file_path)
            
            # Check if optimization is needed
            if len(pdf_content) > 10 * 1024 * 1024:  # 10MB
                logger.info(f"Optimizing large PDF: {document.file_path}")
                pdf_content, metadata = self.pdf_processor.optimize_pdf(pdf_content)
                logger.info(f"PDF optimized: {metadata}")
            
            return document, pdf_content
            
        except Exception as e:
            logger.error(f"Error reading PDF {document.file_path}: {e}")
            return document, None
    
    def get_all_company_documents(self, company: str) -> List[Dict]:
        """Get all documents for a specific company"""
        documents = self.db.query(FinancialDoc).filter(
            FinancialDoc.company_name == company
        ).order_by(FinancialDoc.year.desc()).all()
        
        return [
            {
                "id": doc.id,
                "year": doc.year,
                "doc_type": doc.doc_type,
                "file_path": doc.file_path,
                "file_size": doc.file_size,
                "created_at": doc.created_at
            }
            for doc in documents
        ]
    
    def search_documents(
        self,
        company_name: str,
        year: Optional[int] = None,
        doc_type: Optional[str] = None,
        limit: int = 10,
        db: Session = None
    ) -> List[Dict]:
        """Search for documents based on criteria"""
        if db:
            self.db = db
            
        query = self.db.query(FinancialDoc)
        
        # Apply filters
        query = query.filter(FinancialDoc.company_name == company_name)
        
        if year:
            query = query.filter(FinancialDoc.year == year)
        
        if doc_type:
            query = query.filter(FinancialDoc.doc_type == doc_type)
        
        # Order by year descending and limit
        documents = query.order_by(FinancialDoc.year.desc()).limit(limit).all()
        
        return [
            {
                "id": doc.id,
                "company_name": doc.company_name,
                "year": doc.year,
                "doc_type": doc.doc_type,
                "quarter": doc.quarter,
                "file_path": doc.file_path,
                "file_size": doc.file_size,
                "created_at": doc.created_at,
                "updated_at": doc.updated_at
            }
            for doc in documents
        ]
    
    def get_document_by_id(self, document_id: int, db: Session = None) -> Optional[Dict]:
        """Get a document by ID"""
        if db:
            self.db = db
            
        doc = self.db.query(FinancialDoc).filter(FinancialDoc.id == document_id).first()
        
        if not doc:
            return None
        
        return {
            "id": doc.id,
            "company_name": doc.company_name,
            "year": doc.year,
            "doc_type": doc.doc_type,
            "quarter": doc.quarter,
            "file_path": doc.file_path,
            "file_size": doc.file_size,
            "created_at": doc.created_at,
            "updated_at": doc.updated_at
        }
</file>

<file path="app/services/news_service.py">
"""
News service for managing news articles
"""

import uuid
from typing import List, Optional, Dict, Any
from datetime import date, datetime
import json
import chromadb
from sqlalchemy import select, and_, or_
from sqlalchemy.ext.asyncio import AsyncSession
from loguru import logger

from app.models.news import News
from app.schemas.news_schemas import NewsResponse
from app.core.embedding_client import EmbeddingClient
from app.core.config import settings


class NewsService:
    """Service for managing news articles"""
    
    def __init__(
        self,
        chromadb_client: chromadb.Client,
        embedding_client: EmbeddingClient
    ):
        self.chromadb_client = chromadb_client
        self.embedding_client = embedding_client
        
        # Get or create collection
        try:
            self.collection = self.chromadb_client.get_collection(
                name=settings.CHROMA_COLLECTION_NAME
            )
        except:
            self.collection = self.chromadb_client.create_collection(
                name=settings.CHROMA_COLLECTION_NAME,
                metadata={"hnsw:space": "cosine"}
            )
    
    async def search_news(
        self,
        company_name: str,
        keyword: Optional[str],
        from_date: Optional[date],
        to_date: Optional[date],
        limit: int,
        db: AsyncSession
    ) -> List[NewsResponse]:
        """Search for news articles by criteria"""
        query = select(News).where(News.company_name == company_name)
        
        if keyword:
            # Search in title and content
            query = query.where(
                or_(
                    News.title.ilike(f"%{keyword}%"),
                    News.content.ilike(f"%{keyword}%")
                )
            )
        
        if from_date:
            query = query.where(News.published_date >= datetime.combine(from_date, datetime.min.time()))
        
        if to_date:
            query = query.where(News.published_date <= datetime.combine(to_date, datetime.max.time()))
        
        # Order by published date descending
        query = query.order_by(News.published_date.desc()).limit(limit)
        
        result = await db.execute(query)
        news_items = result.scalars().all()
        
        return [NewsResponse.model_validate(item) for item in news_items]
    
    async def get_news_by_id(
        self,
        news_id: int,
        db: AsyncSession
    ) -> Optional[NewsResponse]:
        """Get news article by ID"""
        result = await db.execute(
            select(News).where(News.id == news_id)
        )
        news_item = result.scalar_one_or_none()
        
        if news_item:
            return NewsResponse.model_validate(news_item)
        return None
    
    async def index_news_from_file(
        self,
        source_file: str,
        db: AsyncSession
    ) -> Dict[str, Any]:
        """Index news from a JSON file"""
        indexed_count = 0
        error_count = 0
        errors = []
        
        try:
            with open(source_file, 'r', encoding='utf-8') as f:
                news_data = json.load(f)
            
            if not isinstance(news_data, list):
                news_data = [news_data]
            
            logger.info(f"Found {len(news_data)} news items to index")
            
            for item in news_data:
                try:
                    # Validate required fields
                    if not all(k in item for k in ['company_name', 'title']):
                        raise ValueError("Missing required fields: company_name, title")
                    
                    # Parse date if provided
                    published_date = None
                    if 'published_date' in item:
                        published_date = datetime.fromisoformat(item['published_date'].replace('Z', '+00:00'))
                    
                    # Create news entry
                    news = News(
                        company_name=item['company_name'],
                        title=item['title'],
                        content=item.get('content'),
                        content_url=item.get('content_url'),
                        source=item.get('source'),
                        published_date=published_date
                    )
                    
                    db.add(news)
                    await db.commit()
                    await db.refresh(news)
                    
                    # Index to vector database
                    await self._index_news_content(news)
                    
                    indexed_count += 1
                    logger.info(f"Indexed news: {news.title[:50]}...")
                    
                except Exception as e:
                    error_count += 1
                    error_msg = f"Error indexing news item: {str(e)}"
                    errors.append(error_msg)
                    logger.error(error_msg)
            
            return {
                "indexed": indexed_count,
                "errors": error_count,
                "error_details": errors,
                "total_items": len(news_data)
            }
            
        except Exception as e:
            logger.error(f"Error reading news file: {str(e)}")
            raise
    
    async def _index_news_content(self, news: News):
        """Index news content to vector database"""
        try:
            # Combine title and content for indexing
            text_content = f"{news.title}\n\n{news.content or ''}"
            
            if not text_content.strip():
                logger.warning(f"No content to index for news ID {news.id}")
                return
            
            # For news, we might not need chunking if articles are short
            # But we'll chunk for consistency
            chunks = self.embedding_client.chunk_text(text_content, chunk_size=500)
            
            # Prepare data for vector database
            documents = []
            metadatas = []
            ids = []
            
            for i, chunk in enumerate(chunks):
                doc_id = f"news_{news.id}_{i}_{uuid.uuid4().hex[:8]}"
                
                documents.append(chunk)
                metadatas.append({
                    "source": f"{news.source or 'Unknown'} - {news.title[:50]}",
                    "company": news.company_name,
                    "news_id": news.id,
                    "published_date": news.published_date.isoformat() if news.published_date else None,
                    "type": "news",
                    "chunk_index": i,
                    "url": news.content_url
                })
                ids.append(doc_id)
            
            # Generate embeddings and add to ChromaDB
            if documents:
                embeddings = await self.embedding_client.embed_documents(documents)
                
                self.collection.add(
                    documents=documents,
                    embeddings=embeddings,
                    metadatas=metadatas,
                    ids=ids
                )
                
                logger.info(f"Added {len(documents)} chunks to vector database for news ID {news.id}")
                
        except Exception as e:
            logger.error(f"Error indexing news content: {str(e)}")
            raise
    
    async def create_news_article(
        self,
        company_name: str,
        title: str,
        content: Optional[str],
        content_url: Optional[str],
        source: Optional[str],
        published_date: Optional[datetime],
        db: AsyncSession
    ) -> NewsResponse:
        """Create a new news article"""
        news = News(
            company_name=company_name,
            title=title,
            content=content,
            content_url=content_url,
            source=source,
            published_date=published_date
        )
        
        db.add(news)
        await db.commit()
        await db.refresh(news)
        
        # Index to vector database
        await self._index_news_content(news)
        
        return NewsResponse.model_validate(news)
</file>

<file path="app/services/pdf_processor.py">
"""
PDF Processing Service
Handles PDF optimization and text extraction
"""

import io
import logging
from typing import Optional, Tuple, List, Dict
import fitz  # PyMuPDF
from PIL import Image
import pytesseract
from pdf2image import convert_from_bytes

logger = logging.getLogger(__name__)


class PDFProcessor:
    """Service for processing and optimizing PDF files"""
    
    def __init__(self):
        self.max_file_size = 10 * 1024 * 1024  # 10MB limit for Claude
        self.target_dpi = 150  # Reduced DPI for images
        self.jpeg_quality = 85  # JPEG compression quality
    
    def optimize_pdf(self, pdf_content: bytes, max_pages: Optional[int] = None) -> Tuple[bytes, Dict[str, any]]:
        """
        Optimize PDF for Claude API submission
        
        Args:
            pdf_content: Original PDF content
            max_pages: Maximum number of pages to include
            
        Returns:
            Optimized PDF content and metadata
        """
        try:
            # Open PDF
            pdf_document = fitz.open(stream=pdf_content, filetype="pdf")
            
            # Get basic info
            num_pages = len(pdf_document)
            original_size = len(pdf_content)
            
            # Determine pages to process
            pages_to_process = min(num_pages, max_pages) if max_pages else num_pages
            
            # Create new optimized PDF
            optimized_pdf = fitz.open()
            
            for page_num in range(pages_to_process):
                page = pdf_document[page_num]
                
                # Get page dimensions
                rect = page.rect
                
                # Extract text
                text = page.get_text()
                
                # If page is mostly text, recreate it
                if len(text.strip()) > 100:  # Arbitrary threshold
                    # Create new page with text only
                    new_page = optimized_pdf.new_page(width=rect.width, height=rect.height)
                    
                    # Re-insert text (simplified - for production, preserve formatting)
                    text_rect = fitz.Rect(50, 50, rect.width - 50, rect.height - 50)
                    new_page.insert_textbox(
                        text_rect,
                        text,
                        fontsize=10,
                        fontname="helv",
                        align=fitz.TEXT_ALIGN_LEFT
                    )
                else:
                    # For image-heavy pages, reduce quality
                    pix = page.get_pixmap(dpi=self.target_dpi)
                    img_data = pix.tobytes("jpeg", jpg_quality=self.jpeg_quality)
                    
                    # Insert compressed image as new page
                    img_rect = fitz.Rect(0, 0, rect.width, rect.height)
                    new_page = optimized_pdf.new_page(width=rect.width, height=rect.height)
                    new_page.insert_image(img_rect, stream=img_data)
            
            # Save optimized PDF
            optimized_content = optimized_pdf.tobytes(
                garbage=4,  # Maximum garbage collection
                deflate=True,  # Compress streams
                clean=True  # Clean up redundant objects
            )
            
            # Close documents
            pdf_document.close()
            optimized_pdf.close()
            
            # Check if further optimization needed
            if len(optimized_content) > self.max_file_size:
                # Try text extraction as last resort
                optimized_content = self._extract_text_as_pdf(pdf_content, pages_to_process)
            
            metadata = {
                "original_pages": num_pages,
                "processed_pages": pages_to_process,
                "original_size": original_size,
                "optimized_size": len(optimized_content),
                "compression_ratio": round(len(optimized_content) / original_size, 2)
            }
            
            return optimized_content, metadata
            
        except Exception as e:
            logger.error(f"Error optimizing PDF: {e}")
            # Return original if optimization fails
            return pdf_content, {"error": str(e), "original_size": len(pdf_content)}
    
    def _extract_text_as_pdf(self, pdf_content: bytes, max_pages: int) -> bytes:
        """Extract text and create a text-only PDF"""
        try:
            pdf_document = fitz.open(stream=pdf_content, filetype="pdf")
            text_pdf = fitz.open()
            
            for page_num in range(min(len(pdf_document), max_pages)):
                page = pdf_document[page_num]
                text = page.get_text()
                
                # Handle tables specially
                tables = page.find_tables()
                if tables:
                    text += "\n\n[표 데이터]\n"
                    for table in tables:
                        for row in table.extract():
                            text += " | ".join(str(cell) if cell else "" for cell in row) + "\n"
                
                # Create text-only page
                new_page = text_pdf.new_page(width=595, height=842)  # A4 size
                text_rect = fitz.Rect(50, 50, 545, 792)
                new_page.insert_textbox(
                    text_rect,
                    text,
                    fontsize=10,
                    fontname="helv",
                    align=fitz.TEXT_ALIGN_LEFT
                )
            
            content = text_pdf.tobytes()
            pdf_document.close()
            text_pdf.close()
            
            return content
            
        except Exception as e:
            logger.error(f"Error creating text PDF: {e}")
            # Create a simple text PDF with error message
            error_pdf = fitz.open()
            page = error_pdf.new_page()
            page.insert_text((50, 50), f"텍스트 추출 오류: {str(e)}")
            content = error_pdf.tobytes()
            error_pdf.close()
            return content
    
    def extract_relevant_pages(self, pdf_content: bytes, keywords: List[str]) -> Tuple[bytes, List[int]]:
        """
        Extract only pages containing specific keywords
        
        Args:
            pdf_content: Original PDF content
            keywords: List of keywords to search for
            
        Returns:
            PDF with relevant pages and list of page numbers
        """
        try:
            pdf_document = fitz.open(stream=pdf_content, filetype="pdf")
            relevant_pages = []
            
            # Search for keywords in each page
            for page_num in range(len(pdf_document)):
                page = pdf_document[page_num]
                text = page.get_text().lower()
                
                # Check if any keyword is present
                for keyword in keywords:
                    if keyword.lower() in text:
                        relevant_pages.append(page_num)
                        break
            
            # Always include first few pages (usually contain summary)
            for i in range(min(3, len(pdf_document))):
                if i not in relevant_pages:
                    relevant_pages.insert(i, i)
            
            # Sort pages
            relevant_pages.sort()
            
            # Create new PDF with relevant pages
            relevant_pdf = fitz.open()
            for page_num in relevant_pages:
                relevant_pdf.insert_pdf(pdf_document, from_page=page_num, to_page=page_num)
            
            content = relevant_pdf.tobytes()
            
            pdf_document.close()
            relevant_pdf.close()
            
            return content, relevant_pages
            
        except Exception as e:
            logger.error(f"Error extracting relevant pages: {e}")
            return pdf_content, list(range(5))  # Return first 5 pages as fallback
    
    def extract_financial_tables(self, pdf_content: bytes) -> Dict[str, List[Dict]]:
        """Extract financial tables from PDF"""
        try:
            pdf_document = fitz.open(stream=pdf_content, filetype="pdf")
            all_tables = {}
            
            for page_num in range(len(pdf_document)):
                page = pdf_document[page_num]
                tables = page.find_tables()
                
                if tables:
                    page_tables = []
                    for table in tables:
                        # Extract table data
                        data = table.extract()
                        # Convert to list of dicts with headers
                        if data and len(data) > 1:
                            headers = [str(h).strip() for h in data[0]]
                            rows = []
                            for row in data[1:]:
                                row_dict = {}
                                for i, cell in enumerate(row):
                                    if i < len(headers):
                                        row_dict[headers[i]] = str(cell).strip() if cell else ""
                                rows.append(row_dict)
                            page_tables.append({
                                "headers": headers,
                                "data": rows
                            })
                    
                    if page_tables:
                        all_tables[f"page_{page_num + 1}"] = page_tables
            
            pdf_document.close()
            return all_tables
            
        except Exception as e:
            logger.error(f"Error extracting tables: {e}")
            return {}
</file>

<file path="app/services/rag_pipeline.py">
"""
RAG (Retrieval-Augmented Generation) Pipeline
"""

from typing import List, Tuple, Dict, Any, Optional
import chromadb
from loguru import logger

from app.core.llm_client import LLMClient
from app.core.embedding_client import EmbeddingClient
from app.core.config import settings


class RAGPipeline:
    """Retrieval-Augmented Generation pipeline for Q&A"""
    
    def __init__(
        self,
        chromadb_client: chromadb.Client,
        llm_client: LLMClient,
        embedding_client: EmbeddingClient
    ):
        self.chromadb_client = chromadb_client
        self.llm_client = llm_client
        self.embedding_client = embedding_client
        
        # Get or create collection
        try:
            self.collection = self.chromadb_client.get_collection(
                name=settings.CHROMA_COLLECTION_NAME
            )
        except:
            self.collection = self.chromadb_client.create_collection(
                name=settings.CHROMA_COLLECTION_NAME,
                metadata={"hnsw:space": "cosine"}
            )
    
    async def generate_response(
        self,
        question: str,
        context: Optional[Dict[str, Any]] = None,
        top_k: int = 5
    ) -> Tuple[str, List[str]]:
        """
        Generate response using RAG pipeline
        
        Args:
            question: User's question
            context: Additional context
            top_k: Number of documents to retrieve
        
        Returns:
            Tuple of (answer, sources)
        """
        logger.info(f"Processing question: {question[:100]}...")
        
        # 1. Generate query embedding
        query_embedding = await self.embedding_client.embed_text(question)
        
        # 2. Retrieve relevant documents
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )
        
        if not results["documents"][0]:
            logger.warning("No relevant documents found")
            return await self._generate_no_context_response(question), []
        
        # 3. Extract documents and metadata
        documents = results["documents"][0]
        metadatas = results["metadatas"][0]
        distances = results["distances"][0]
        
        # 4. Build augmented prompt
        augmented_prompt = self._build_augmented_prompt(
            question=question,
            documents=documents,
            metadatas=metadatas,
            context=context
        )
        
        # 5. Generate response
        question_type = self._classify_question(question)
        answer = await self.llm_client.generate_text(
            prompt=augmented_prompt,
            question_type=question_type,
            temperature=0.3  # Lower temperature for factual responses
        )
        
        # 6. Extract sources
        sources = self._extract_sources(metadatas)
        
        logger.info(f"Generated response with {len(sources)} sources")
        
        return answer, sources
    
    def _build_augmented_prompt(
        self,
        question: str,
        documents: List[str],
        metadatas: List[Dict[str, Any]],
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """Build augmented prompt with retrieved documents"""
        
        # Format documents with metadata
        formatted_docs = []
        for i, (doc, meta) in enumerate(zip(documents, metadatas)):
            source = meta.get("source", f"Document {i+1}")
            formatted_doc = f"[{source}]\n{doc}"
            formatted_docs.append(formatted_doc)
        
        documents_text = "\n\n---\n\n".join(formatted_docs)
        
        # Build prompt
        prompt = f"""You are an intelligent assistant for an investment team analyzing portfolio companies.
You have access to financial reports, news articles, and other documents about these companies.

Based on the following documents, please answer the user's question.
Provide specific data points, numbers, and cite your sources.
If the answer is not in the provided documents, clearly state that you don't have enough information.

Retrieved Documents:
{documents_text}

User Question: {question}

Please provide a clear, concise, and accurate answer based on the documents above.
When citing information, reference the document source in square brackets."""
        
        # Add context if provided
        if context:
            prompt += f"\n\nAdditional Context: {context}"
        
        return prompt
    
    async def _generate_no_context_response(self, question: str) -> str:
        """Generate response when no relevant documents are found"""
        prompt = f"""You are an intelligent assistant for an investment team.
The user has asked a question, but no relevant documents were found in the database.

User Question: {question}

Please provide a helpful response explaining that you don't have the specific information requested,
and suggest what kind of documents or information would be needed to answer their question."""
        
        return await self.llm_client.generate_text(
            prompt=prompt,
            question_type="simple",
            temperature=0.7
        )
    
    def _classify_question(self, question: str) -> str:
        """Classify question type for model selection"""
        question_lower = question.lower()
        
        # Simple lookup patterns
        simple_patterns = [
            "얼마", "몇", "언제", "어디", "누구",
            "매출", "이익", "자산", "부채"
        ]
        
        # Complex analysis patterns
        complex_patterns = [
            "분석", "비교", "평가", "전망", "예측",
            "왜", "어떻게", "설명", "요약"
        ]
        
        if any(pattern in question_lower for pattern in simple_patterns):
            return "simple_lookup"
        elif any(pattern in question_lower for pattern in complex_patterns):
            return "complex_analysis"
        else:
            return "standard"
    
    def _extract_sources(self, metadatas: List[Dict[str, Any]]) -> List[str]:
        """Extract source references from metadata"""
        sources = []
        
        for meta in metadatas:
            source = meta.get("source", "Unknown")
            page = meta.get("page")
            
            if page:
                source_ref = f"{source} (p.{page})"
            else:
                source_ref = source
            
            if source_ref not in sources:
                sources.append(source_ref)
        
        return sources
    
    async def add_documents(
        self,
        documents: List[str],
        metadatas: List[Dict[str, Any]],
        ids: List[str]
    ):
        """Add documents to the vector database"""
        logger.info(f"Adding {len(documents)} documents to vector database")
        
        # Generate embeddings
        embeddings = await self.embedding_client.embed_documents(documents)
        
        # Add to ChromaDB
        self.collection.add(
            documents=documents,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
        
        logger.info(f"Successfully added {len(documents)} documents")
</file>

<file path="app/__init__.py">
# Portfolio Q&A Chatbot Application
</file>

<file path="app/main.py">
"""
FastAPI main application module
"""

from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from loguru import logger

from app.api.endpoints import chat, documents, health
from app.core.config import settings
from app.db.session import engine
from app.models.base import Base


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Manage application lifecycle"""
    # Startup
    logger.info("Starting up Portfolio Q&A Chatbot...")
    
    # Create database tables
    Base.metadata.create_all(bind=engine)
    
    # Add test data for development
    if settings.DEBUG:
        from app.db.session import SessionLocal
        from app.models.financial_doc import FinancialDoc
        
        db = SessionLocal()
        try:
            # Check if documents already exist
            existing_count = db.query(FinancialDoc).count()
            if existing_count == 0:
                # Add test documents
                test_docs = [
                    FinancialDoc(
                        company_name="마인이스",
                        doc_type="사업보고서",
                        year=2024,
                        file_path="data/financial_docs/마인이스_2024_사업보고서.pdf",
                        file_size=1024000
                    ),
                    FinancialDoc(
                        company_name="우나스텔라",
                        doc_type="사업보고서",
                        year=2024,
                        file_path="data/financial_docs/우나스텔라_2024_사업보고서.pdf",
                        file_size=2048000
                    ),
                    FinancialDoc(
                        company_name="설로인",
                        doc_type="사업보고서",
                        year=2024,
                        file_path="data/financial_docs/설로인_2024_사업보고서.pdf",
                        file_size=1536000
                    )
                ]
                for doc in test_docs:
                    db.add(doc)
                db.commit()
                logger.info(f"Added {len(test_docs)} test documents")
        except Exception as e:
            logger.error(f"Error adding test data: {e}")
            db.rollback()
        finally:
            db.close()
    
    logger.info("Application started successfully")
    
    yield
    
    # Shutdown
    logger.info("Shutting down...")
    engine.dispose()


# Create FastAPI application
app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description="AI-powered Q&A chatbot for investment portfolio management",
    lifespan=lifespan
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:4001", "http://127.0.0.1:4001", "*"],  # Added specific origins
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"],
)

# Include routers
app.include_router(health.router, tags=["health"])
app.include_router(chat.router, prefix="/api/chat", tags=["chat"])
app.include_router(documents.router, prefix="/api/documents", tags=["documents"])
# app.include_router(news.router, prefix="/api/news", tags=["news"])  # Temporarily disabled

# Root endpoint
@app.get("/")
async def root():
    return {
        "message": "Welcome to Portfolio Q&A Chatbot API",
        "version": settings.APP_VERSION,
        "docs": "/docs",
        "redoc": "/redoc"
    }
</file>

<file path="data/cache/.gitkeep">
# This file ensures the directory is tracked by git
</file>

<file path="data/financial_docs/.gitkeep">
# This file ensures the directory is tracked by git
</file>

<file path="data/news_attachments/.gitkeep">
# This file ensures the directory is tracked by git
</file>

<file path="data/UPLOAD_GUIDE.md">
# 📁 투자 포트폴리오 문서 업로드 가이드

## 1. 📂 폴더 구조

문서는 다음과 같은 폴더 구조로 업로드해주세요:

```
data/financial_docs/
├── 마인이스/
│   ├── 2023/
│   └── 2024/
├── 우나스텔라/
│   ├── 2023/
│   └── 2024/
└── 설로인/
    ├── 2023/
    └── 2024/
```

## 2. 📋 파일명 규칙

### 사업보고서 (연간)
- 형식: `{회사명}_{연도}_사업보고서.pdf`
- 예시: `마인이스_2024_사업보고서.pdf`

### 분기보고서
- 형식: `{회사명}_{연도}_Q{분기}_분기보고서.pdf`
- 예시: `우나스텔라_2024_Q1_분기보고서.pdf`

### 반기보고서
- 형식: `{회사명}_{연도}_Q2_반기보고서.pdf`
- 예시: `설로인_2024_Q2_반기보고서.pdf`

## 3. 📝 지원 문서 타입

- **사업보고서**: 연간 재무제표 및 사업 현황
- **분기보고서**: 1분기, 3분기 재무 현황
- **반기보고서**: 2분기(상반기) 재무 현황

## 4. ✅ 업로드 체크리스트

1. [ ] 회사명 폴더가 정확한지 확인
2. [ ] 연도 폴더가 정확한지 확인
3. [ ] 파일명이 규칙에 맞는지 확인
4. [ ] PDF 파일 형식인지 확인

## 5. 🚀 업로드 후 처리

### 데이터베이스 초기화 (최초 1회)
```bash
python scripts/init_database.py
```

### 문서 인덱싱
```bash
python scripts/index_documents.py
```

### 서버 실행
```bash
# 가상환경 활성화
source venv/bin/activate

# 백엔드 서버 실행
python test_server.py

# 또는 실제 FastAPI 서버
python -m uvicorn app.main:app --reload
```

## 6. 💡 참고사항

- 파일명에 특수문자는 언더스코어(_)와 하이픈(-)만 사용
- 한글 파일명 사용 가능
- 파일 크기는 100MB 이하 권장
- 스캔된 PDF보다 텍스트 추출 가능한 PDF 권장

## 7. 🆘 문제 해결

### 파일이 인식되지 않을 때
1. 파일명 규칙 확인
2. 폴더 위치 확인
3. 파일 권한 확인

### 인덱싱 오류 발생 시
1. PDF 파일이 손상되지 않았는지 확인
2. 파일 크기가 너무 크지 않은지 확인
3. 로그 파일 확인: `logs/indexing.log`
</file>

<file path="frontend/public/vite.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="31.88" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 257"><defs><linearGradient id="IconifyId1813088fe1fbc01fb466" x1="-.828%" x2="57.636%" y1="7.652%" y2="78.411%"><stop offset="0%" stop-color="#41D1FF"></stop><stop offset="100%" stop-color="#BD34FE"></stop></linearGradient><linearGradient id="IconifyId1813088fe1fbc01fb467" x1="43.376%" x2="50.316%" y1="2.242%" y2="89.03%"><stop offset="0%" stop-color="#FFEA83"></stop><stop offset="8.333%" stop-color="#FFDD35"></stop><stop offset="100%" stop-color="#FFA800"></stop></linearGradient></defs><path fill="url(#IconifyId1813088fe1fbc01fb466)" d="M255.153 37.938L134.897 252.976c-2.483 4.44-8.862 4.466-11.382.048L.875 37.958c-2.746-4.814 1.371-10.646 6.827-9.67l120.385 21.517a6.537 6.537 0 0 0 2.322-.004l117.867-21.483c5.438-.991 9.574 4.796 6.877 9.62Z"></path><path fill="url(#IconifyId1813088fe1fbc01fb467)" d="M185.432.063L96.44 17.501a3.268 3.268 0 0 0-2.634 3.014l-5.474 92.456a3.268 3.268 0 0 0 3.997 3.378l24.777-5.718c2.318-.535 4.413 1.507 3.936 3.838l-7.361 36.047c-.495 2.426 1.782 4.5 4.151 3.78l15.304-4.649c2.372-.72 4.652 1.36 4.15 3.788l-11.698 56.621c-.732 3.542 3.979 5.473 5.943 2.437l1.313-2.028l72.516-144.72c1.215-2.423-.88-5.186-3.54-4.672l-25.505 4.922c-2.396.462-4.435-1.77-3.759-4.114l16.646-57.705c.677-2.35-1.37-4.583-3.769-4.113Z"></path></svg>
</file>

<file path="frontend/src/assets/react.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="35.93" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 228"><path fill="#00D8FF" d="M210.483 73.824a171.49 171.49 0 0 0-8.24-2.597c.465-1.9.893-3.777 1.273-5.621c6.238-30.281 2.16-54.676-11.769-62.708c-13.355-7.7-35.196.329-57.254 19.526a171.23 171.23 0 0 0-6.375 5.848a155.866 155.866 0 0 0-4.241-3.917C100.759 3.829 77.587-4.822 63.673 3.233C50.33 10.957 46.379 33.89 51.995 62.588a170.974 170.974 0 0 0 1.892 8.48c-3.28.932-6.445 1.924-9.474 2.98C17.309 83.498 0 98.307 0 113.668c0 15.865 18.582 31.778 46.812 41.427a145.52 145.52 0 0 0 6.921 2.165a167.467 167.467 0 0 0-2.01 9.138c-5.354 28.2-1.173 50.591 12.134 58.266c13.744 7.926 36.812-.22 59.273-19.855a145.567 145.567 0 0 0 5.342-4.923a168.064 168.064 0 0 0 6.92 6.314c21.758 18.722 43.246 26.282 56.54 18.586c13.731-7.949 18.194-32.003 12.4-61.268a145.016 145.016 0 0 0-1.535-6.842c1.62-.48 3.21-.974 4.76-1.488c29.348-9.723 48.443-25.443 48.443-41.52c0-15.417-17.868-30.326-45.517-39.844Zm-6.365 70.984c-1.4.463-2.836.91-4.3 1.345c-3.24-10.257-7.612-21.163-12.963-32.432c5.106-11 9.31-21.767 12.459-31.957c2.619.758 5.16 1.557 7.61 2.4c23.69 8.156 38.14 20.213 38.14 29.504c0 9.896-15.606 22.743-40.946 31.14Zm-10.514 20.834c2.562 12.94 2.927 24.64 1.23 33.787c-1.524 8.219-4.59 13.698-8.382 15.893c-8.067 4.67-25.32-1.4-43.927-17.412a156.726 156.726 0 0 1-6.437-5.87c7.214-7.889 14.423-17.06 21.459-27.246c12.376-1.098 24.068-2.894 34.671-5.345a134.17 134.17 0 0 1 1.386 6.193ZM87.276 214.515c-7.882 2.783-14.16 2.863-17.955.675c-8.075-4.657-11.432-22.636-6.853-46.752a156.923 156.923 0 0 1 1.869-8.499c10.486 2.32 22.093 3.988 34.498 4.994c7.084 9.967 14.501 19.128 21.976 27.15a134.668 134.668 0 0 1-4.877 4.492c-9.933 8.682-19.886 14.842-28.658 17.94ZM50.35 144.747c-12.483-4.267-22.792-9.812-29.858-15.863c-6.35-5.437-9.555-10.836-9.555-15.216c0-9.322 13.897-21.212 37.076-29.293c2.813-.98 5.757-1.905 8.812-2.773c3.204 10.42 7.406 21.315 12.477 32.332c-5.137 11.18-9.399 22.249-12.634 32.792a134.718 134.718 0 0 1-6.318-1.979Zm12.378-84.26c-4.811-24.587-1.616-43.134 6.425-47.789c8.564-4.958 27.502 2.111 47.463 19.835a144.318 144.318 0 0 1 3.841 3.545c-7.438 7.987-14.787 17.08-21.808 26.988c-12.04 1.116-23.565 2.908-34.161 5.309a160.342 160.342 0 0 1-1.76-7.887Zm110.427 27.268a347.8 347.8 0 0 0-7.785-12.803c8.168 1.033 15.994 2.404 23.343 4.08c-2.206 7.072-4.956 14.465-8.193 22.045a381.151 381.151 0 0 0-7.365-13.322Zm-45.032-43.861c5.044 5.465 10.096 11.566 15.065 18.186a322.04 322.04 0 0 0-30.257-.006c4.974-6.559 10.069-12.652 15.192-18.18ZM82.802 87.83a323.167 323.167 0 0 0-7.227 13.238c-3.184-7.553-5.909-14.98-8.134-22.152c7.304-1.634 15.093-2.97 23.209-3.984a321.524 321.524 0 0 0-7.848 12.897Zm8.081 65.352c-8.385-.936-16.291-2.203-23.593-3.793c2.26-7.3 5.045-14.885 8.298-22.6a321.187 321.187 0 0 0 7.257 13.246c2.594 4.48 5.28 8.868 8.038 13.147Zm37.542 31.03c-5.184-5.592-10.354-11.779-15.403-18.433c4.902.192 9.899.29 14.978.29c5.218 0 10.376-.117 15.453-.343c-4.985 6.774-10.018 12.97-15.028 18.486Zm52.198-57.817c3.422 7.8 6.306 15.345 8.596 22.52c-7.422 1.694-15.436 3.058-23.88 4.071a382.417 382.417 0 0 0 7.859-13.026a347.403 347.403 0 0 0 7.425-13.565Zm-16.898 8.101a358.557 358.557 0 0 1-12.281 19.815a329.4 329.4 0 0 1-23.444.823c-7.967 0-15.716-.248-23.178-.732a310.202 310.202 0 0 1-12.513-19.846h.001a307.41 307.41 0 0 1-10.923-20.627a310.278 310.278 0 0 1 10.89-20.637l-.001.001a307.318 307.318 0 0 1 12.413-19.761c7.613-.576 15.42-.876 23.31-.876H128c7.926 0 15.743.303 23.354.883a329.357 329.357 0 0 1 12.335 19.695a358.489 358.489 0 0 1 11.036 20.54a329.472 329.472 0 0 1-11 20.722Zm22.56-122.124c8.572 4.944 11.906 24.881 6.52 51.026c-.344 1.668-.73 3.367-1.15 5.09c-10.622-2.452-22.155-4.275-34.23-5.408c-7.034-10.017-14.323-19.124-21.64-27.008a160.789 160.789 0 0 1 5.888-5.4c18.9-16.447 36.564-22.941 44.612-18.3ZM128 90.808c12.625 0 22.86 10.235 22.86 22.86s-10.235 22.86-22.86 22.86s-22.86-10.235-22.86-22.86s10.235-22.86 22.86-22.86Z"></path></svg>
</file>

<file path="frontend/src/components/chat/ChatWindow.tsx">
import React from 'react';
import MessageList from './MessageList';
import MessageInput from './MessageInput';
import ErrorAlert from '../common/ErrorAlert';
import { useChatContext } from '../../contexts/ChatContext';

const ChatWindow: React.FC = () => {
  const { messages, isLoading, error, sendMessage, clearError } = useChatContext();

  return (
    <div className="flex flex-col h-full bg-gray-50">
      {error && (
        <div className="p-4 bg-white border-b">
          <ErrorAlert message={error} onClose={clearError} />
        </div>
      )}
      
      <MessageList messages={messages} isLoading={isLoading} />
      <MessageInput onSendMessage={sendMessage} disabled={isLoading} />
    </div>
  );
};

export default ChatWindow;
</file>

<file path="frontend/src/components/chat/MessageBubble.tsx">
import React from 'react';
import { User, Bot, Clock, FileText } from 'lucide-react';
import type { ChatMessage } from '../../types';

interface MessageBubbleProps {
  message: ChatMessage;
}

const MessageBubble: React.FC<MessageBubbleProps> = ({ message }) => {
  const isUser = message.role === 'user';

  return (
    <div className={`flex ${isUser ? 'justify-end' : 'justify-start'} mb-4`}>
      <div className={`flex ${isUser ? 'flex-row-reverse' : 'flex-row'} max-w-3xl`}>
        <div className={`flex-shrink-0 ${isUser ? 'ml-3' : 'mr-3'}`}>
          <div
            className={`w-10 h-10 rounded-full flex items-center justify-center ${
              isUser ? 'bg-blue-600' : 'bg-gray-600'
            }`}
          >
            {isUser ? (
              <User className="h-6 w-6 text-white" />
            ) : (
              <Bot className="h-6 w-6 text-white" />
            )}
          </div>
        </div>

        <div className={`flex flex-col ${isUser ? 'items-end' : 'items-start'}`}>
          <div
            className={`px-4 py-3 rounded-lg ${
              isUser
                ? 'bg-blue-600 text-white'
                : 'bg-gray-100 text-gray-800'
            }`}
          >
            <p className="whitespace-pre-wrap">{message.content}</p>
          </div>

          {/* Message metadata */}
          <div className="flex items-center mt-2 space-x-2 text-xs text-gray-500">
            <span>{new Date(message.timestamp).toLocaleTimeString()}</span>
            
            {message.processingTime && (
              <span className="flex items-center">
                <Clock className="h-3 w-3 mr-1" />
                {message.processingTime.toFixed(1)}초
              </span>
            )}
          </div>

          {/* Sources */}
          {message.sources && message.sources.length > 0 && (
            <div className="mt-2">
              <p className="text-xs text-gray-600 mb-1">출처:</p>
              <div className="flex flex-wrap gap-2">
                {message.sources.map((source, index) => (
                  <div
                    key={index}
                    className="flex items-center px-2 py-1 bg-gray-200 rounded text-xs text-gray-700"
                  >
                    <FileText className="h-3 w-3 mr-1" />
                    {source}
                  </div>
                ))}
              </div>
            </div>
          )}
        </div>
      </div>
    </div>
  );
};

export default MessageBubble;
</file>

<file path="frontend/src/components/chat/MessageInput.tsx">
import React, { useState, KeyboardEvent } from 'react';
import { Send } from 'lucide-react';

interface MessageInputProps {
  onSendMessage: (message: string) => void;
  disabled?: boolean;
}

const MessageInput: React.FC<MessageInputProps> = ({ onSendMessage, disabled = false }) => {
  const [message, setMessage] = useState('');

  const handleSubmit = () => {
    if (message.trim() && !disabled) {
      onSendMessage(message.trim());
      setMessage('');
    }
  };

  const handleKeyPress = (e: KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSubmit();
    }
  };

  return (
    <div className="border-t bg-white p-4">
      <div className="max-w-4xl mx-auto">
        <div className="flex items-end space-x-2">
          <textarea
            value={message}
            onChange={(e) => setMessage(e.target.value)}
            onKeyPress={handleKeyPress}
            placeholder="질문을 입력하세요... (예: 삼성전자의 최근 매출은?)"
            disabled={disabled}
            className="flex-1 resize-none rounded-lg border border-gray-300 px-4 py-2 focus:outline-none focus:ring-2 focus:ring-blue-500 disabled:bg-gray-100"
            rows={1}
            style={{ minHeight: '40px', maxHeight: '120px' }}
          />
          <button
            onClick={handleSubmit}
            disabled={disabled || !message.trim()}
            className="rounded-lg bg-blue-600 p-2 text-white hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed transition-colors"
          >
            <Send className="h-5 w-5" />
          </button>
        </div>
        
        <div className="mt-2 text-xs text-gray-500">
          Shift + Enter로 줄바꿈을 할 수 있습니다.
        </div>
      </div>
    </div>
  );
};

export default MessageInput;
</file>

<file path="frontend/src/components/chat/MessageList.tsx">
import React, { useEffect, useRef } from 'react';
import MessageBubble from './MessageBubble';
import LoadingSpinner from '../common/LoadingSpinner';
import type { ChatMessage } from '../../types';

interface MessageListProps {
  messages: ChatMessage[];
  isLoading: boolean;
}

const MessageList: React.FC<MessageListProps> = ({ messages, isLoading }) => {
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages, isLoading]);

  if (messages.length === 0 && !isLoading) {
    return (
      <div className="flex-1 flex items-center justify-center">
        <div className="text-center">
          <p className="text-gray-500 text-lg mb-2">채팅을 시작해보세요!</p>
          <p className="text-gray-400 text-sm">
            투자 포트폴리오 기업에 대한 질문을 입력하면 AI가 답변해드립니다.
          </p>
        </div>
      </div>
    );
  }

  return (
    <div className="flex-1 overflow-y-auto p-4">
      <div className="max-w-4xl mx-auto">
        {messages.map((message) => (
          <MessageBubble key={message.id} message={message} />
        ))}
        
        {isLoading && (
          <div className="flex justify-start mb-4">
            <div className="flex flex-row max-w-3xl">
              <div className="flex-shrink-0 mr-3">
                <div className="w-10 h-10 rounded-full bg-gray-600 flex items-center justify-center">
                  <LoadingSpinner size="sm" className="text-white" />
                </div>
              </div>
              <div className="px-4 py-3 rounded-lg bg-gray-100">
                <div className="flex items-center space-x-2">
                  <LoadingSpinner size="sm" />
                  <span className="text-gray-600">응답을 생성하고 있습니다...</span>
                </div>
              </div>
            </div>
          </div>
        )}
        
        <div ref={messagesEndRef} />
      </div>
    </div>
  );
};

export default MessageList;
</file>

<file path="frontend/src/components/common/ErrorAlert.tsx">
import React from 'react';
import { AlertCircle, X } from 'lucide-react';

interface ErrorAlertProps {
  message: string;
  onClose?: () => void;
}

const ErrorAlert: React.FC<ErrorAlertProps> = ({ message, onClose }) => {
  return (
    <div className="bg-red-50 border border-red-200 rounded-lg p-4 flex items-start">
      <AlertCircle className="h-5 w-5 text-red-600 mt-0.5 mr-3 flex-shrink-0" />
      <div className="flex-1">
        <p className="text-sm text-red-800">{message}</p>
      </div>
      {onClose && (
        <button
          onClick={onClose}
          className="ml-3 text-red-600 hover:text-red-800 transition-colors"
        >
          <X className="h-5 w-5" />
        </button>
      )}
    </div>
  );
};

export default ErrorAlert;
</file>

<file path="frontend/src/components/common/Header.tsx">
import React from 'react';
import { Link, useLocation } from 'react-router-dom';
import { MessageSquare, Home, FlaskConical } from 'lucide-react';

const Header: React.FC = () => {
  const location = useLocation();

  const isActive = (path: string) => location.pathname === path;

  return (
    <header className="bg-white shadow-md">
      <div className="container mx-auto px-4">
        <div className="flex items-center justify-between h-16">
          <Link to="/" className="flex items-center space-x-2">
            <MessageSquare className="h-8 w-8 text-blue-600" />
            <span className="text-xl font-bold text-gray-800">Portfolio Q&A</span>
          </Link>

          <nav className="flex space-x-6">
            <Link
              to="/"
              className={`flex items-center space-x-1 px-3 py-2 rounded-md text-sm font-medium transition-colors ${
                isActive('/') 
                  ? 'bg-blue-100 text-blue-700' 
                  : 'text-gray-600 hover:text-gray-900 hover:bg-gray-100'
              }`}
            >
              <Home className="h-4 w-4" />
              <span>홈</span>
            </Link>
            
            <Link
              to="/chat"
              className={`flex items-center space-x-1 px-3 py-2 rounded-md text-sm font-medium transition-colors ${
                isActive('/chat') 
                  ? 'bg-blue-100 text-blue-700' 
                  : 'text-gray-600 hover:text-gray-900 hover:bg-gray-100'
              }`}
            >
              <MessageSquare className="h-4 w-4" />
              <span>채팅</span>
            </Link>
            
            <Link
              to="/test"
              className={`flex items-center space-x-1 px-3 py-2 rounded-md text-sm font-medium transition-colors ${
                isActive('/test') 
                  ? 'bg-blue-100 text-blue-700' 
                  : 'text-gray-600 hover:text-gray-900 hover:bg-gray-100'
              }`}
            >
              <FlaskConical className="h-4 w-4" />
              <span>테스트</span>
            </Link>
          </nav>
        </div>
      </div>
    </header>
  );
};

export default Header;
</file>

<file path="frontend/src/components/common/LoadingSpinner.tsx">
import React from 'react';
import { Loader2 } from 'lucide-react';

interface LoadingSpinnerProps {
  size?: 'sm' | 'md' | 'lg';
  className?: string;
}

const LoadingSpinner: React.FC<LoadingSpinnerProps> = ({ size = 'md', className = '' }) => {
  const sizeClasses = {
    sm: 'h-4 w-4',
    md: 'h-8 w-8',
    lg: 'h-12 w-12',
  };

  return (
    <div className={`flex items-center justify-center ${className}`}>
      <Loader2 className={`animate-spin text-blue-600 ${sizeClasses[size]}`} />
    </div>
  );
};

export default LoadingSpinner;
</file>

<file path="frontend/src/contexts/ChatContext.tsx">
import React, { createContext, useContext, useState, useCallback, ReactNode } from 'react';
import type { ChatMessage, ChatResponse } from '../types';
import { chatAPI } from '../services/api';

interface ChatContextType {
  messages: ChatMessage[];
  isLoading: boolean;
  error: string | null;
  sendMessage: (content: string) => Promise<void>;
  clearMessages: () => void;
  clearError: () => void;
}

const ChatContext = createContext<ChatContextType | undefined>(undefined);

export const useChatContext = () => {
  const context = useContext(ChatContext);
  if (!context) {
    throw new Error('useChatContext must be used within a ChatProvider');
  }
  return context;
};

interface ChatProviderProps {
  children: ReactNode;
}

export const ChatProvider: React.FC<ChatProviderProps> = ({ children }) => {
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const sendMessage = useCallback(async (content: string) => {
    // Clear any previous errors
    setError(null);
    
    // Add user message
    const userMessage: ChatMessage = {
      id: Date.now().toString(),
      role: 'user',
      content,
      timestamp: new Date(),
    };
    
    setMessages(prev => [...prev, userMessage]);
    setIsLoading(true);

    try {
      // Send message to API
      const response: ChatResponse = await chatAPI.sendMessage(content);
      
      // Add assistant message
      const assistantMessage: ChatMessage = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: response.answer,
        timestamp: new Date(),
        sources: response.sources,
        charts: response.charts,
        processingTime: response.processingTime,
      };
      
      setMessages(prev => [...prev, assistantMessage]);
    } catch (err) {
      console.error('Error sending message:', err);
      setError(err instanceof Error ? err.message : '메시지 전송 중 오류가 발생했습니다.');
    } finally {
      setIsLoading(false);
    }
  }, []);

  const clearMessages = useCallback(() => {
    setMessages([]);
  }, []);

  const clearError = useCallback(() => {
    setError(null);
  }, []);

  const value = {
    messages,
    isLoading,
    error,
    sendMessage,
    clearMessages,
    clearError,
  };

  return <ChatContext.Provider value={value}>{children}</ChatContext.Provider>;
};
</file>

<file path="frontend/src/pages/ChatPage.tsx">
import React from 'react';
import ChatWindow from '../components/chat/ChatWindow';

const ChatPage: React.FC = () => {
  return (
    <div className="h-full flex flex-col">
      <div className="bg-white border-b px-4 py-3">
        <h1 className="text-xl font-semibold text-gray-800">
          포트폴리오 Q&A 채팅
        </h1>
        <p className="text-sm text-gray-600">
          투자 포트폴리오 기업에 대한 질문을 입력하세요.
        </p>
      </div>
      <div className="flex-1 overflow-hidden">
        <ChatWindow />
      </div>
    </div>
  );
};

export default ChatPage;
</file>

<file path="frontend/src/pages/HomePage.tsx">
import React from 'react';
import { Link } from 'react-router-dom';
import { MessageSquare, Search, FileText, TrendingUp, ArrowRight } from 'lucide-react';

const HomePage: React.FC = () => {
  const features = [
    {
      icon: <Search className="h-8 w-8 text-blue-600" />,
      title: '실시간 정보 검색',
      description: '120~250개 포트폴리오 기업의 최신 정보를 즉시 검색할 수 있습니다.',
    },
    {
      icon: <FileText className="h-8 w-8 text-blue-600" />,
      title: '재무제표 분석',
      description: 'PDF 형태의 사업보고서, 분기보고서를 AI가 분석하여 답변합니다.',
    },
    {
      icon: <TrendingUp className="h-8 w-8 text-blue-600" />,
      title: '데이터 시각화',
      description: '재무 데이터를 차트로 시각화하여 한눈에 파악할 수 있습니다.',
    },
  ];

  const exampleQuestions = [
    "삼성전자의 2024년 매출은 얼마인가요?",
    "LG전자의 최근 인수합병 소식이 있나요?",
    "SK하이닉스의 HBM 사업 현황을 알려주세요.",
    "현대자동차의 전기차 판매 실적은 어떤가요?",
  ];

  return (
    <div className="min-h-screen bg-gray-50">
      {/* Hero Section */}
      <section className="bg-white">
        <div className="container mx-auto px-4 py-16">
          <div className="text-center max-w-3xl mx-auto">
            <h1 className="text-4xl font-bold text-gray-900 mb-4">
              투자 포트폴리오 Q&A 챗봇
            </h1>
            <p className="text-xl text-gray-600 mb-8">
              AI 기반 대화형 시스템으로 포트폴리오 기업의 재무 정보와 뉴스를 
              실시간으로 조회하고 분석해보세요.
            </p>
            <Link
              to="/chat"
              className="inline-flex items-center px-6 py-3 bg-blue-600 text-white font-medium rounded-lg hover:bg-blue-700 transition-colors"
            >
              <MessageSquare className="h-5 w-5 mr-2" />
              채팅 시작하기
              <ArrowRight className="h-5 w-5 ml-2" />
            </Link>
          </div>
        </div>
      </section>

      {/* Features Section */}
      <section className="py-16">
        <div className="container mx-auto px-4">
          <h2 className="text-3xl font-bold text-center text-gray-900 mb-12">
            주요 기능
          </h2>
          <div className="grid md:grid-cols-3 gap-8">
            {features.map((feature, index) => (
              <div
                key={index}
                className="bg-white p-6 rounded-lg shadow-md hover:shadow-lg transition-shadow"
              >
                <div className="mb-4">{feature.icon}</div>
                <h3 className="text-xl font-semibold text-gray-900 mb-2">
                  {feature.title}
                </h3>
                <p className="text-gray-600">{feature.description}</p>
              </div>
            ))}
          </div>
        </div>
      </section>

      {/* Example Questions Section */}
      <section className="py-16 bg-white">
        <div className="container mx-auto px-4">
          <h2 className="text-3xl font-bold text-center text-gray-900 mb-12">
            이런 질문을 해보세요
          </h2>
          <div className="max-w-2xl mx-auto">
            <div className="space-y-4">
              {exampleQuestions.map((question, index) => (
                <Link
                  key={index}
                  to="/chat"
                  className="block p-4 bg-gray-50 rounded-lg hover:bg-gray-100 transition-colors"
                >
                  <div className="flex items-center">
                    <MessageSquare className="h-5 w-5 text-blue-600 mr-3 flex-shrink-0" />
                    <span className="text-gray-700">{question}</span>
                  </div>
                </Link>
              ))}
            </div>
          </div>
        </div>
      </section>

      {/* CTA Section */}
      <section className="py-16">
        <div className="container mx-auto px-4 text-center">
          <h2 className="text-3xl font-bold text-gray-900 mb-4">
            지금 바로 시작하세요
          </h2>
          <p className="text-xl text-gray-600 mb-8">
            투자팀의 업무 효율을 90% 향상시켜보세요.
          </p>
          <Link
            to="/chat"
            className="inline-flex items-center px-8 py-4 bg-blue-600 text-white font-medium rounded-lg hover:bg-blue-700 transition-colors text-lg"
          >
            채팅 시작하기
            <ArrowRight className="h-6 w-6 ml-2" />
          </Link>
        </div>
      </section>
    </div>
  );
};

export default HomePage;
</file>

<file path="frontend/src/pages/TestPage.tsx">
import React, { useState } from 'react';
import { 
  CheckCircle, 
  XCircle, 
  AlertCircle, 
  RefreshCw,
  Database,
  Server,
  HardDrive,
  Activity
} from 'lucide-react';
import { healthAPI, chatAPI, documentAPI, newsAPI } from '../services/api';
import LoadingSpinner from '../components/common/LoadingSpinner';

interface TestResult {
  name: string;
  status: 'pending' | 'testing' | 'success' | 'error';
  message?: string;
  data?: any;
}

const TestPage: React.FC = () => {
  const [testResults, setTestResults] = useState<TestResult[]>([]);
  const [isRunning, setIsRunning] = useState(false);

  const testCases = [
    {
      name: '기본 헬스체크',
      test: async () => {
        const result = await healthAPI.checkHealth();
        return { success: true, data: result };
      },
    },
    {
      name: '상세 헬스체크',
      test: async () => {
        const result = await healthAPI.checkDetailedHealth();
        return { success: true, data: result };
      },
    },
    {
      name: '채팅 API 테스트',
      test: async () => {
        const result = await chatAPI.sendMessage('테스트 메시지입니다.');
        return { success: true, data: result };
      },
    },
    {
      name: '문서 검색 테스트',
      test: async () => {
        const result = await documentAPI.searchDocuments({ 
          company: '삼성전자',
          limit: 5 
        });
        return { success: true, data: result };
      },
    },
    {
      name: '뉴스 검색 테스트',
      test: async () => {
        const result = await newsAPI.searchNews({ 
          company: '삼성전자',
          limit: 5 
        });
        return { success: true, data: result };
      },
    },
  ];

  const runTests = async () => {
    setIsRunning(true);
    const results: TestResult[] = testCases.map(tc => ({
      name: tc.name,
      status: 'pending' as const,
    }));
    setTestResults(results);

    for (let i = 0; i < testCases.length; i++) {
      // Update to testing
      results[i].status = 'testing';
      setTestResults([...results]);

      try {
        const testResult = await testCases[i].test();
        results[i].status = 'success';
        results[i].data = testResult.data;
        results[i].message = '성공';
      } catch (error) {
        results[i].status = 'error';
        results[i].message = error instanceof Error ? error.message : '알 수 없는 오류';
      }

      setTestResults([...results]);
    }

    setIsRunning(false);
  };

  const getStatusIcon = (status: TestResult['status']) => {
    switch (status) {
      case 'pending':
        return <AlertCircle className="h-5 w-5 text-gray-400" />;
      case 'testing':
        return <LoadingSpinner size="sm" />;
      case 'success':
        return <CheckCircle className="h-5 w-5 text-green-600" />;
      case 'error':
        return <XCircle className="h-5 w-5 text-red-600" />;
    }
  };

  const getServiceIcon = (serviceName: string) => {
    if (serviceName.includes('PostgreSQL')) return <Database className="h-4 w-4" />;
    if (serviceName.includes('Redis')) return <Server className="h-4 w-4" />;
    if (serviceName.includes('ChromaDB')) return <HardDrive className="h-4 w-4" />;
    return <Activity className="h-4 w-4" />;
  };

  return (
    <div className="container mx-auto px-4 py-8 max-w-4xl">
      <div className="bg-white rounded-lg shadow-md p-6 mb-8">
        <h1 className="text-2xl font-bold text-gray-900 mb-4">
          API 테스트 대시보드
        </h1>
        <p className="text-gray-600 mb-6">
          백엔드 API와 데이터베이스 연결 상태를 확인합니다.
        </p>
        
        <button
          onClick={runTests}
          disabled={isRunning}
          className="inline-flex items-center px-4 py-2 bg-blue-600 text-white font-medium rounded-lg hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed transition-colors"
        >
          <RefreshCw className={`h-5 w-5 mr-2 ${isRunning ? 'animate-spin' : ''}`} />
          {isRunning ? '테스트 진행 중...' : '테스트 실행'}
        </button>
      </div>

      {testResults.length > 0 && (
        <div className="space-y-4">
          {testResults.map((result, index) => (
            <div
              key={index}
              className="bg-white rounded-lg shadow-md p-6 transition-all"
            >
              <div className="flex items-center justify-between mb-4">
                <div className="flex items-center space-x-3">
                  {getStatusIcon(result.status)}
                  <h3 className="text-lg font-semibold text-gray-900">
                    {result.name}
                  </h3>
                </div>
                {result.message && (
                  <span
                    className={`text-sm ${
                      result.status === 'error' ? 'text-red-600' : 'text-green-600'
                    }`}
                  >
                    {result.message}
                  </span>
                )}
              </div>

              {result.data && (
                <div className="mt-4">
                  {/* Special handling for detailed health check */}
                  {result.name === '상세 헬스체크' && result.data.dependencies && (
                    <div className="space-y-2">
                      <p className="text-sm font-medium text-gray-700 mb-2">
                        서비스 상태:
                      </p>
                      {Object.entries(result.data.dependencies).map(([service, info]: [string, any]) => (
                        <div
                          key={service}
                          className="flex items-center justify-between p-2 bg-gray-50 rounded"
                        >
                          <div className="flex items-center space-x-2">
                            {getServiceIcon(service)}
                            <span className="text-sm font-medium capitalize">
                              {service}
                            </span>
                          </div>
                          <span
                            className={`text-sm ${
                              info.status === 'healthy'
                                ? 'text-green-600'
                                : 'text-red-600'
                            }`}
                          >
                            {info.status}
                          </span>
                        </div>
                      ))}
                    </div>
                  )}
                  
                  {/* Default data display */}
                  {result.name !== '상세 헬스체크' && (
                    <div className="bg-gray-50 rounded p-4 overflow-auto max-h-60">
                      <pre className="text-xs text-gray-700">
                        {JSON.stringify(result.data, null, 2)}
                      </pre>
                    </div>
                  )}
                </div>
              )}
            </div>
          ))}
        </div>
      )}

      {/* Quick Test Samples */}
      <div className="mt-12 bg-white rounded-lg shadow-md p-6">
        <h2 className="text-xl font-bold text-gray-900 mb-4">
          빠른 테스트 예제
        </h2>
        <div className="space-y-3">
          <div className="p-3 bg-gray-50 rounded">
            <p className="text-sm font-medium text-gray-700">채팅 테스트:</p>
            <code className="text-xs text-gray-600">
              "삼성전자의 최근 매출은 얼마인가요?"
            </code>
          </div>
          <div className="p-3 bg-gray-50 rounded">
            <p className="text-sm font-medium text-gray-700">문서 검색:</p>
            <code className="text-xs text-gray-600">
              company: "LG전자", year: 2024
            </code>
          </div>
          <div className="p-3 bg-gray-50 rounded">
            <p className="text-sm font-medium text-gray-700">뉴스 검색:</p>
            <code className="text-xs text-gray-600">
              company: "SK하이닉스", keyword: "HBM"
            </code>
          </div>
        </div>
      </div>
    </div>
  );
};

export default TestPage;
</file>

<file path="frontend/src/services/api.ts">
import axios from 'axios';

const API_BASE_URL = import.meta.env.VITE_API_URL || 'http://127.0.0.1:8081/api';

const api = axios.create({
  baseURL: API_BASE_URL,
  headers: {
    'Content-Type': 'application/json',
  },
});

// Request interceptor
api.interceptors.request.use(
  (config) => {
    // Add auth token if available
    const token = localStorage.getItem('authToken');
    if (token) {
      config.headers.Authorization = `Bearer ${token}`;
    }
    return config;
  },
  (error) => {
    return Promise.reject(error);
  }
);

// Response interceptor
api.interceptors.response.use(
  (response) => response,
  (error) => {
    console.error('API Error:', error);
    
    if (error.code === 'ERR_NETWORK' || error.code === 'ERR_CONNECTION_REFUSED') {
      error.message = '백엔드 서버에 연결할 수 없습니다. 서버가 실행 중인지 확인해주세요.';
    } else if (error.response?.status === 401) {
      // Handle unauthorized
      localStorage.removeItem('authToken');
      window.location.href = '/login';
    } else if (error.response?.status === 500) {
      error.message = error.response?.data?.detail || '서버 오류가 발생했습니다.';
    }
    
    return Promise.reject(error);
  }
);

// Chat API
export const chatAPI = {
  sendMessage: async (question: string, context?: any) => {
    const response = await api.post('/chat/', { question, context });
    return response.data;
  },
  
  getChatHistory: async (limit = 50, offset = 0) => {
    const response = await api.get('/chat/history', { params: { limit, offset } });
    return response.data;
  },
};

// Document API
export const documentAPI = {
  searchDocuments: async (params: {
    company: string;
    year?: number;
    type?: string;
    limit?: number;
  }) => {
    const response = await api.get('/documents/search', { params });
    return response.data;
  },
  
  getDocument: async (id: number) => {
    const response = await api.get(`/documents/${id}`);
    return response.data;
  },
};

// News API
export const newsAPI = {
  searchNews: async (params: {
    company: string;
    keyword?: string;
    from?: string;
    to?: string;
    limit?: number;
  }) => {
    const response = await api.get('/news/search', { params });
    return response.data;
  },
  
  getNewsArticle: async (id: number) => {
    const response = await api.get(`/news/${id}`);
    return response.data;
  },
};

// Health API
export const healthAPI = {
  checkHealth: async () => {
    const response = await axios.get('http://127.0.0.1:8081/health');
    return response.data;
  },
  
  checkDetailedHealth: async () => {
    const response = await axios.get('http://127.0.0.1:8081/health/detailed');
    return response.data;
  },
};

export default api;
</file>

<file path="frontend/src/types/index.ts">
// Chat types
export interface ChatMessage {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  sources?: string[];
  charts?: ChartData[];
  processingTime?: number;
}

export interface ChatRequest {
  question: string;
  context?: any;
}

export interface ChatResponse {
  answer: string;
  sources: string[];
  charts?: ChartData[];
  processingTime?: number;
}

// Chart types
export interface ChartData {
  type: 'line' | 'bar' | 'pie';
  title: string;
  data: any;
  options?: any;
}

// Document types
export interface Document {
  id: number;
  companyName: string;
  docType?: string;
  year: number;
  quarter?: number;
  filePath: string;
  fileSize?: number;
  createdAt: string;
  updatedAt: string;
}

// News types
export interface NewsArticle {
  id: number;
  companyName: string;
  title: string;
  content?: string;
  contentUrl?: string;
  source?: string;
  publishedDate?: string;
  createdAt: string;
  updatedAt: string;
}

// Health check types
export interface HealthStatus {
  status: 'healthy' | 'degraded' | 'unhealthy';
  service: string;
  version: string;
  dependencies?: {
    [key: string]: {
      status: 'healthy' | 'unhealthy';
      error?: string;
      statusCode?: number;
    };
  };
}
</file>

<file path="frontend/src/App.tsx">
import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { ChatProvider } from './contexts/ChatContext';
import Header from './components/common/Header';
import HomePage from './pages/HomePage';
import ChatPage from './pages/ChatPage';
import TestPage from './pages/TestPage';

function App() {
  return (
    <Router>
      <ChatProvider>
        <div className="flex flex-col h-screen">
          <Header />
          <main className="flex-1 overflow-hidden">
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/chat" element={<ChatPage />} />
              <Route path="/test" element={<TestPage />} />
            </Routes>
          </main>
        </div>
      </ChatProvider>
    </Router>
  );
}

export default App;
</file>

<file path="frontend/src/index.css">
@tailwind base;
@tailwind components;
@tailwind utilities;
</file>

<file path="frontend/src/main.tsx">
import { StrictMode } from 'react'
import { createRoot } from 'react-dom/client'
import './index.css'
import App from './App.tsx'

createRoot(document.getElementById('root')!).render(
  <StrictMode>
    <App />
  </StrictMode>,
)
</file>

<file path="frontend/src/vite-env.d.ts">
/// <reference types="vite/client" />
</file>

<file path="frontend/.env.example">
# API Configuration
VITE_API_URL=http://localhost:8080/api
</file>

<file path="frontend/.gitignore">
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
*.local

# Editor directories and files
.vscode/*
!.vscode/extensions.json
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?
</file>

<file path="frontend/eslint.config.js">
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import tseslint from 'typescript-eslint'
import { globalIgnores } from 'eslint/config'

export default tseslint.config([
  globalIgnores(['dist']),
  {
    files: ['**/*.{ts,tsx}'],
    extends: [
      js.configs.recommended,
      tseslint.configs.recommended,
      reactHooks.configs['recommended-latest'],
      reactRefresh.configs.vite,
    ],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
    },
  },
])
</file>

<file path="frontend/index.html">
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vite + React + TS</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>
</file>

<file path="frontend/package.json">
{
  "name": "frontend",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc -b && vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "axios": "^1.11.0",
    "chart.js": "^4.5.0",
    "lucide-react": "^0.525.0",
    "react": "^19.1.0",
    "react-chartjs-2": "^5.3.0",
    "react-dom": "^19.1.0",
    "react-router-dom": "^7.7.1"
  },
  "devDependencies": {
    "@eslint/js": "^9.30.1",
    "@types/react": "^19.1.8",
    "@types/react-dom": "^19.1.6",
    "@types/react-router-dom": "^5.3.3",
    "@vitejs/plugin-react": "^4.6.0",
    "autoprefixer": "^10.4.21",
    "eslint": "^9.30.1",
    "eslint-plugin-react-hooks": "^5.2.0",
    "eslint-plugin-react-refresh": "^0.4.20",
    "globals": "^16.3.0",
    "postcss": "^8.5.6",
    "tailwindcss": "^3.4.17",
    "typescript": "~5.8.3",
    "typescript-eslint": "^8.35.1",
    "vite": "^7.0.4"
  }
}
</file>

<file path="frontend/postcss.config.cjs">
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}
</file>

<file path="frontend/postcss.config.mjs">
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}
</file>

<file path="frontend/README.md">
# 포트폴리오 Q&A 챗봇 프론트엔드

React + TypeScript + Vite로 구축된 투자 포트폴리오 Q&A 챗봇의 프론트엔드입니다.

## 기술 스택

- **React 19** - UI 라이브러리
- **TypeScript** - 타입 안정성
- **Vite** - 빌드 도구
- **Tailwind CSS** - 스타일링
- **React Router** - 라우팅
- **Axios** - API 통신
- **Chart.js** - 데이터 시각화

## 시작하기

### 개발 환경 실행

```bash
# 의존성 설치
npm install

# 개발 서버 실행 (http://localhost:4000)
npm run dev
```

### 빌드

```bash
# 프로덕션 빌드
npm run build

# 빌드 미리보기
npm run preview
```

## 프로젝트 구조

```
src/
├── components/      # 재사용 가능한 컴포넌트
│   ├── chat/       # 채팅 관련 컴포넌트
│   ├── common/     # 공통 컴포넌트
│   └── charts/     # 차트 컴포넌트
├── contexts/       # React Context
├── pages/          # 페이지 컴포넌트
├── services/       # API 서비스
├── types/          # TypeScript 타입 정의
└── hooks/          # 커스텀 훅
```

## 주요 기능

### 1. 홈페이지 (`/`)
- 서비스 소개
- 주요 기능 안내
- 예시 질문 제공

### 2. 채팅 페이지 (`/chat`)
- 실시간 Q&A 채팅
- 응답 소스 표시
- 로딩 상태 표시

### 3. 테스트 페이지 (`/test`)
- API 연결 상태 확인
- 백엔드 서비스 헬스체크
- 샘플 API 테스트

## 환경 변수

`.env` 파일을 생성하고 다음 내용을 설정하세요:

```env
# API 서버 URL
VITE_API_URL=http://localhost/api
```

## API 연동

백엔드 API는 다음 엔드포인트를 사용합니다:

- `/api/chat` - 채팅 메시지 전송
- `/api/documents/search` - 문서 검색
- `/api/news/search` - 뉴스 검색
- `/api/health` - 헬스체크

## 개발 가이드

### 컴포넌트 추가

새로운 컴포넌트 추가 시:

1. `src/components` 내 적절한 폴더에 생성
2. TypeScript 인터페이스 정의
3. Tailwind CSS 클래스 사용

### API 추가

새로운 API 추가 시:

1. `src/services/api.ts`에 함수 추가
2. `src/types/index.ts`에 타입 정의
3. 에러 처리 로직 포함

## 문제 해결

### CORS 에러
개발 환경에서는 Vite 프록시가 자동으로 처리합니다.
프로덕션에서는 Nginx 설정을 확인하세요.

### 빌드 에러
```bash
# 캐시 삭제 후 재설치
rm -rf node_modules package-lock.json
npm install
```
</file>

<file path="frontend/tailwind.config.js">
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}
</file>

<file path="frontend/tsconfig.app.json">
{
  "compilerOptions": {
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.app.tsbuildinfo",
    "target": "ES2022",
    "useDefineForClassFields": true,
    "lib": ["ES2022", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,
    "moduleDetection": "force",
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "erasableSyntaxOnly": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  },
  "include": ["src"]
}
</file>

<file path="frontend/tsconfig.json">
{
  "files": [],
  "references": [
    { "path": "./tsconfig.app.json" },
    { "path": "./tsconfig.node.json" }
  ]
}
</file>

<file path="frontend/tsconfig.node.json">
{
  "compilerOptions": {
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.node.tsbuildinfo",
    "target": "ES2023",
    "lib": ["ES2023"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,
    "moduleDetection": "force",
    "noEmit": true,

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "erasableSyntaxOnly": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  },
  "include": ["vite.config.ts"]
}
</file>

<file path="frontend/vite.config.ts">
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
  server: {
    port: 4001,
    proxy: {
      '/api': {
        target: 'http://127.0.0.1:8081',
        changeOrigin: true,
        secure: false,
        rewrite: (path) => path,  // Keep the path as is
        configure: (proxy, _options) => {
          proxy.on('error', (err, _req, _res) => {
            console.log('proxy error', err);
          });
          proxy.on('proxyReq', (proxyReq, req, _res) => {
            console.log('Proxying:', req.method, req.url, '->', proxyReq.path);
          });
          proxy.on('proxyRes', (proxyRes, req, _res) => {
            console.log('Received:', proxyRes.statusCode, req.url);
          });
        },
      },
    },
  },
})
</file>

<file path="init-db/01_create_schema.sql">
-- Enable required extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- News metadata table
CREATE TABLE IF NOT EXISTS news (
    id SERIAL PRIMARY KEY,
    company_name VARCHAR(100) NOT NULL,
    title TEXT NOT NULL,
    content TEXT,
    content_url TEXT,
    source VARCHAR(100),
    published_date TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Create index for news table
CREATE INDEX idx_news_company_date ON news (company_name, published_date DESC);

-- Financial documents index table
CREATE TABLE IF NOT EXISTS financial_docs (
    id SERIAL PRIMARY KEY,
    company_name VARCHAR(100) NOT NULL,
    doc_type VARCHAR(50), -- '사업보고서', '반기보고서', '분기보고서'
    year INTEGER NOT NULL,
    quarter INTEGER,
    file_path TEXT NOT NULL,
    file_size BIGINT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Create index for financial_docs table
CREATE INDEX idx_financial_docs_company_year ON financial_docs (company_name, year DESC);

-- Users table (for future extensibility)
CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    name VARCHAR(100),
    password_hash TEXT,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT NOW(),
    last_login TIMESTAMP
);

-- Chat history table (optional)
CREATE TABLE IF NOT EXISTS chat_history (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    question TEXT NOT NULL,
    answer TEXT,
    context JSONB, -- stored search document info
    created_at TIMESTAMP DEFAULT NOW()
);

-- Create index for chat_history
CREATE INDEX idx_chat_history_user_created ON chat_history (user_id, created_at DESC);
</file>

<file path="nginx/conf.d/default.conf">
upstream fastapi_backend {
    server app:8080;
}

server {
    listen 80;
    server_name localhost;

    client_max_body_size 50M;

    # API endpoints
    location /api {
        proxy_pass http://fastapi_backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        
        # Timeout settings for long-running requests
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # FastAPI documentation
    location /docs {
        proxy_pass http://fastapi_backend/docs;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    location /redoc {
        proxy_pass http://fastapi_backend/redoc;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Static files (if needed in the future)
    location /static {
        alias /usr/share/nginx/html/static;
    }

    # Health check endpoint
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
}
</file>

<file path="nginx/nginx.conf">
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css text/xml text/javascript application/json application/javascript application/xml+rss;

    # Include server configurations
    include /etc/nginx/conf.d/*.conf;
}
</file>

<file path="scripts/create_dummy_pdfs.py">
"""
Create dummy PDF files for testing
"""
from reportlab.pdfgen import canvas
from pathlib import Path

def create_dummy_pdf(filepath: Path, company: str, year: int):
    """Create a dummy PDF with test content"""
    c = canvas.Canvas(str(filepath))
    
    # Add test content
    c.setFont("Helvetica-Bold", 20)
    c.drawString(100, 750, f"{company} {year}년 사업보고서")
    
    c.setFont("Helvetica", 12)
    c.drawString(100, 700, f"테스트용 더미 문서입니다.")
    c.drawString(100, 680, f"실제 내용은 추후 업로드됩니다.")
    
    # Add some dummy financial data
    c.drawString(100, 640, f"매출액: 1,234억원")
    c.drawString(100, 620, f"영업이익: 234억원")
    c.drawString(100, 600, f"당기순이익: 123억원")
    
    c.save()

def main():
    # Create data directory
    data_dir = Path("data/financial_docs")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # Companies and their dummy PDFs
    companies = [
        ("마인이스", 2024),
        ("우나스텔라", 2024),
        ("설로인", 2024)
    ]
    
    for company, year in companies:
        filename = f"{company}_{year}_사업보고서.pdf"
        filepath = data_dir / filename
        
        if not filepath.exists():
            create_dummy_pdf(filepath, company, year)
            print(f"Created: {filepath}")
        else:
            print(f"Already exists: {filepath}")

if __name__ == "__main__":
    main()
</file>

<file path="scripts/create_test_files.py">
"""
Create test files for development
"""
from pathlib import Path

def create_test_file(filepath: Path, company: str, year: int):
    """Create a test file with dummy content"""
    content = f"""
{company} {year}년 사업보고서

테스트용 더미 문서입니다.

주요 재무 정보:
- 매출액: 1,234억원
- 영업이익: 234억원  
- 당기순이익: 123억원

사업 개요:
{company}는 혁신적인 기술을 보유한 기업으로, 지속적인 성장을 이어가고 있습니다.

주요 사업 분야:
1. AI 솔루션 개발
2. 클라우드 서비스
3. 데이터 분석

향후 전망:
{year+1}년에도 지속적인 성장이 예상됩니다.
"""
    
    filepath.write_text(content, encoding='utf-8')

def main():
    # Create data directory
    data_dir = Path("data/financial_docs")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # Companies and their test files
    companies = [
        ("마인이스", 2024),
        ("우나스텔라", 2024),
        ("설로인", 2024)
    ]
    
    for company, year in companies:
        # Create as .txt for now (will be treated as PDF in test)
        filename = f"{company}_{year}_사업보고서.pdf"
        filepath = data_dir / filename
        
        if not filepath.exists():
            create_test_file(filepath, company, year)
            print(f"Created: {filepath}")
        else:
            print(f"Already exists: {filepath}")

if __name__ == "__main__":
    main()
</file>

<file path="scripts/import_news.py">
#!/usr/bin/env python3
"""
Import news data from JSON file into the database
"""

import asyncio
import sys
from pathlib import Path
import argparse
from datetime import datetime
import json
from loguru import logger

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

from app.db.session import AsyncSessionLocal
from app.services.news_service import NewsService
from app.core.embedding_client import EmbeddingClient
from app.core.config import settings
import chromadb
from chromadb.config import Settings as ChromaSettings


def get_chromadb_client() -> chromadb.Client:
    """Get ChromaDB client"""
    try:
        return chromadb.HttpClient(
            host="localhost",
            port=8000,
            settings=ChromaSettings(anonymized_telemetry=False)
        )
    except Exception as e:
        logger.warning(f"Could not connect to ChromaDB server: {e}")
        return chromadb.PersistentClient(path="./chromadb_data")


def create_sample_news_data(output_file: str):
    """Create sample news data for testing"""
    
    sample_news = [
        {
            "company_name": "삼성전자",
            "title": "삼성전자, 2024년 4분기 영업이익 6.5조원 기록",
            "content": "삼성전자가 2024년 4분기 영업이익 6.5조원을 기록하며 시장 예상치를 상회했다. 메모리 반도체 가격 상승과 스마트폰 판매 호조가 실적 개선의 주요 원인으로 분석된다.",
            "content_url": "https://news.example.com/samsung-q4-2024",
            "source": "한국경제신문",
            "published_date": "2025-01-25T09:00:00"
        },
        {
            "company_name": "삼성전자",
            "title": "삼성전자, AI 반도체 시장 진출 본격화",
            "content": "삼성전자가 차세대 AI 반도체 개발에 10조원을 투자한다고 발표했다. 2025년 하반기 양산을 목표로 하고 있으며, 글로벌 AI 칩 시장에서의 경쟁력 확보를 노린다.",
            "content_url": "https://news.example.com/samsung-ai-chip",
            "source": "매일경제",
            "published_date": "2025-01-20T14:30:00"
        },
        {
            "company_name": "LG전자",
            "title": "LG전자, 전장사업부 매출 사상 최대치 달성",
            "content": "LG전자의 전장사업부가 2024년 연간 매출 10조원을 돌파하며 사상 최대 실적을 기록했다. 전기차 시장 성장과 함께 배터리, 인포테인먼트 시스템 수주가 크게 늘었다.",
            "content_url": "https://news.example.com/lg-auto-record",
            "source": "서울경제",
            "published_date": "2025-01-22T11:00:00"
        },
        {
            "company_name": "SK하이닉스",
            "title": "SK하이닉스, HBM3E 양산 시작... AI 시장 공략",
            "content": "SK하이닉스가 차세대 고대역폭 메모리 HBM3E의 양산을 시작했다. 엔비디아 등 주요 AI 칩 제조사에 공급될 예정이며, AI 서버 시장에서의 점유율 확대가 기대된다.",
            "content_url": "https://news.example.com/sk-hbm3e",
            "source": "전자신문",
            "published_date": "2025-01-23T13:45:00"
        },
        {
            "company_name": "현대자동차",
            "title": "현대차, 인도 시장에서 연간 판매 100만대 돌파",
            "content": "현대자동차가 인도 시장에서 연간 판매량 100만대를 처음으로 돌파했다. 인도 내 전기차 생산 시설 확충과 현지화 전략이 주효했다는 평가다.",
            "content_url": "https://news.example.com/hyundai-india",
            "source": "한국일보",
            "published_date": "2025-01-21T10:30:00"
        },
        {
            "company_name": "네이버",
            "title": "네이버, 자체 개발 LLM '하이퍼클로바X' 글로벌 출시",
            "content": "네이버가 자체 개발한 대규모 언어모델 '하이퍼클로바X'를 글로벌 시장에 출시한다. 한국어와 영어, 일본어를 지원하며, 기업용 AI 서비스 시장을 공략할 계획이다.",
            "content_url": "https://news.example.com/naver-hyperclova",
            "source": "디지털타임스",
            "published_date": "2025-01-24T15:00:00"
        },
        {
            "company_name": "카카오",
            "title": "카카오뱅크, 2024년 당기순이익 5000억원 돌파",
            "content": "카카오뱅크가 2024년 당기순이익 5000억원을 돌파하며 흑자 기조를 이어갔다. 대출 자산의 질적 개선과 수수료 수익 증가가 실적 향상의 주요 요인으로 꼽힌다.",
            "content_url": "https://news.example.com/kakaobank-profit",
            "source": "이데일리",
            "published_date": "2025-01-19T09:30:00"
        },
        {
            "company_name": "셀트리온",
            "title": "셀트리온, 바이오시밀러 신약 FDA 승인 획득",
            "content": "셀트리온이 개발한 자가면역질환 치료제 바이오시밀러가 미국 FDA 승인을 받았다. 연간 1조원 규모의 시장 진출이 가능해져 매출 성장이 기대된다.",
            "content_url": "https://news.example.com/celltrion-fda",
            "source": "머니투데이",
            "published_date": "2025-01-18T16:20:00"
        }
    ]
    
    # Save to file
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(sample_news, f, ensure_ascii=False, indent=2)
    
    logger.info(f"Created sample news data file: {output_path}")
    logger.info(f"Total news items: {len(sample_news)}")
    
    return len(sample_news)


async def import_news_from_file(file_path: str):
    """Import news from JSON file"""
    
    # Initialize services
    chromadb_client = get_chromadb_client()
    embedding_client = EmbeddingClient()
    news_service = NewsService(chromadb_client, embedding_client)
    
    # Check if file exists
    if not Path(file_path).exists():
        raise FileNotFoundError(f"News file not found: {file_path}")
    
    async with AsyncSessionLocal() as db:
        try:
            result = await news_service.index_news_from_file(file_path, db)
            return result
        except Exception as e:
            logger.error(f"Error importing news: {str(e)}")
            raise


async def verify_imported_news():
    """Verify imported news in the database"""
    from app.models.news import News
    from sqlalchemy import select, func
    
    async with AsyncSessionLocal() as db:
        # Count total news
        count_result = await db.execute(select(func.count(News.id)))
        total_news = count_result.scalar()
        
        # Get news statistics by company
        stats_result = await db.execute(
            select(
                News.company_name,
                func.count(News.id).label('count'),
                func.min(News.published_date).label('oldest'),
                func.max(News.published_date).label('newest')
            ).group_by(News.company_name)
        )
        
        stats = stats_result.all()
        
        # Get recent news
        recent_result = await db.execute(
            select(News)
            .order_by(News.published_date.desc())
            .limit(5)
        )
        recent_news = recent_result.scalars().all()
        
        return {
            "total_news": total_news,
            "by_company": [
                {
                    "company": stat.company_name,
                    "count": stat.count,
                    "date_range": f"{stat.oldest.date() if stat.oldest else 'N/A'} ~ {stat.newest.date() if stat.newest else 'N/A'}"
                }
                for stat in stats
            ],
            "recent_news": [
                {
                    "title": news.title,
                    "company": news.company_name,
                    "date": news.published_date.strftime("%Y-%m-%d") if news.published_date else "N/A"
                }
                for news in recent_news
            ]
        }


async def main():
    """Main function"""
    parser = argparse.ArgumentParser(description="Import news data")
    parser.add_argument(
        "--file",
        help="JSON file containing news data"
    )
    parser.add_argument(
        "--create-sample",
        action="store_true",
        help="Create sample news data file"
    )
    parser.add_argument(
        "--verify",
        action="store_true",
        help="Verify imported news"
    )
    
    args = parser.parse_args()
    
    logger.info("Starting news import script...")
    
    if args.create_sample:
        # Create sample data
        sample_file = "data/sample_news.json"
        count = create_sample_news_data(sample_file)
        print(f"\n✅ Created sample news file: {sample_file}")
        print(f"   Contains {count} news items")
        print(f"\nTo import this data, run:")
        print(f"   python {sys.argv[0]} --file {sample_file}")
    
    elif args.verify:
        # Verify imported news
        logger.info("Verifying imported news...")
        stats = await verify_imported_news()
        
        print("\n=== News Database Statistics ===")
        print(f"Total news articles: {stats['total_news']}")
        
        print("\nBy Company:")
        for company_stat in stats['by_company']:
            print(f"  - {company_stat['company']}: {company_stat['count']} articles")
            print(f"    Date range: {company_stat['date_range']}")
        
        if stats['recent_news']:
            print("\nRecent Articles:")
            for i, news in enumerate(stats['recent_news'], 1):
                print(f"  {i}. [{news['date']}] {news['company']}: {news['title'][:60]}...")
    
    elif args.file:
        # Import news from file
        result = await import_news_from_file(args.file)
        
        print("\n=== Import Results ===")
        print(f"Total items in file: {result['total_items']}")
        print(f"Successfully imported: {result['indexed']}")
        print(f"Errors: {result['errors']}")
        
        if result['error_details']:
            print("\nError details:")
            for error in result['error_details'][:5]:
                print(f"  - {error}")
    
    else:
        parser.print_help()
        print("\nExamples:")
        print(f"  python {sys.argv[0]} --create-sample")
        print(f"  python {sys.argv[0]} --file data/sample_news.json")
        print(f"  python {sys.argv[0]} --verify")
    
    logger.info("Script completed!")


if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="scripts/index_documents.py">
#!/usr/bin/env python3
"""
Index financial documents into the database and vector store
"""

import asyncio
import sys
from pathlib import Path
from typing import List, Dict, Any
import argparse
from loguru import logger

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

from app.db.session import AsyncSessionLocal, engine
from app.models.base import Base
from app.services.document_service import DocumentService
from app.core.embedding_client import EmbeddingClient
from app.core.config import settings
import chromadb
from chromadb.config import Settings as ChromaSettings


async def init_database():
    """Initialize database tables"""
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    logger.info("Database tables initialized")


def get_chromadb_client() -> chromadb.Client:
    """Get ChromaDB client"""
    try:
        # For script, use HttpClient to connect to running ChromaDB
        return chromadb.HttpClient(
            host="localhost",
            port=8000,
            settings=ChromaSettings(anonymized_telemetry=False)
        )
    except Exception as e:
        logger.warning(f"Could not connect to ChromaDB server: {e}")
        # Fallback to persistent client
        return chromadb.PersistentClient(path="./chromadb_data")


async def index_documents(directory: str, company_filter: List[str] = None):
    """Index documents from directory"""
    
    # Initialize services
    chromadb_client = get_chromadb_client()
    embedding_client = EmbeddingClient()
    document_service = DocumentService(chromadb_client, embedding_client)
    
    # Get database session
    async with AsyncSessionLocal() as db:
        try:
            # Filter by company if specified
            if company_filter:
                logger.info(f"Indexing documents for companies: {company_filter}")
            else:
                logger.info(f"Indexing all documents from: {directory}")
            
            # Index documents
            result = await document_service.index_documents_from_directory(directory, db)
            
            return result
            
        except Exception as e:
            logger.error(f"Error during indexing: {str(e)}")
            raise


async def verify_indexed_documents():
    """Verify indexed documents in the database"""
    from app.models.financial_doc import FinancialDoc
    from sqlalchemy import select, func
    
    async with AsyncSessionLocal() as db:
        # Count total documents
        count_result = await db.execute(select(func.count(FinancialDoc.id)))
        total_docs = count_result.scalar()
        
        # Get document statistics by company
        stats_result = await db.execute(
            select(
                FinancialDoc.company_name,
                func.count(FinancialDoc.id).label('count'),
                func.array_agg(FinancialDoc.doc_type).label('types')
            ).group_by(FinancialDoc.company_name)
        )
        
        stats = stats_result.all()
        
        return {
            "total_documents": total_docs,
            "by_company": [
                {
                    "company": stat.company_name,
                    "count": stat.count,
                    "document_types": list(set(stat.types))
                }
                for stat in stats
            ]
        }


async def verify_vector_store():
    """Verify documents in vector store"""
    chromadb_client = get_chromadb_client()
    
    try:
        collection = chromadb_client.get_collection(name=settings.CHROMA_COLLECTION_NAME)
        count = collection.count()
        
        # Get sample
        sample = collection.peek(limit=5)
        
        return {
            "total_chunks": count,
            "sample_metadata": sample.get("metadatas", []) if sample else []
        }
    except Exception as e:
        logger.error(f"Error verifying vector store: {e}")
        return {"error": str(e)}


async def main():
    """Main function"""
    parser = argparse.ArgumentParser(description="Index financial documents")
    parser.add_argument(
        "--directory",
        default=settings.FINANCIAL_DOCS_PATH,
        help="Directory containing documents to index"
    )
    parser.add_argument(
        "--companies",
        nargs="+",
        help="Filter by specific companies"
    )
    parser.add_argument(
        "--verify",
        action="store_true",
        help="Verify indexed documents instead of indexing"
    )
    parser.add_argument(
        "--init-db",
        action="store_true",
        help="Initialize database tables"
    )
    
    args = parser.parse_args()
    
    logger.info("Starting document indexing script...")
    
    # Initialize database if requested
    if args.init_db:
        await init_database()
    
    if args.verify:
        # Verify mode
        logger.info("Verifying indexed documents...")
        
        db_stats = await verify_indexed_documents()
        vector_stats = await verify_vector_store()
        
        print("\n=== Database Statistics ===")
        print(f"Total documents: {db_stats['total_documents']}")
        print("\nBy Company:")
        for company_stat in db_stats['by_company']:
            print(f"  - {company_stat['company']}: {company_stat['count']} documents")
            print(f"    Types: {', '.join(company_stat['document_types'])}")
        
        print("\n=== Vector Store Statistics ===")
        if "error" in vector_stats:
            print(f"Error: {vector_stats['error']}")
        else:
            print(f"Total chunks: {vector_stats['total_chunks']}")
            if vector_stats['sample_metadata']:
                print("\nSample entries:")
                for i, meta in enumerate(vector_stats['sample_metadata'][:3]):
                    print(f"  {i+1}. Company: {meta.get('company')}, "
                          f"Year: {meta.get('year')}, "
                          f"Type: {meta.get('doc_type')}")
    
    else:
        # Index mode
        result = await index_documents(args.directory, args.companies)
        
        print("\n=== Indexing Results ===")
        print(f"Total files found: {result['total_files']}")
        print(f"Successfully indexed: {result['indexed']}")
        print(f"Errors: {result['errors']}")
        
        if result['error_details']:
            print("\nError details:")
            for error in result['error_details'][:5]:  # Show first 5 errors
                print(f"  - {error}")
    
    logger.info("Script completed!")


if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="scripts/init_database.py">
#!/usr/bin/env python3
"""
Database initialization script
Creates tables and sample data for testing
"""

import os
import sys
from pathlib import Path
from datetime import datetime, timedelta
import random

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent))

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from app.models.base import Base
from app.models.user import User
from app.models.financial_doc import FinancialDoc
from app.models.news import News
from app.models.chat_history import ChatHistory
from app.core.config import get_settings
from app.core.security import get_password_hash

settings = get_settings()

# Sample company names
SAMPLE_COMPANIES = [
    "마인이스", "우나스텔라", "설로인"
]

# Document types
DOC_TYPES = ["사업보고서", "반기보고서", "분기보고서"]


def create_database():
    """Create database if it doesn't exist"""
    # Create engine without database name
    engine_url = settings.DATABASE_URL.rsplit('/', 1)[0]
    engine = create_engine(engine_url)
    
    try:
        with engine.connect() as conn:
            # Check if database exists
            result = conn.execute(
                text("SELECT 1 FROM pg_database WHERE datname = 'portfolio_qa'")
            )
            if not result.fetchone():
                # Create database
                conn.execute(text("COMMIT"))
                conn.execute(text("CREATE DATABASE portfolio_qa"))
                print("✅ Database 'portfolio_qa' created")
            else:
                print("ℹ️  Database 'portfolio_qa' already exists")
    except Exception as e:
        print(f"⚠️  Could not create database: {e}")
        print("   Please ensure PostgreSQL is running")


def init_tables():
    """Initialize all tables"""
    engine = create_engine(settings.DATABASE_URL)
    
    # Create all tables
    Base.metadata.create_all(bind=engine)
    print("✅ All tables created")
    
    return engine


def create_sample_data(engine):
    """Create sample data for testing"""
    Session = sessionmaker(bind=engine)
    session = Session()
    
    try:
        # Check if data already exists
        if session.query(User).count() > 0:
            print("ℹ️  Sample data already exists. Skipping...")
            return
        
        # 1. Create sample users
        print("Creating sample users...")
        users = [
            User(
                email="admin@example.com",
                name="관리자",
                password_hash=get_password_hash("admin123"),
                is_active=True
            ),
            User(
                email="user@example.com",
                name="일반사용자",
                password_hash=get_password_hash("user123"),
                is_active=True
            )
        ]
        session.add_all(users)
        session.commit()
        print(f"✅ Created {len(users)} users")
        
        # 2. Create sample financial documents
        print("Creating sample financial documents...")
        docs = []
        for company in SAMPLE_COMPANIES:  # All companies
            for year in [2023, 2024]:
                for doc_type in DOC_TYPES:
                    if doc_type == "사업보고서":
                        # Annual report - no quarter
                        doc = FinancialDoc(
                            company_name=company,
                            doc_type=doc_type,
                            year=year,
                            file_path=f"data/financial_docs/{company}/{year}/{company}_{doc_type}_{year}.pdf",
                            file_size=random.randint(1000000, 10000000)  # 1-10MB
                        )
                        docs.append(doc)
                    else:
                        # Quarterly reports
                        for quarter in [1, 2]:
                            doc = FinancialDoc(
                                company_name=company,
                                doc_type=doc_type,
                                year=year,
                                quarter=quarter,
                                file_path=f"data/financial_docs/{company}/{year}/{company}_{doc_type}_{year}_Q{quarter}.pdf",
                                file_size=random.randint(500000, 5000000)  # 0.5-5MB
                            )
                            docs.append(doc)
        
        session.add_all(docs)
        session.commit()
        print(f"✅ Created {len(docs)} financial documents")
        
        # 3. Create sample news
        print("Creating sample news articles...")
        news_items = []
        news_titles = [
            "{company}, 역대 최대 실적 달성",
            "{company}, 신규 사업 진출 발표",
            "{company}, 해외 시장 공략 본격화",
            "{company}, ESG 경영 강화 선언",
            "{company}, 기술 혁신으로 시장 선도"
        ]
        
        for company in SAMPLE_COMPANIES:
            for i in range(10):  # 10 news per company
                days_ago = random.randint(1, 30)
                news = News(
                    company_name=company,
                    title=random.choice(news_titles).format(company=company),
                    content=f"{company}의 최근 소식입니다. 상세 내용은 다음과 같습니다...",
                    content_url=f"https://news.example.com/{company}/{i}",
                    source=random.choice(["한국경제", "매일경제", "조선일보", "연합뉴스"]),
                    published_date=datetime.now() - timedelta(days=days_ago)
                )
                news_items.append(news)
        
        session.add_all(news_items)
        session.commit()
        print(f"✅ Created {len(news_items)} news articles")
        
        # 4. Create sample chat history
        print("Creating sample chat history...")
        sample_questions = [
            "마인이스의 2024년 매출은 얼마인가요?",
            "우나스텔라의 최근 실적은 어떤가요?",
            "설로인의 주요 사업은 무엇인가요?",
            "마인이스의 성장 전략은?",
            "우나스텔라의 ESG 활동 내역을 알려주세요"
        ]
        
        chats = []
        for i, question in enumerate(sample_questions):
            chat = ChatHistory(
                user_id=users[0].id,  # Admin user
                question=question,
                answer=f"이것은 '{question}'에 대한 샘플 답변입니다.",
                context={
                    "sources": ["sample_doc_1.pdf", "sample_doc_2.pdf"],
                    "confidence": 0.85
                }
            )
            chats.append(chat)
        
        session.add_all(chats)
        session.commit()
        print(f"✅ Created {len(chats)} chat history entries")
        
        print("\n✅ All sample data created successfully!")
        
    except Exception as e:
        session.rollback()
        print(f"❌ Error creating sample data: {e}")
        raise
    finally:
        session.close()


def create_directory_structure():
    """Create directory structure for sample companies"""
    print("\nCreating directory structure...")
    
    for company in SAMPLE_COMPANIES:
        for year in [2023, 2024]:
            dir_path = Path(f"data/financial_docs/{company}/{year}")
            dir_path.mkdir(parents=True, exist_ok=True)
    
    print("✅ Directory structure created")


def main():
    """Main initialization function"""
    print("🚀 Starting database initialization...\n")
    
    # Create database
    create_database()
    
    # Initialize tables
    engine = init_tables()
    
    # Create sample data
    create_sample_data(engine)
    
    # Create directory structure
    create_directory_structure()
    
    print("\n✅ Database initialization completed!")
    print("\n📌 Next steps:")
    print("1. Place your PDF files in: data/financial_docs/{company}/{year}/")
    print("2. Run the document indexing script: python scripts/index_documents.py")
    print("3. Start the backend server: python -m uvicorn app.main:app --reload")


if __name__ == "__main__":
    main()
</file>

<file path="scripts/init_db.py">
#!/usr/bin/env python3
"""
Initialize the SQLite database with tables and sample data
"""

import sys
import os
from pathlib import Path
import logging

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

from sqlalchemy import create_engine
from app.db.session import Base, engine
from app.models.financial_doc import FinancialDoc
from app.models.chat_history import ChatHistory
from app.models.portfolio_company import PortfolioCompany
from app.models.news_article import NewsArticle
from app.core.config import settings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def init_database():
    """Initialize database with tables"""
    try:
        # Create data directory if it doesn't exist
        data_dir = Path("data")
        data_dir.mkdir(exist_ok=True)
        
        logger.info(f"Creating database at: {settings.DATABASE_URL}")
        
        # Create all tables
        Base.metadata.create_all(bind=engine)
        
        logger.info("Database tables created successfully!")
        
        # Add sample portfolio companies
        from sqlalchemy.orm import Session
        
        with Session(engine) as session:
            # Check if companies already exist
            existing = session.query(PortfolioCompany).first()
            if not existing:
                companies = [
                    PortfolioCompany(
                        name="마인이스",
                        industry="제조업",
                        description="첨단 소재 제조 기업",
                        website="https://mines.co.kr"
                    ),
                    PortfolioCompany(
                        name="우나스텔라",
                        industry="IT/소프트웨어",
                        description="AI 및 빅데이터 솔루션 기업",
                        website="https://unastella.com"
                    ),
                    PortfolioCompany(
                        name="설로인",
                        industry="바이오/헬스케어",
                        description="바이오 신약 개발 기업",
                        website="https://sulloin.com"
                    )
                ]
                
                session.add_all(companies)
                session.commit()
                logger.info(f"Added {len(companies)} portfolio companies")
            
            # Scan and add financial documents
            docs_path = Path("data/financial_docs")
            if docs_path.exists():
                added_docs = 0
                for company_dir in docs_path.iterdir():
                    if company_dir.is_dir():
                        company_name = company_dir.name
                        
                        for pdf_file in company_dir.glob("*.pdf"):
                            # Check if document already exists
                            existing_doc = session.query(FinancialDoc).filter_by(
                                file_path=str(pdf_file)
                            ).first()
                            
                            if not existing_doc:
                                # Parse filename to extract year and doc type
                                filename = pdf_file.stem
                                parts = filename.split("_")
                                
                                if len(parts) >= 3:
                                    year = int(parts[1])
                                    doc_type = parts[2]
                                else:
                                    # Fallback parsing
                                    year = 2024
                                    doc_type = "재무제표"
                                
                                doc = FinancialDoc(
                                    company_name=company_name,
                                    year=year,
                                    doc_type=doc_type,
                                    file_path=str(pdf_file),
                                    file_size=pdf_file.stat().st_size
                                )
                                session.add(doc)
                                added_docs += 1
                
                session.commit()
                if added_docs > 0:
                    logger.info(f"Added {added_docs} financial documents")
        
        logger.info("Database initialization completed!")
        
    except Exception as e:
        logger.error(f"Error initializing database: {e}")
        raise


if __name__ == "__main__":
    init_database()
</file>

<file path="scripts/organize_documents.py">
#!/usr/bin/env python3
"""
문서 파일 정리 및 메타데이터 추출 스크립트
- 업로드된 파일들의 이름을 분석하여 정리
- 데이터베이스에 메타데이터 저장
"""

import os
import sys
import re
import shutil
from pathlib import Path
from datetime import datetime
import hashlib

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent))

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.models.financial_doc import FinancialDoc

# SQLite를 사용한 간단한 설정
DATABASE_URL = "sqlite:///./portfolio_qa.db"


class DocumentOrganizer:
    """문서 파일 정리 및 분석 클래스"""
    
    def __init__(self):
        self.base_path = Path("data/financial_docs")
        self.engine = create_engine(DATABASE_URL)
        self.Session = sessionmaker(bind=self.engine)
        
        # 테이블 생성 (없을 경우)
        from app.models.base import Base
        Base.metadata.create_all(bind=self.engine)
        
        # 문서 타입 매핑
        self.doc_type_patterns = {
            "사업보고서": ["사업보고서", "annual", "연간"],
            "분기보고서": ["분기", "quarter", r"\dQ", "1Q", "2Q", "3Q", "4Q"],
            "반기보고서": ["반기", "half"],
            "재무제표": ["재무제표", "financial", "가결산"],
        }
        
    def analyze_filename(self, filename):
        """파일명 분석하여 메타데이터 추출"""
        metadata = {
            "doc_type": None,
            "year": None,
            "quarter": None,
            "original_filename": filename
        }
        
        # 연도 추출 (2023, 2024, 23, 24 등)
        year_patterns = [
            r"20(\d{2})",  # 2023, 2024
            r"(\d{2})년",   # 23년, 24년
            r"_(\d{2})\.",  # _23., _24.
            r"(\d{4})\.?(?:12|Q|q)",  # 202312, 2024Q
        ]
        
        for pattern in year_patterns:
            match = re.search(pattern, filename)
            if match:
                year_str = match.group(1)
                if len(year_str) == 2:
                    metadata["year"] = 2000 + int(year_str)
                else:
                    metadata["year"] = int(year_str)
                break
        
        # 문서 타입 추출
        filename_lower = filename.lower()
        for doc_type, patterns in self.doc_type_patterns.items():
            for pattern in patterns:
                if isinstance(pattern, str):
                    if pattern.lower() in filename_lower:
                        metadata["doc_type"] = doc_type
                        break
                else:  # regex pattern
                    if re.search(pattern, filename, re.IGNORECASE):
                        metadata["doc_type"] = doc_type
                        break
            if metadata["doc_type"]:
                break
        
        # 분기 추출
        quarter_match = re.search(r"(\d)[Qq]|Q(\d)|(\d)분기", filename)
        if quarter_match:
            quarter_num = quarter_match.group(1) or quarter_match.group(2) or quarter_match.group(3)
            metadata["quarter"] = int(quarter_num)
        
        # 4Q가 있으면 사업보고서로 분류
        if "4Q" in filename or "4q" in filename:
            metadata["doc_type"] = "사업보고서"
            metadata["quarter"] = None
        
        return metadata
    
    def generate_new_filename(self, company, metadata):
        """표준화된 파일명 생성"""
        year = metadata["year"]
        doc_type = metadata["doc_type"] or "기타문서"
        quarter = metadata["quarter"]
        
        if quarter and doc_type != "사업보고서":
            new_name = f"{company}_{year}_Q{quarter}_{doc_type}.pdf"
        else:
            new_name = f"{company}_{year}_{doc_type}.pdf"
        
        return new_name
    
    def calculate_file_hash(self, filepath):
        """파일 해시 계산"""
        hash_md5 = hashlib.md5()
        with open(filepath, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def process_company_documents(self, company_name):
        """특정 회사의 문서들 처리"""
        company_path = self.base_path / company_name
        if not company_path.exists():
            print(f"⚠️  {company_name} 폴더가 없습니다.")
            return
        
        print(f"\n📁 {company_name} 문서 처리 중...")
        processed = 0
        
        session = self.Session()
        
        try:
            # 모든 PDF 파일 찾기
            for year_dir in company_path.iterdir():
                if not year_dir.is_dir():
                    continue
                    
                year = year_dir.name
                
                for file_path in year_dir.glob("*.[pP][dD][fF]"):
                    print(f"\n  파일: {file_path.name}")
                    
                    # 파일명 분석
                    metadata = self.analyze_filename(file_path.name)
                    
                    # 연도가 파일명에서 추출되지 않으면 폴더명 사용
                    if not metadata["year"]:
                        try:
                            metadata["year"] = int(year)
                        except ValueError:
                            print(f"    ⚠️  연도를 확인할 수 없습니다: {year}")
                            continue
                    
                    print(f"    분석 결과: 연도={metadata['year']}, "
                          f"타입={metadata['doc_type']}, 분기={metadata['quarter']}")
                    
                    # 새 파일명 생성
                    new_filename = self.generate_new_filename(company_name, metadata)
                    new_path = file_path.parent / new_filename
                    
                    # 파일명 변경 (필요한 경우)
                    if file_path.name != new_filename:
                        if new_path.exists():
                            print(f"    ⚠️  대상 파일이 이미 존재합니다: {new_filename}")
                        else:
                            shutil.move(str(file_path), str(new_path))
                            print(f"    ✅ 파일명 변경: {file_path.name} → {new_filename}")
                            file_path = new_path
                    
                    # DB에 저장
                    existing = session.query(FinancialDoc).filter_by(
                        company_name=company_name,
                        year=metadata["year"],
                        doc_type=metadata["doc_type"],
                        quarter=metadata["quarter"]
                    ).first()
                    
                    if existing:
                        print(f"    ℹ️  이미 DB에 등록되어 있습니다.")
                    else:
                        # 파일 정보 수집
                        file_size = file_path.stat().st_size
                        file_hash = self.calculate_file_hash(file_path)
                        # 프로젝트 루트 기준 상대 경로
                        relative_path = str(file_path).replace(str(Path.cwd()) + "/", "")
                        
                        doc = FinancialDoc(
                            company_name=company_name,
                            doc_type=metadata["doc_type"] or "기타문서",
                            year=metadata["year"],
                            quarter=metadata["quarter"],
                            file_path=str(relative_path),
                            file_size=file_size,
                            # file_hash=file_hash  # 모델에 추가 필요시
                        )
                        
                        session.add(doc)
                        print(f"    ✅ DB에 등록되었습니다.")
                    
                    processed += 1
            
            session.commit()
            print(f"\n✅ {company_name}: {processed}개 파일 처리 완료")
            
        except Exception as e:
            session.rollback()
            print(f"\n❌ 오류 발생: {e}")
            raise
        finally:
            session.close()
    
    def process_excel_files(self):
        """엑셀 파일 처리 (별도 폴더로 이동)"""
        excel_dir = self.base_path.parent / "excel_files"
        excel_dir.mkdir(exist_ok=True)
        
        moved = 0
        for company_path in self.base_path.iterdir():
            if not company_path.is_dir():
                continue
                
            for excel_file in company_path.rglob("*.xlsx"):
                target = excel_dir / company_path.name / excel_file.parent.name / excel_file.name
                target.parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(excel_file), str(target))
                print(f"  📊 엑셀 파일 이동: {excel_file} → {target}")
                moved += 1
        
        if moved > 0:
            print(f"\n✅ {moved}개 엑셀 파일을 별도 폴더로 이동했습니다.")
    
    def run(self):
        """전체 문서 정리 프로세스 실행"""
        print("🚀 문서 정리 및 DB 등록 시작...\n")
        
        # 엑셀 파일 별도 처리
        self.process_excel_files()
        
        # 각 회사별 처리
        companies = ["마인이스", "설로인", "우나스텔라"]
        for company in companies:
            self.process_company_documents(company)
        
        print("\n✅ 모든 문서 정리 완료!")
        print("\n📌 다음 단계:")
        print("1. 문서 인덱싱: python scripts/index_documents.py")
        print("2. 서버 실행: python test_server.py")


def main():
    """메인 함수"""
    organizer = DocumentOrganizer()
    organizer.run()


if __name__ == "__main__":
    main()
</file>

<file path="scripts/populate_test_data.py">
"""
Populate test data for development
"""
import sys
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.db.session import SessionLocal
from app.models.financial_doc import FinancialDoc
from loguru import logger

def populate_test_documents():
    """Populate test documents in database"""
    db = SessionLocal()
    
    try:
        # Check if documents already exist
        existing_count = db.query(FinancialDoc).count()
        if existing_count > 0:
            logger.info(f"Database already has {existing_count} documents")
            return
        
        # Test documents
        test_docs = [
            {
                "company_name": "마인이스",
                "doc_type": "사업보고서",
                "year": 2024,
                "file_path": "data/financial_docs/마인이스_2024_사업보고서.pdf",
                "file_size": 1024000
            },
            {
                "company_name": "우나스텔라",
                "doc_type": "사업보고서", 
                "year": 2024,
                "file_path": "data/financial_docs/우나스텔라_2024_사업보고서.pdf",
                "file_size": 2048000
            },
            {
                "company_name": "설로인",
                "doc_type": "사업보고서",
                "year": 2024,
                "file_path": "data/financial_docs/설로인_2024_사업보고서.pdf",
                "file_size": 1536000
            }
        ]
        
        # Insert test documents
        for doc_data in test_docs:
            doc = FinancialDoc(**doc_data)
            db.add(doc)
        
        db.commit()
        logger.info(f"Successfully added {len(test_docs)} test documents")
        
    except Exception as e:
        logger.error(f"Error populating test data: {e}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    populate_test_documents()
</file>

<file path="scripts/setup_file_system.py">
#!/usr/bin/env python3
"""
Setup file system structure for financial documents
"""

import os
import sys
from pathlib import Path
from datetime import datetime
import json
from loguru import logger

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

from app.core.config import settings


def create_file_structure():
    """Create the required directory structure for document storage"""
    
    base_path = Path(settings.DATA_PATH)
    financial_docs_path = Path(settings.FINANCIAL_DOCS_PATH)
    cache_path = Path(settings.CACHE_PATH)
    
    # Create main directories
    directories = [
        base_path,
        financial_docs_path,
        cache_path,
        cache_path / "embeddings"
    ]
    
    # Create sample company directories
    sample_companies = [
        "삼성전자", "LG전자", "SK하이닉스", "현대자동차", "POSCO",
        "네이버", "카카오", "셀트리온", "삼성바이오로직스", "현대모비스"
    ]
    
    for company in sample_companies:
        company_path = financial_docs_path / company
        directories.append(company_path)
        
        # Create year directories (2022-2024)
        for year in range(2022, 2025):
            year_path = company_path / str(year)
            directories.append(year_path)
    
    # Create all directories
    created_count = 0
    for directory in directories:
        if not directory.exists():
            directory.mkdir(parents=True, exist_ok=True)
            logger.info(f"Created directory: {directory}")
            created_count += 1
        else:
            logger.info(f"Directory already exists: {directory}")
    
    # Create metadata file
    metadata_file = base_path / "metadata.json"
    if not metadata_file.exists():
        metadata = {
            "created_at": datetime.now().isoformat(),
            "version": "1.0",
            "companies": sample_companies,
            "document_types": ["사업보고서", "반기보고서", "분기보고서"],
            "years": list(range(2022, 2025))
        }
        
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Created metadata file: {metadata_file}")
    
    return {
        "directories_created": created_count,
        "total_directories": len(directories),
        "base_path": str(base_path),
        "companies": sample_companies
    }


def create_sample_documents():
    """Create sample PDF placeholder files for testing"""
    
    financial_docs_path = Path(settings.FINANCIAL_DOCS_PATH)
    
    # Sample document templates
    doc_templates = [
        {"type": "사업보고서", "filename": "annual_report_{year}.pdf"},
        {"type": "반기보고서", "filename": "half_year_report_{year}.pdf"},
        {"type": "1분기보고서", "filename": "Q1_report_{year}.pdf"},
        {"type": "3분기보고서", "filename": "Q3_report_{year}.pdf"}
    ]
    
    sample_companies = ["삼성전자", "LG전자", "SK하이닉스"]
    created_files = []
    
    for company in sample_companies:
        for year in [2023, 2024]:
            for template in doc_templates:
                # Skip quarters for 2024 if it's early in the year
                if year == 2024 and template["type"] not in ["사업보고서", "1분기보고서"]:
                    continue
                
                filename = template["filename"].format(year=year)
                file_path = financial_docs_path / company / str(year) / filename
                
                # Create a placeholder text file (in real scenario, these would be PDFs)
                if not file_path.exists():
                    file_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # Create sample content
                    content = f"""
{company} {year}년 {template['type']}

1. 회사 개요
- 회사명: {company}
- 보고서 유형: {template['type']}
- 회계연도: {year}

2. 주요 재무 정보
- 매출액: {1234 * (year - 2020)}억원
- 영업이익: {123 * (year - 2020)}억원
- 당기순이익: {100 * (year - 2020)}억원

3. 주요 사업 현황
- 주력 제품 매출 성장
- 신규 사업 진출
- R&D 투자 확대

(이것은 테스트를 위한 샘플 문서입니다)
"""
                    
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    created_files.append(str(file_path))
                    logger.info(f"Created sample file: {file_path}")
    
    return created_files


def main():
    """Main function"""
    logger.info("Starting file system setup...")
    
    # Create directory structure
    result = create_file_structure()
    logger.info(f"Directory structure created: {result}")
    
    # Create sample documents
    if "--with-samples" in sys.argv:
        logger.info("Creating sample documents...")
        sample_files = create_sample_documents()
        logger.info(f"Created {len(sample_files)} sample files")
    
    logger.info("File system setup completed!")
    
    # Print summary
    print("\n=== File System Setup Summary ===")
    print(f"Base path: {result['base_path']}")
    print(f"Directories created: {result['directories_created']}")
    print(f"Total directories: {result['total_directories']}")
    print(f"Companies configured: {', '.join(result['companies'][:5])}...")
    print("\nTo create sample documents, run with --with-samples flag")


if __name__ == "__main__":
    main()
</file>

<file path="scripts/setup_sample_files.py">
#!/usr/bin/env python3
"""
Setup sample PDF files for testing
Creates dummy PDF files or downloads sample files
"""

import os
import sys
from pathlib import Path
from datetime import datetime
import requests
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent))

# Sample companies
SAMPLE_COMPANIES = ["마인이스", "우나스텔라", "설로인"]


def create_sample_pdf(filepath, company, doc_type, year, quarter=None):
    """Create a sample PDF with Korean financial report content"""
    doc = SimpleDocTemplate(str(filepath), pagesize=letter)
    story = []
    styles = getSampleStyleSheet()
    
    # Custom Korean style
    korean_style = ParagraphStyle(
        'Korean',
        parent=styles['Normal'],
        fontName='Helvetica',  # In production, use Korean font
        fontSize=12,
        leading=18
    )
    
    title_style = ParagraphStyle(
        'KoreanTitle',
        parent=styles['Title'],
        fontName='Helvetica-Bold',
        fontSize=20,
        leading=24,
        alignment=1  # Center
    )
    
    # Title
    if quarter:
        title = f"{company} {year}년 {quarter}분기 {doc_type}"
    else:
        title = f"{company} {year}년 {doc_type}"
    
    story.append(Paragraph(title, title_style))
    story.append(Spacer(1, 0.5*inch))
    
    # Company info
    story.append(Paragraph(f"<b>회사명:</b> {company}", korean_style))
    story.append(Paragraph(f"<b>보고서 유형:</b> {doc_type}", korean_style))
    story.append(Paragraph(f"<b>회계연도:</b> {year}년", korean_style))
    if quarter:
        story.append(Paragraph(f"<b>분기:</b> {quarter}분기", korean_style))
    story.append(Spacer(1, 0.3*inch))
    
    # Sample financial data table
    story.append(Paragraph("<b>주요 재무 현황</b>", korean_style))
    story.append(Spacer(1, 0.2*inch))
    
    # Create sample financial data
    data = [
        ['항목', '당기', '전기', '증감률'],
        ['매출액', '80,123', '75,432', '+6.2%'],
        ['영업이익', '12,345', '11,234', '+9.9%'],
        ['당기순이익', '9,876', '8,765', '+12.7%'],
        ['자산총계', '150,000', '140,000', '+7.1%'],
        ['부채총계', '50,000', '48,000', '+4.2%'],
        ['자본총계', '100,000', '92,000', '+8.7%']
    ]
    
    # Create table
    table = Table(data, colWidths=[2*inch, 1.5*inch, 1.5*inch, 1*inch])
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    
    story.append(table)
    story.append(Spacer(1, 0.3*inch))
    
    # Add sample text content
    story.append(Paragraph("<b>사업 개요</b>", korean_style))
    story.append(Paragraph(
        f"{company}는 대한민국을 대표하는 기업으로, 지속적인 혁신과 성장을 통해 "
        f"글로벌 시장에서 경쟁력을 강화하고 있습니다. {year}년에는 특히 "
        f"신사업 분야에서 괄목할만한 성과를 달성하였으며, ESG 경영을 통해 "
        f"지속가능한 성장 기반을 마련하였습니다.",
        korean_style
    ))
    story.append(Spacer(1, 0.2*inch))
    
    # Footer
    story.append(Spacer(1, 1*inch))
    story.append(Paragraph(
        f"본 문서는 테스트용 샘플 문서입니다. 실제 {company}의 {doc_type}가 아닙니다.",
        ParagraphStyle('Footer', parent=korean_style, fontSize=10, textColor=colors.grey)
    ))
    
    # Build PDF
    doc.build(story)
    print(f"✅ Created: {filepath}")


def setup_sample_pdfs():
    """Create sample PDF files for testing"""
    print("📄 Creating sample PDF files...")
    
    # Ensure reportlab is installed
    try:
        import reportlab
    except ImportError:
        print("Installing reportlab for PDF generation...")
        os.system(f"{sys.executable} -m pip install reportlab")
    
    created_count = 0
    
    for company in SAMPLE_COMPANIES:
        for year in [2023, 2024]:
            # Annual report
            dir_path = Path(f"data/financial_docs/{company}/{year}")
            dir_path.mkdir(parents=True, exist_ok=True)
            
            # Create annual report
            filepath = dir_path / f"{company}_{year}_사업보고서.pdf"
            if not filepath.exists():
                create_sample_pdf(filepath, company, "사업보고서", year)
                created_count += 1
            
            # Create quarterly reports
            for quarter in [1, 2]:
                for doc_type in ["분기보고서", "반기보고서"]:
                    if doc_type == "반기보고서" and quarter != 2:
                        continue  # 반기보고서는 2분기만
                    
                    filename = f"{company}_{year}_Q{quarter}_{doc_type}.pdf"
                    filepath = dir_path / filename
                    if not filepath.exists():
                        create_sample_pdf(filepath, company, doc_type, year, quarter)
                        created_count += 1
    
    print(f"\n✅ Created {created_count} sample PDF files")
    print(f"📁 Files location: data/financial_docs/")
    
    # Create a README in the data directory
    readme_content = """# Sample Data Directory

This directory contains sample PDF files for testing the Q&A chatbot.

## Structure:
```
data/
├── financial_docs/
│   ├── 삼성전자/
│   │   ├── 2023/
│   │   │   ├── 삼성전자_2023_사업보고서.pdf
│   │   │   ├── 삼성전자_2023_Q1_분기보고서.pdf
│   │   │   └── ...
│   │   └── 2024/
│   └── ...
└── news_attachments/
```

## Adding Real Documents:
1. Replace the sample PDFs with actual financial reports
2. Maintain the same directory structure
3. Run the indexing script: `python scripts/index_documents.py`

## Note:
These are dummy PDFs created for testing purposes only.
They do not contain actual financial data.
"""
    
    readme_path = Path("data/README.md")
    readme_path.write_text(readme_content, encoding='utf-8')
    print("📝 Created data/README.md")


def main():
    """Main function"""
    print("🚀 Setting up sample files...\n")
    
    # Check if reportlab is available
    try:
        import reportlab
        setup_sample_pdfs()
    except ImportError:
        print("⚠️  reportlab not found. Installing...")
        os.system(f"{sys.executable} -m pip install reportlab")
        setup_sample_pdfs()
    
    print("\n✅ Sample file setup completed!")
    print("\n📌 Next steps:")
    print("1. Review the generated PDFs in data/financial_docs/")
    print("2. Replace with actual financial documents when available")
    print("3. Run document indexing: python scripts/index_documents.py")


if __name__ == "__main__":
    main()
</file>

<file path="scripts/test_claude_api.py">
#!/usr/bin/env python3
"""
Test Claude API integration
"""

import asyncio
import sys
from pathlib import Path
import argparse
from loguru import logger
from typing import List, Dict

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

from app.core.llm_client import LLMClient
from app.core.config import settings


async def test_basic_completion():
    """Test basic text completion"""
    client = LLMClient()
    
    test_prompts = [
        {
            "prompt": "한국의 수도는 어디인가요?",
            "type": "simple_lookup",
            "expected": "서울"
        },
        {
            "prompt": "삼성전자의 2023년 매출액이 300조원이었다면, 영업이익률 10%일 때 영업이익은 얼마인가요?",
            "type": "simple_lookup",
            "expected": "30조원"
        },
        {
            "prompt": "반도체 산업의 최근 동향과 향후 전망에 대해 간단히 설명해주세요.",
            "type": "standard",
            "expected": "반도체"
        }
    ]
    
    results = []
    
    for test in test_prompts:
        logger.info(f"Testing prompt: {test['prompt'][:50]}...")
        
        try:
            response = await client.generate_text(
                prompt=test['prompt'],
                question_type=test['type'],
                max_tokens=500,
                temperature=0.3
            )
            
            success = test['expected'].lower() in response.lower()
            
            results.append({
                "prompt": test['prompt'],
                "type": test['type'],
                "response": response[:200] + "..." if len(response) > 200 else response,
                "success": success,
                "error": None
            })
            
            logger.info(f"Response received: {'✅' if success else '❌'}")
            
        except Exception as e:
            results.append({
                "prompt": test['prompt'],
                "type": test['type'],
                "response": None,
                "success": False,
                "error": str(e)
            })
            logger.error(f"Error: {str(e)}")
    
    return results


async def test_document_analysis():
    """Test document analysis capability"""
    client = LLMClient()
    
    # Sample financial document content
    sample_doc = """
    삼성전자 2024년 3분기 실적 발표
    
    1. 매출액: 79조원 (전년 동기 대비 12% 증가)
    2. 영업이익: 9.1조원 (영업이익률 11.5%)
    3. 당기순이익: 7.2조원
    
    주요 사업부별 실적:
    - 반도체(DS): 매출 23조원, 영업이익 3.8조원
    - 스마트폰(IM): 매출 28조원, 영업이익 2.8조원
    - 디스플레이(DP): 매출 7조원, 영업이익 0.7조원
    
    주요 성과:
    - HBM3 메모리 양산 본격화
    - 갤럭시 S24 시리즈 판매 호조
    - OLED 패널 수요 증가
    """
    
    test_questions = [
        "삼성전자의 3분기 매출액은 얼마인가요?",
        "반도체 사업부의 영업이익률을 계산해주세요.",
        "전년 대비 매출 성장률은 몇 퍼센트인가요?"
    ]
    
    results = []
    
    for question in test_questions:
        logger.info(f"Testing document analysis: {question}")
        
        try:
            result = await client.analyze_document(
                document_content=sample_doc,
                question=question,
                doc_type="financial_report"
            )
            
            results.append({
                "question": question,
                "answer": result['answer'],
                "success": True,
                "error": None
            })
            
            logger.info("Analysis completed successfully")
            
        except Exception as e:
            results.append({
                "question": question,
                "answer": None,
                "success": False,
                "error": str(e)
            })
            logger.error(f"Error: {str(e)}")
    
    return results


async def test_model_routing():
    """Test model routing logic"""
    client = LLMClient()
    
    test_cases = [
        ("simple_lookup", 0.3, "simple"),
        ("standard", 0.5, "standard"),
        ("complex_analysis", 0.8, "advanced"),
        ("simple_lookup", 0.9, "simple"),  # Simple type overrides complexity
    ]
    
    results = []
    
    for question_type, complexity, expected_tier in test_cases:
        model = client.select_model(question_type, complexity)
        
        if "haiku" in model and expected_tier == "simple":
            correct = True
        elif "sonnet" in model and expected_tier == "standard":
            correct = True
        elif "opus" in model and expected_tier == "advanced":
            correct = True
        else:
            correct = False
        
        results.append({
            "question_type": question_type,
            "complexity": complexity,
            "selected_model": model,
            "expected_tier": expected_tier,
            "correct": correct
        })
        
        logger.info(f"Model routing: {question_type}/{complexity} -> {model} {'✅' if correct else '❌'}")
    
    return results


async def test_rag_pipeline():
    """Test full RAG pipeline (requires indexed documents)"""
    from app.services.rag_pipeline import RAGPipeline
    from app.core.embedding_client import EmbeddingClient
    import chromadb
    from chromadb.config import Settings as ChromaSettings
    
    try:
        # Initialize components
        chromadb_client = chromadb.HttpClient(
            host="localhost",
            port=8000,
            settings=ChromaSettings(anonymized_telemetry=False)
        )
        llm_client = LLMClient()
        embedding_client = EmbeddingClient()
        
        rag_pipeline = RAGPipeline(chromadb_client, llm_client, embedding_client)
        
        # Test questions
        test_questions = [
            "삼성전자의 최근 매출은 얼마인가요?",
            "LG전자의 주요 사업 분야는 무엇인가요?",
            "SK하이닉스의 HBM 제품에 대해 알려주세요."
        ]
        
        results = []
        
        for question in test_questions:
            logger.info(f"Testing RAG pipeline: {question}")
            
            try:
                answer, sources = await rag_pipeline.generate_response(
                    question=question,
                    top_k=3
                )
                
                results.append({
                    "question": question,
                    "answer": answer[:200] + "..." if len(answer) > 200 else answer,
                    "sources": sources,
                    "success": True,
                    "error": None
                })
                
                logger.info(f"Found {len(sources)} sources")
                
            except Exception as e:
                results.append({
                    "question": question,
                    "answer": None,
                    "sources": [],
                    "success": False,
                    "error": str(e)
                })
                logger.error(f"Error: {str(e)}")
        
        return results
        
    except Exception as e:
        logger.error(f"Failed to initialize RAG pipeline: {str(e)}")
        return []


def print_test_results(test_name: str, results: List[Dict]):
    """Print test results in a formatted way"""
    print(f"\n{'='*60}")
    print(f" {test_name}")
    print(f"{'='*60}")
    
    if not results:
        print("No results to display")
        return
    
    success_count = sum(1 for r in results if r.get('success', False))
    total_count = len(results)
    
    print(f"Success Rate: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\n")
    
    for i, result in enumerate(results, 1):
        print(f"{i}. {'✅' if result.get('success') else '❌'} ", end="")
        
        if 'prompt' in result:
            print(f"Prompt: {result['prompt'][:60]}...")
        elif 'question' in result:
            print(f"Question: {result['question'][:60]}...")
        elif 'question_type' in result:
            print(f"Type: {result['question_type']}, Complexity: {result['complexity']}")
        
        if result.get('error'):
            print(f"   Error: {result['error']}")
        elif 'response' in result and result['response']:
            print(f"   Response: {result['response']}")
        elif 'answer' in result and result['answer']:
            print(f"   Answer: {result['answer']}")
        elif 'selected_model' in result:
            print(f"   Model: {result['selected_model']}")
        
        if 'sources' in result and result['sources']:
            print(f"   Sources: {', '.join(result['sources'][:3])}")
        
        print()


async def main():
    """Main function"""
    parser = argparse.ArgumentParser(description="Test Claude API integration")
    parser.add_argument(
        "--test",
        choices=["basic", "document", "routing", "rag", "all"],
        default="basic",
        help="Type of test to run"
    )
    
    args = parser.parse_args()
    
    print(f"\n🤖 Claude API Test Suite")
    print(f"API Key: {'✅ Configured' if settings.CLAUDE_API_KEY else '❌ Missing'}")
    
    if not settings.CLAUDE_API_KEY:
        print("\n❌ Error: CLAUDE_API_KEY not found in environment variables")
        print("Please set your Claude API key in the .env file")
        return
    
    if args.test in ["basic", "all"]:
        logger.info("Running basic completion tests...")
        results = await test_basic_completion()
        print_test_results("Basic Completion Tests", results)
    
    if args.test in ["document", "all"]:
        logger.info("Running document analysis tests...")
        results = await test_document_analysis()
        print_test_results("Document Analysis Tests", results)
    
    if args.test in ["routing", "all"]:
        logger.info("Running model routing tests...")
        results = await test_model_routing()
        print_test_results("Model Routing Tests", results)
    
    if args.test in ["rag", "all"]:
        logger.info("Running RAG pipeline tests...")
        results = await test_rag_pipeline()
        if results:
            print_test_results("RAG Pipeline Tests", results)
        else:
            print("\n⚠️  RAG pipeline tests require indexed documents.")
            print("   Run the indexing scripts first:")
            print("   1. python scripts/setup_file_system.py --with-samples")
            print("   2. python scripts/index_documents.py")
    
    print("\n✅ Test suite completed!")


if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="scripts/update_document_type.py">
#!/usr/bin/env python3
"""
문서 타입 업데이트 스크립트
"""

import os
import sys
from pathlib import Path

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent))

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.models.financial_doc import FinancialDoc

# SQLite 데이터베이스
DATABASE_URL = "sqlite:///./portfolio_qa.db"


def update_document_types():
    """마인이스 문서 타입을 재무제표로 업데이트"""
    engine = create_engine(DATABASE_URL)
    Session = sessionmaker(bind=engine)
    session = Session()
    
    try:
        # 마인이스의 기타문서를 찾아서 재무제표로 변경
        docs = session.query(FinancialDoc).filter_by(
            company_name="마인이스",
            doc_type="기타문서"
        ).all()
        
        for doc in docs:
            doc.doc_type = "재무제표"
            print(f"✅ 업데이트: {doc.company_name} {doc.year}년 - {doc.doc_type}")
        
        # 사업보고서도 재무제표로 변경
        annual_docs = session.query(FinancialDoc).filter_by(
            company_name="마인이스",
            doc_type="사업보고서"
        ).all()
        
        for doc in annual_docs:
            doc.doc_type = "재무제표"
            print(f"✅ 업데이트: {doc.company_name} {doc.year}년 - {doc.doc_type}")
        
        session.commit()
        print("\n✅ 데이터베이스 업데이트 완료!")
        
        # 파일명도 변경
        base_path = Path("data/financial_docs/마인이스")
        
        # 2023년 파일
        old_file_2023 = base_path / "2023" / "마인이스_2023_기타문서.pdf"
        new_file_2023 = base_path / "2023" / "마인이스_2023_재무제표.pdf"
        if old_file_2023.exists():
            old_file_2023.rename(new_file_2023)
            print(f"✅ 파일명 변경: {old_file_2023.name} → {new_file_2023.name}")
        
        # 2024년 파일
        old_file_2024 = base_path / "2024" / "마인이스_2024_사업보고서.pdf"
        new_file_2024 = base_path / "2024" / "마인이스_2024_재무제표.pdf"
        if old_file_2024.exists():
            old_file_2024.rename(new_file_2024)
            print(f"✅ 파일명 변경: {old_file_2024.name} → {new_file_2024.name}")
            
            # DB의 파일 경로도 업데이트
            doc_2024 = session.query(FinancialDoc).filter_by(
                company_name="마인이스",
                year=2024
            ).first()
            if doc_2024:
                doc_2024.file_path = str(new_file_2024).replace(str(Path.cwd()) + "/", "")
                session.commit()
        
        print("\n✅ 모든 업데이트 완료!")
        
        # 현재 상태 확인
        print("\n📊 현재 문서 현황:")
        all_docs = session.query(FinancialDoc).order_by(
            FinancialDoc.company_name, 
            FinancialDoc.year
        ).all()
        
        for doc in all_docs:
            print(f"  - {doc.company_name} {doc.year}년: {doc.doc_type}")
        
    except Exception as e:
        session.rollback()
        print(f"❌ 오류 발생: {e}")
    finally:
        session.close()


if __name__ == "__main__":
    update_document_types()
</file>

<file path="vooster-docs/architecture.md">
# 기술 요구사항 명세서 (TRD)

## 1. Executive Technical Summary
- **프로젝트 개요**: 본 프로젝트는 투자팀이 포트폴리오 기업(마인이스, 우나스텔라, 설로인)의 재무 정보를 신속하게 조회하고 분석할 수 있도록 지원하는 AI 기반 대화형 Q&A 챗봇을 구축하는 것을 목표로 합니다. 아키텍처는 React 프론트엔드와 FastAPI 백엔드를 중심으로 구성되며, PDF 문서를 Claude API에 직접 전송하는 심플한 방식으로 정확한 답변을 생성합니다.
- **핵심 기술 스택**: 프론트엔드는 React와 Tailwind CSS, 백엔드는 Python FastAPI를 사용합니다. 데이터 저장은 SQLite(메타데이터), Redis(캐시)를 활용하며, 핵심 AI 기능은 Anthropic의 Claude API를 통해 구현합니다.
- **주요 기술 목표**: 평균 응답 시간 3초 이내, 월 API 비용 10만원 미만, 시스템 가용성 99% 달성을 목표로 합니다. 초기에는 3개 기업의 재무제표를 대상으로 하며, 향후 필요시 확장 가능한 구조를 유지합니다.
- **핵심 기술 가정**: 사용자의 질의응답은 Claude API의 PDF 네이티브 지원 기능을 활용하여 처리되며, 전체 PDF를 직접 전송하는 방식으로 문맥 손실 없이 정확한 답변을 제공합니다. 초기 데이터(PDF)는 로컬 파일 시스템에 저장되고 메타데이터는 데이터베이스에서 관리됩니다.

## 2. 기술 스택

| 카테고리 | 기술 / 라이브러리 | 선정 사유 |
| --- | --- | --- |
| **프론트엔드** | React.js, Vite | 선언적 UI와 컴포넌트 기반 아키텍처로 복잡한 채팅 인터페이스를 효율적으로 구축할 수 있습니다. Vite는 빠른 개발 서버와 빌드 속도를 제공합니다. |
| **UI/스타일링** | Tailwind CSS | 유틸리티-우선 접근 방식으로 신속한 프로토타이핑과 일관된 디자인 시스템 적용이 용이합니다. |
| **백엔드 프레임워크** | FastAPI (Python) | 비동기 처리를 지원하여 I/O 바운드 작업(API 호출, DB 조회)이 많은 챗봇 특성에 적합하며, 자동 API 문서 생성으로 개발 생산성을 높입니다. |
| **데이터베이스 (메타데이터)** | PostgreSQL/SQLite | 문서 메타데이터를 관리하기 위한 관계형 데이터베이스입니다. 초기 개발은 SQLite로 시작하여 빠른 구축을, 프로덕션에서는 PostgreSQL로 전환하여 확장성을 확보합니다. |
| **캐시** | Redis | 인메모리 데이터 저장소로, 반복적인 API 응답과 검색 결과를 캐싱하여 시스템 응답 속도를 향상시키고 API 비용을 절감하는 데 필수적입니다. |
| **AI/LLM** | Claude 3 API | 한국어 처리 능력이 우수하고, 대용량 PDF 문서 분석에 강점을 보여 본 프로젝트의 핵심 요구사항인 문서 기반 질의응답에 가장 적합합니다. |
| **인프라/배포** | Docker, Nginx, Gunicorn | 컨테이너화를 통해 개발 및 배포 환경을 일치시키고, Nginx와 Gunicorn 조합은 안정적인 Python 웹 애플리케이션 서빙을 위한 표준 구성입니다. |

## 3. 시스템 아키텍처 설계

### 최상위 구성 요소
- **프론트엔드 (React Web UI)**: 사용자가 질문을 입력하고 답변을 확인하는 웹 기반 채팅 인터페이스입니다. API 서버와 통신하여 데이터를 주고받으며, 차트 시각화를 담당합니다.
- **웹 서버 (Nginx)**: 리버스 프록시 역할을 수행하며, 클라이언트의 요청을 백엔드 애플리케이션 서버로 전달합니다. 정적 파일 서빙 및 로드 밸런싱을 담당합니다.
- **백엔드 (FastAPI Server)**: 비즈니스 로직의 핵심으로, 사용자 요청 처리, 데이터베이스 및 외부 API 연동, PDF 직접 전송 파이프라인 실행 등 모든 서버 사이드 로직을 총괄합니다.
- **데이터 저장소**:
    - **PostgreSQL/SQLite**: 문서, 뉴스, 사용자 등의 메타데이터를 저장합니다. (초기에는 SQLite로 시작)
    - **Redis**: 자주 사용되는 데이터나 API 응답을 캐싱하여 성능을 향상시킵니다.
    - **File System**: 원본 PDF 문서 파일을 저장하고 관리합니다.
- **외부 서비스 (Claude API)**: 백엔드에서 전체 PDF와 사용자 질문을 직접 전달받아, 문서 내용을 분석하고 자연어 답변을 생성하는 핵심 LLM 서비스입니다.

### 최상위 컴포넌트 상호작용 다이어그램

```mermaid
graph TD
    subgraph 사용자 환경
        A[React 웹 UI]
    end

    subgraph 서버 인프라
        B[Nginx 리버스 프록시]
        C[FastAPI 백엔드 서버]
        D[SQLite/PostgreSQL<br/>(메타데이터)]
        E[Redis<br/>(캐시)]
        G[로컬 파일 시스템<br/>(PDF 원본)]
    end

    subgraph 외부 서비스
        H[Claude API]
    end

    A -- HTTPS --> B
    B -- HTTP --> C

    C -- PDF 직접 전송 --> H
    C -- CRUD --> D
    C -- 캐시 조회/저장 --> E
    C -- PDF 파일 읽기 --> G
```

- **사용자 요청 흐름**: 사용자는 React UI에서 질문을 입력하고, 이 요청은 Nginx를 통해 FastAPI 백엔드 서버로 전달됩니다.
- **백엔드 처리**: FastAPI 서버는 질문과 관련된 회사명을 파악하고, SQLite/PostgreSQL에서 해당 문서의 메타데이터를 조회하여 PDF 파일 경로를 확인합니다.
- **PDF 직접 전송 및 응답 생성**: 파일 시스템에서 PDF를 읽어 전체 내용을 사용자 질문과 함께 Claude API에 직접 전송합니다. Redis 캐시를 우선적으로 확인하여 동일한 질문에 대한 API 호출을 최소화합니다.
- **응답 반환**: Claude API로부터 받은 답변을 가공하여(텍스트, 출처 페이지 등) Nginx를 거쳐 React UI로 전송하여 사용자에게 표시합니다.

### 코드 구성 및 규칙
**도메인 주도 구성 전략**
- **도메인 분리**: 코드를 비즈니스 도메인(예: `chat`, `documents`, `users`, `auth`) 중심으로 구성하여 응집도를 높이고 결합도를 낮춥니다.
- **계층 기반 아키텍처**: 각 도메인 내부는 API(라우터), 서비스(비즈니스 로직), 리포지토리(데이터 접근) 계층으로 분리하여 관심사를 명확히 합니다.
- **공유 컴포넌트**: 여러 도메인에서 공통으로 사용되는 유틸리티, 설정, 기본 스키마 등은 `core` 또는 `shared` 모듈에 배치합니다.

**범용 파일 및 폴더 구조 (FastAPI 백엔드 기준)**
```
/
├── app/
│   ├── __init__.py
│   ├── main.py             # FastAPI 앱 초기화 및 미들웨어 설정
│   ├── api/                # API 엔드포인트 (라우터)
│   │   ├── __init__.py
│   │   ├── endpoints/
│   │   │   ├── chat.py
│   │   │   ├── documents.py
│   │   │   └── auth.py
│   │   └── deps.py         # 의존성 주입
│   ├── core/               # 핵심 로직 및 설정
│   │   ├── __init__.py
│   │   ├── config.py       # 환경 변수 및 설정
│   │   └── security.py     # 인증/보안 관련 유틸
│   ├── crud/               # 데이터베이스 CRUD 작업 (리포지토리)
│   │   ├── __init__.py
│   │   └── ...
│   ├── schemas/            # Pydantic 데이터 모델
│   │   ├── __init__.py
│   │   └── ...
│   ├── services/           # 비즈니스 로직
│   │   ├── __init__.py
│   │   ├── chat_service.py
│   │   └── rag_pipeline.py
│   └── db/                 # 데이터베이스 세션 및 초기화
│       ├── __init__.py
│       └── session.py
├── data/                   # 데이터 파일 (PRD 구조 참조)
│   └── ...
├── tests/                  # 테스트 코드
└── docker-compose.yml      # Docker 설정
```

### 데이터 흐름 및 통신 패턴
- **클라이언트-서버 통신**: 프론트엔드와 백엔드는 JSON 형식을 사용하는 RESTful API를 통해 통신합니다. 모든 통신은 HTTPS로 암호화됩니다.
- **데이터베이스 상호작용**: FastAPI는 SQLAlchemy ORM을 사용하여 PostgreSQL과 상호작용하며, 비동기 세션을 통해 효율적인 DB 접근을 관리합니다.
- **외부 서비스 통합**: 백엔드의 `rag_pipeline` 서비스가 Claude API와의 통신을 전담합니다. API 요청/응답 로직을 별도 모듈로 추상화하여 관리하고, 비용 및 사용량 모니터링 로직을 포함합니다.
- **실시간 통신**: 현재는 요청-응답 모델을 사용합니다. 향후 실시간 스트리밍 답변이 필요할 경우, WebSocket 또는 Server-Sent Events(SSE)를 도입하여 응답을 점진적으로 표시할 수 있습니다.
- **PDF 직접 전송 흐름**:
    1.  사용자 질문 수신
    2.  질문에서 회사명 추출 (예: "마인이스의 2024년 매출은?")
    3.  DB에서 해당 회사의 관련 문서 경로 조회
    4.  파일 시스템에서 PDF 파일 읽기
    5.  전체 PDF와 사용자 질문을 Claude API로 전송
    6.  LLM 답변 수신 후, 출처 정보와 함께 가공하여 사용자에게 반환

## 4. 성능 및 최적화 전략
- **응답 캐싱**: Redis를 활용하여 동일한 질문에 대한 LLM 응답과 자주 조회되는 문서 검색 결과를 캐싱합니다. 이를 통해 API 비용을 절감하고 평균 응답 시간을 3초 이내로 유지합니다.
- **LLM 라우팅 최적화**: 질문의 유형과 복잡도를 분석하여 Claude 3의 Opus, Sonnet, Haiku 모델을 동적으로 선택하는 라우팅 로직을 구현합니다. 단순 조회는 비용이 저렴한 Haiku를, 복잡한 분석은 Opus를 사용하여 비용 대비 성능을 최적화합니다.
- **비동기 처리 활용**: FastAPI의 비동기 기능을 최대한 활용하여 외부 API 호출, 데이터베이스 조회 등 I/O 바운드 작업을 병렬로 처리함으로써 전체 시스템의 처리량과 응답성을 높입니다.
- **데이터베이스 인덱싱**: PostgreSQL 테이블의 `company_name`, `published_date`, `year` 등 검색 조건으로 자주 사용되는 컬럼에 인덱스를 생성하여 쿼리 성능을 최적화합니다.

## 5. 구현 로드맵 및 마일스톤
### 1단계: 기반 구축 (MVP 구현, 2주)
- **핵심 인프라**: SQLite 기반 간단한 개발 환경, Redis 캐싱 설정을 완료합니다. (Docker는 선택사항)
- **필수 기능**: Claude API를 연동한 PDF 직접 전송 방식의 채팅 기능, 문서 메타데이터 관리, 기본 캐싱 기능을 구현합니다.
- **기본 보안**: API 통신을 위한 기본 설정만 적용합니다.
- **개발 환경**: FastAPI 프로젝트 구조 설정 및 Git 리포지토리 생성을 완료합니다.
- **예상 기간**: 1-2주

### 2단계: 기능 강화 (3-4주)
- **고급 기능**: 사용자 로그인 및 인증 시스템(JWT 기반), 재무 데이터 차트 시각화(Chart.js 연동), 검색 결과 캐싱 로직을 구현합니다.
- **성능 최적화**: 쿼리 최적화 및 응답 캐싱을 통해 시스템 성능을 개선합니다.
- **보안 강화**: HTTPS 적용 및 민감 정보 암호화 저장 방안을 마련합니다.
- **모니터링 구현**: 기본적인 API 요청/응답 로깅 시스템을 구축합니다.
- **예상 기간**: 2주

### 3단계: 확장 및 최적화 (2개월 후)
- **확장성 구현**: 두레이 메신저 연동을 위한 인터페이스 추상화 및 구현을 진행합니다.
- **고급 통합**: KIIPS ERP 연동을 위한 아키텍처를 설계하고 프로토타입을 개발합니다.
- **엔터프라이즈 기능**: 자동 리포트 생성, 다중 문서 비교 분석 등 고급 분석 기능을 추가합니다.
- **규정 준수 및 감사**: 내부 SSO 연동 및 접근 제어 정책을 강화합니다.
- **예상 기간**: 4주 이상

## 6. 리스크 평가 및 완화 전략
### 기술 리스크 분석
- **기술 리스크**: Claude API 장애 또는 성능 저하 발생 시, 시스템의 핵심 기능이 마비될 수 있습니다.
    - **완화 전략**: Gemini 등 대체 LLM으로 전환할 수 있는 폴백(Fallback) 로직을 구현하고, API 상태를 주기적으로 모니터링합니다.
- **성능 리스크**: 포트폴리오 기업 수가 증가하고 PDF 파일 크기가 커질수록 Claude API 응답 시간이 길어지고 비용이 증가할 수 있습니다.
    - **완화 전략**: Redis 캐싱을 적극 활용하여 동일한 질문에 대한 반복 호출을 방지합니다. PDF 크기가 너무 큰 경우(100MB 이상) 필요시 페이지 범위를 지정하여 전송하는 로직을 추가합니다. 향후 비용이 문제가 될 경우 벡터 인덱싱 방식으로 전환을 검토합니다.
- **보안 리스크**: 내부 재무 정보 등 민감 데이터를 다루므로, 비인가 접근 시 정보 유출의 위험이 있습니다.
    - **완화 전략**: 강력한 사용자 인증(향후 SSO 연동)을 적용하고, 데이터베이스 접근 제어 및 모든 통신 구간 암호화를 의무화합니다.
- **통합 리스크**: 향후 두레이, ERP 등 외부 시스템 연동 시 API 사양 변경이나 호환성 문제가 발생할 수 있습니다.
    - **완화 전략**: 외부 연동 모듈을 추상화된 인터페이스 기반으로 설계하여 특정 시스템에 대한 의존도를 낮추고, 변경에 유연하게 대응할 수 있도록 합니다.

### 프로젝트 납품 리스크
- **일정 리스크**: 1인 개발로 진행되므로, 예상치 못한 기술적 난관이나 요구사항 변경 시 일정 지연 가능성이 높습니다.
    - **대응 계획**: MVP 범위를 명확히 하고, 주간 단위로 진행 상황을 공유하며 위험 요소를 조기에 식별합니다. 일정 지연이 불가피할 경우, 우선순위가 낮은 기능(Could Have)부터 제외하는 방향으로 범위를 조정합니다.
- **자원 리스크**: 특정 기술(LLM, 벡터 DB)에 대한 전문성이 부족할 경우 개발 속도가 저하될 수 있습니다.
    - **대응 계획**: 커뮤니티와 공식 문서를 적극 활용하고, 복잡한 문제는 외부 전문가 자문을 구하는 방안을 고려합니다.
- **품질 리스크**: 빠른 개발 속도를 우선시하다 보면 테스트 커버리지가 부족해져 배포 후 버그가 발생할 수 있습니다.
    - **대응 계획**: 핵심 기능(RAG 파이프라인, 인증)에 대한 단위 테스트 및 통합 테스트 코드를 작성하여 코드 품질을 최소한으로 보장합니다.
- **배포 리스크**: 개발 환경과 운영 환경의 차이로 인해 배포 시 예상치 못한 문제가 발생할 수 있습니다.
    - **대응 계획**: Docker를 사용하여 환경을 일치시키고, 배포 전 스테이징 환경에서 충분한 테스트를 거칩니다. 배포 프로세스를 스크립트로 자동화하여 실수를 줄입니다.
</file>

<file path="vooster-docs/clean-code.md">
# Clean Code Guidelines

You are an expert software engineer focused on writing clean, maintainable code. Follow these principles rigorously:

## Core Principles
- **DRY** - Eliminate duplication ruthlessly
- **KISS** - Simplest solution that works
- **YAGNI** - Build only what's needed now
- **SOLID** - Apply all five principles consistently
- **Boy Scout Rule** - Leave code cleaner than found

## Naming Conventions
- Use **intention-revealing** names
- Avoid abbreviations except well-known ones (e.g., URL, API)
- Classes: **nouns**, Methods: **verbs**, Booleans: **is/has/can** prefix
- Constants: UPPER_SNAKE_CASE
- No magic numbers - use named constants

## Functions & Methods
- **Single Responsibility** - one reason to change
- Maximum 20 lines (prefer under 10)
- Maximum 3 parameters (use objects for more)
- No side effects in pure functions
- Early returns over nested conditions

## Code Structure
- **Cyclomatic complexity** < 10
- Maximum nesting depth: 3 levels
- Organize by feature, not by type
- Dependencies point inward (Clean Architecture)
- Interfaces over implementations

## Comments & Documentation
- Code should be self-documenting
- Comments explain **why**, not what
- Update comments with code changes
- Delete commented-out code immediately
- Document public APIs thoroughly

## Error Handling
- Fail fast with clear messages
- Use exceptions over error codes
- Handle errors at appropriate levels
- Never catch generic exceptions
- Log errors with context

## Testing
- **TDD** when possible
- Test behavior, not implementation
- One assertion per test
- Descriptive test names: `should_X_when_Y`
- **AAA pattern**: Arrange, Act, Assert
- Maintain test coverage > 80%

## Performance & Optimization
- Profile before optimizing
- Optimize algorithms before micro-optimizations
- Cache expensive operations
- Lazy load when appropriate
- Avoid premature optimization

## Security
- Never trust user input
- Sanitize all inputs
- Use parameterized queries
- Follow **principle of least privilege**
- Keep dependencies updated
- No secrets in code

## Version Control
- Atomic commits - one logical change
- Imperative mood commit messages
- Reference issue numbers
- Branch names: `type/description`
- Rebase feature branches before merging

## Code Reviews
- Review for correctness first
- Check edge cases
- Verify naming clarity
- Ensure consistent style
- Suggest improvements constructively

## Refactoring Triggers
- Duplicate code (Rule of Three)
- Long methods/classes
- Feature envy
- Data clumps
- Divergent change
- Shotgun surgery

## Final Checklist
Before committing, ensure:
- [ ] All tests pass
- [ ] No linting errors
- [ ] No console logs
- [ ] No commented code
- [ ] No TODOs without tickets
- [ ] Performance acceptable
- [ ] Security considered
- [ ] Documentation updated

Remember: **Clean code reads like well-written prose**. Optimize for readability and maintainability over cleverness.
</file>

<file path="vooster-docs/git-commit-message.md">
# Git Commit Message Rules

## Format Structure
```
<type>(<scope>): <description>

[optional body]

[optional footer]
```

## Types (Required)
- `feat`
- `fix`
- `docs`
- `style`
- `refactor`
- `perf`
- `test`
- `chore`
- `ci`
- `build`
- `revert`

## Scope (Optional)
- Component, file, or feature area affected
- Use kebab-case: `user-auth`, `payment-api`
- Omit if change affects multiple areas

## Description Rules
- Use imperative mood
- No capitalization of first letter
- No period at end
- Max 50 characters
- Be specific and actionable

## Body Guidelines
- Wrap at 72 characters
- Explain what and why, not how
- Separate from description with blank line
- Use bullet points for multiple changes

## Footer Format
- `BREAKING CHANGE:` for breaking changes
- `Closes #123` for issue references
- `Co-authored-by: Vooster AI (@vooster-ai)`

## Examples
```
feat(auth): add OAuth2 Google login

fix: resolve memory leak in user session cleanup

docs(api): update authentication endpoints

refactor(utils): extract validation helpers to separate module

BREAKING CHANGE: remove deprecated getUserData() method
```

## Workflow Integration
**ALWAYS write a commit message after completing any development task, feature, or bug fix.**

## Validation Checklist
- [ ] Type is from approved list
- [ ] Description under 50 chars
- [ ] Imperative mood used
- [ ] No trailing period
- [ ] Meaningful and clear context
</file>

<file path="vooster-docs/guideline.md">
# Investment Portfolio Q&A Chatbot: Code Guideline

## 1. Project Overview

This document outlines the coding standards and best practices for the "Investment Portfolio Intelligence Assistant" project. This AI-powered conversational Q&A chatbot aims to provide investment teams with rapid access to financial and news information on portfolio companies. The system leverages a React.js frontend, a FastAPI backend, and a Retrieval-Augmented Generation (RAG) pattern utilizing Anthropic's Claude API, PostgreSQL, ChromaDB, and Redis.

Key architectural decisions include:
*   **Decoupled Frontend/Backend**: React.js for UI, FastAPI for business logic.
*   **RAG Pattern**: Claude API for LLM, ChromaDB for vector search, PostgreSQL for metadata.
*   **Performance Optimization**: Redis for caching, asynchronous processing in FastAPI.
*   **Scalability**: Dockerized services, domain-driven backend structure.

## 2. Core Principles

1.  **Readability**: Code MUST be easily understood by other developers.
2.  **Maintainability**: Code MUST be simple to modify, debug, and extend.
3.  **Testability**: Code MUST be designed for easy and comprehensive testing.
4.  **Performance**: Code MUST be optimized for speed and resource efficiency, especially for I/O operations.
5.  **Security**: Code MUST adhere to security best practices, protecting sensitive data.

## 3. Language-Specific Guidelines

### 3.1 Python (FastAPI Backend)

#### File Organization and Directory Structure
*   **MUST**: Organize code by business domain within the `app/` directory.
    ```
    app/
    ├── api/                # API endpoints (routers)
    │   ├── endpoints/
    │   │   ├── chat.py
    │   │   ├── documents.py
    │   │   └── auth.py
    │   └── deps.py         # Dependency injection utilities
    ├── core/               # Core configurations, utilities, security
    │   ├── config.py
    │   └── security.py
    ├── crud/               # Database CRUD operations (repositories)
    │   ├── chat_crud.py
    │   └── document_crud.py
    ├── schemas/            # Pydantic models for request/response/database
    │   ├── chat_schemas.py
    │   └── document_schemas.py
    ├── services/           # Business logic, external API calls, RAG pipeline
    │   ├── chat_service.py
    │   ├── document_service.py
    │   └── rag_pipeline.py
    ├── db/                 # Database session management
    │   └── session.py
    └── main.py             # FastAPI app initialization
    ```
*   **MUST NOT**: Create monolithic files containing multiple unrelated domains or layers.

#### Import/Dependency Management
*   **MUST**: Use absolute imports from the `app` root.
    ```python
    # MUST: Absolute import
    from app.services.chat_service import ChatService
    from app.schemas.chat_schemas import ChatRequest
    ```
*   **MUST NOT**: Use relative imports that make code less portable or harder to refactor.
    ```python
    # MUST NOT: Relative import
    # from ..services.chat_service import ChatService
    ```
*   **MUST**: Explicitly declare dependencies using FastAPI's `Depends` for better testability and maintainability.
    ```python
    # MUST: Use FastAPI's Depends for dependency injection
    from fastapi import Depends, APIRouter
    from app.services.chat_service import ChatService

    router = APIRouter()

    @router.post("/chat/")
    async def create_chat_completion(
        request: ChatRequest,
        chat_service: ChatService = Depends(ChatService)
    ):
        return await chat_service.process_query(request.question)
    ```

#### Error Handling Patterns
*   **MUST**: Use FastAPI's `HTTPException` for API-level errors.
    ```python
    # MUST: Raise HTTPException for API errors
    from fastapi import HTTPException, status

    async def get_document(doc_id: int):
        doc = await document_crud.get(doc_id)
        if not doc:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Document not found")
        return doc
    ```
*   **MUST**: Implement custom exception handlers for specific application errors.
*   **MUST**: Log detailed error information for debugging.
    ```python
    # MUST: Log errors
    import logging
    logger = logging.getLogger(__name__)

    try:
        # Some risky operation
        result = 1 / 0
    except ZeroDivisionError as e:
        logger.error(f"Calculation error: {e}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Internal server error")
    ```

### 3.2 JavaScript/TypeScript (React.js Frontend)

#### File Organization and Directory Structure
*   **MUST**: Organize components and hooks by feature or domain.
    ```
    src/
    ├── components/         # Reusable UI components (e.g., Button, Modal)
    │   ├── common/
    │   └── layout/
    ├── features/           # Feature-specific components, hooks, and logic
    │   ├── chat/
    │   │   ├── components/ # Chat-specific components (e.g., ChatWindow, MessageBubble)
    │   │   ├── hooks/      # Chat-specific hooks (e.g., useChat)
    │   │   └── ChatPage.jsx
    │   ├── auth/
    │   │   └── LoginPage.jsx
    │   └── documents/
    ├── hooks/              # Global reusable hooks (e.g., useAuth)
    ├── services/           # API interaction logic
    │   └── api.js
    ├── contexts/           # React Context API providers
    ├── utils/              # General utility functions
    ├── App.jsx
    └── main.jsx
    ```
*   **MUST NOT**: Dump all components into a single `components/` directory without further organization.

#### Import/Dependency Management
*   **MUST**: Use absolute imports configured via `jsconfig.json` or `tsconfig.json` for cleaner paths.
    ```javascript
    // jsconfig.json or tsconfig.json
    {
      "compilerOptions": {
        "baseUrl": "src"
      }
    }

    // MUST: Absolute import
    import { Button } from 'components/common/Button';
    import { useChat } from 'features/chat/hooks/useChat';
    ```
*   **MUST NOT**: Use deeply nested relative imports.

#### Error Handling Patterns
*   **MUST**: Use `try-catch` blocks for asynchronous operations (e.g., API calls) and display user-friendly error messages.
    ```javascript
    // MUST: Handle errors in async operations
    import { useState } from 'react';
    import api from 'services/api';

    function ChatInput() {
      const [error, setError] = useState(null);

      const handleSubmit = async (question) => {
        try {
          setError(null);
          const response = await api.post('/chat', { question });
          // Process response
        } catch (err) {
          console.error("Failed to send message:", err);
          setError("Failed to send message. Please try again.");
        }
      };

      return (
        <div>
          {error && <div className="text-red-500">{error}</div>}
          <button onClick={() => handleSubmit("Hello")}>Send</button>
        </div>
      );
    }
    ```
*   **MUST**: Centralize error logging or reporting (e.g., to a monitoring service) if applicable.

## 4. Code Style Rules

### MUST Follow:

*   **Consistent Naming Conventions**:
    *   **Python**: `snake_case` for variables, functions, and modules. `PascalCase` for classes. `UPPER_SNAKE_CASE` for constants.
    *   **JavaScript/TypeScript**: `camelCase` for variables and functions. `PascalCase` for React components and classes. `UPPER_SNAKE_CASE` for global constants.
    *   **Rationale**: Ensures immediate recognition of code elements and improves readability.

    ```python
    # MUST: Python naming
    class ChatService:
        MAX_RETRIES = 3
        def process_query(self, user_question: str):
            pass
    ```
    ```javascript
    // MUST: JavaScript naming
    const maxRetries = 3;
    function ChatInput() { /* ... */ }
    class ApiService { /* ... */ }
    ```

*   **Type Hinting (Python) / TypeScript (JavaScript)**:
    *   **MUST**: Use type hints for all function arguments, return values, and class attributes in Python.
    *   **MUST**: Use TypeScript for all frontend code to ensure type safety.
    *   **Rationale**: Improves code clarity, enables static analysis, and reduces runtime errors.

    ```python
    # MUST: Python type hints
    def calculate_revenue(sales: float, price_per_unit: float) -> float:
        return sales * price_per_unit
    ```
    ```typescript
    // MUST: TypeScript types
    interface ChatMessage {
      id: string;
      text: string;
      sender: 'user' | 'ai';
    }

    const sendMessage = (message: ChatMessage): void => { /* ... */ };
    ```

*   **Docstrings/Comments**:
    *   **MUST**: Provide clear and concise docstrings for all modules, classes, and functions in Python (Google style).
    *   **MUST**: Add comments for complex logic or non-obvious code sections in both Python and JavaScript.
    *   **Rationale**: Essential for understanding code purpose and usage, especially in a team environment.

    ```python
    # MUST: Python Docstring
    def get_financial_report(company_name: str, year: int) -> dict:
        """Retrieves the financial report for a given company and year.

        Args:
            company_name: The name of the company.
            year: The fiscal year of the report.

        Returns:
            A dictionary containing the financial report data.
        """
        # ... implementation ...
    ```

*   **Pydantic for Data Validation**:
    *   **MUST**: Use Pydantic models for all request bodies, response models, and database schemas in FastAPI.
    *   **Rationale**: Provides robust data validation, serialization, and automatic documentation.

    ```python
    # MUST: Use Pydantic for data validation
    from pydantic import BaseModel

    class ChatRequest(BaseModel):
        question: str
        context: dict | None = None

    class ChatResponse(BaseModel):
        answer: str
        sources: list[str]
    ```

*   **Asynchronous Programming**:
    *   **MUST**: Use `async/await` for all I/O-bound operations (database queries, external API calls, file operations) in FastAPI.
    *   **Rationale**: Prevents blocking the event loop, improving concurrency and overall system responsiveness.

    ```python
    # MUST: Use async/await for I/O operations
    from sqlalchemy.ext.asyncio import AsyncSession
    from app.crud.document_crud import DocumentCRUD

    async def get_document_by_id(db: AsyncSession, doc_id: int):
        return await DocumentCRUD(db).get(doc_id)
    ```

### MUST NOT Do:

*   **Monolithic Files/Modules**:
    *   **MUST NOT**: Create huge, multi-responsibility modules or files that handle too many unrelated concerns.
    *   **Rationale**: Violates Single Responsibility Principle, makes code hard to navigate, test, and maintain.

    ```python
    # MUST NOT: Monolithic file (avoid combining unrelated logic)
    # chat_and_document_and_user_service.py
    # This file should be split into chat_service.py, document_service.py, user_service.py
    ```

*   **Complex State Management (Frontend)**:
    *   **MUST NOT**: Introduce overly complex state management patterns (e.g., Redux) unless absolutely necessary for global, deeply shared state. Prefer React Context API and local component state for most cases.
    *   **Rationale**: Increases boilerplate and learning curve for a project of this scale. Context API is sufficient for the current requirements.

    ```javascript
    // MUST NOT: Over-engineer state management for simple cases
    // Avoid introducing Redux/Zustand/Jotai for simple chat state if Context API suffices.
    // Use React Context API for global state like user authentication or theme.
    ```

*   **Hardcoding Sensitive Information**:
    *   **MUST NOT**: Hardcode API keys, database credentials, or any other sensitive information directly in the code.
    *   **Rationale**: Major security vulnerability. Use environment variables (e.g., `os.getenv` in Python, `import.meta.env` in Vite) or a secure configuration management system.

    ```python
    # MUST NOT: Hardcode API key
    # CLAUDE_API_KEY = "sk-..."

    # MUST: Use environment variables
    import os
    CLAUDE_API_KEY = os.getenv("CLAUDE_API_KEY")
    ```

*   **Ignoring Exceptions**:
    *   **MUST NOT**: Use empty `except` blocks or `pass` in `except` blocks, suppressing errors without logging or handling them.
    *   **Rationale**: Makes debugging impossible and hides critical issues.

    ```python
    # MUST NOT: Suppress exceptions
    # try:
    #     some_risky_operation()
    # except Exception:
    #     pass # This is bad!

    # MUST: Handle or log exceptions appropriately
    try:
        some_risky_operation()
    except SpecificException as e:
        logger.error(f"Error during operation: {e}")
        # Re-raise, return error, or provide fallback
    ```

## 5. Architecture Patterns

### Component/Module Structure Guidelines

*   **Domain-Driven Design (Backend)**:
    *   **MUST**: Structure the backend around business domains (e.g., `chat`, `documents`, `auth`). Each domain should have its own `api/endpoints`, `services`, `crud`, and `schemas` subdirectories.
    *   **Rationale**: Promotes high cohesion and low coupling, making the codebase easier to understand, develop, and scale independently.

*   **Layered Architecture (Backend)**:
    *   **MUST**: Maintain clear separation between API (endpoints), Service (business logic), and Repository (CRUD/data access) layers.
    *   **Rationale**: Each layer has a distinct responsibility, simplifying testing and allowing changes in one layer without affecting others.

    ```python
    # app/api/endpoints/chat.py (API Layer)
    from fastapi import APIRouter, Depends
    from app.schemas.chat_schemas import ChatRequest, ChatResponse
    from app.services.chat_service import ChatService

    router = APIRouter()

    @router.post("/chat", response_model=ChatResponse)
    async def chat_endpoint(request: ChatRequest, service: ChatService = Depends()):
        return await service.process_query(request.question, request.context)

    # app/services/chat_service.py (Service Layer - Business Logic)
    from app.services.rag_pipeline import RAGPipeline
    from app.crud.chat_crud import ChatCRUD
    from app.schemas.chat_schemas import ChatResponse
    from sqlalchemy.ext.asyncio import AsyncSession

    class ChatService:
        def __init__(self, db_session: AsyncSession = Depends(get_db_session)):
            self.rag_pipeline = RAGPipeline(db_session)
            self.chat_crud = ChatCRUD(db_session)

        async def process_query(self, question: str, context: dict) -> ChatResponse:
            answer, sources = await self.rag_pipeline.generate_response(question, context)
            await self.chat_crud.save_chat_history(question, answer, sources)
            return ChatResponse(answer=answer, sources=sources)

    # app/crud/chat_crud.py (Repository Layer - Data Access)
    from sqlalchemy.ext.asyncio import AsyncSession
    from app.db.models import ChatHistory

    class ChatCRUD:
        def __init__(self, db_session: AsyncSession):
            self.db = db_session

        async def save_chat_history(self, question: str, answer: str, sources: list[str]):
            chat_entry = ChatHistory(question=question, answer=answer, context={"sources": sources})
            self.db.add(chat_entry)
            await self.db.commit()
            await self.db.refresh(chat_entry)
            return chat_entry
    ```

### Data Flow Patterns

*   **Request-Response (RESTful API)**:
    *   **MUST**: All client-server communication MUST follow a RESTful request-response pattern using JSON payloads.
    *   **Rationale**: Standard, stateless, and widely understood pattern for web services.
    *   **Example**: `POST /api/chat` for sending questions, `GET /api/news/search` for news retrieval.

*   **RAG Pipeline**:
    *   **MUST**: Implement the RAG pipeline within the `rag_pipeline.py` service. This service is responsible for:
        1.  Receiving user query.
        2.  Generating embeddings for the query.
        3.  Retrieving relevant document chunks from ChromaDB.
        4.  Constructing an augmented prompt.
        5.  Calling the Claude API.
        6.  Parsing and returning the LLM response.
    *   **Rationale**: Centralizes the core AI logic, making it maintainable and testable.

    ```python
    # app/services/rag_pipeline.py
    from app.crud.document_crud import DocumentCRUD
    from app.core.llm import LLMClient # Abstraction for Claude API
    from app.core.embedding import EmbeddingClient # Abstraction for Embedding model

    class RAGPipeline:
        def __init__(self, db_session: AsyncSession):
            self.document_crud = DocumentCRUD(db_session)
            self.llm_client = LLMClient()
            self.embedding_client = EmbeddingClient()

        async def generate_response(self, question: str, context: dict | None = None) -> tuple[str, list[str]]:
            # 1. Generate query embedding
            query_embedding = await self.embedding_client.embed(question)

            # 2. Retrieve relevant documents from ChromaDB (via document_crud)
            relevant_docs = await self.document_crud.search_vector_db(query_embedding, top_k=5)
            doc_contents = [doc.content for doc in relevant_docs]
            sources = [doc.source_id for doc in relevant_docs] # Assuming source_id is available

            # 3. Construct augmented prompt
            augmented_prompt = self._build_prompt(question, doc_contents)

            # 4. Call LLM API (with optional model routing)
            answer = await self.llm_client.generate_text(augmented_prompt, question_type="complex_analysis")

            return answer, sources

        def _build_prompt(self, question: str, documents: list[str]) -> str:
            # MUST: Define clear prompt templates
            context_str = "\n".join([f"Document {i+1}: {doc}" for i, doc in enumerate(documents)])
            return f"""You are an intelligent assistant for investment teams.
            Based on the following documents, answer the user's question.
            If the answer is not in the documents, state that you don't have enough information.

            Documents:
            {context_str}

            User Question: {question}
            """
    ```

### State Management Conventions (React Frontend)

*   **MUST**: Prefer local component state (`useState`) for UI-specific, ephemeral data.
*   **MUST**: Use `useContext` for global or shared state that needs to be accessed by multiple, non-directly related components (e.g., authentication status, user preferences).
*   **MUST**: Use custom hooks (`useReducer`, `useEffect`) to encapsulate complex state logic and side effects, promoting reusability.
*   **Rationale**: Keeps state management simple and predictable for the project's scale, avoiding over-engineering.

    ```javascript
    // MUST: Use useState for local component state
    import React, { useState } from 'react';

    function MessageInput() {
      const [message, setMessage] = useState('');
      const handleSend = () => { /* ... */ };

      return (
        <input
          type="text"
          value={message}
          onChange={(e) => setMessage(e.target.value)}
        />
      );
    }

    // MUST: Use useContext for global state
    // src/contexts/AuthContext.jsx
    import React, { createContext, useContext, useState } from 'react';

    const AuthContext = createContext(null);

    export const AuthProvider = ({ children }) => {
      const [user, setUser] = useState(null);
      // ... login/logout functions ...
      return (
        <AuthContext.Provider value={{ user, setUser }}>
          {children}
        </AuthContext.Provider>
      );
    };

    export const useAuth = () => useContext(AuthContext);

    // In a component:
    // import { useAuth } from 'contexts/AuthContext';
    // const { user } = useAuth();
    ```

### API Design Standards (FastAPI)

*   **MUST**: Follow RESTful principles for API endpoint design (e.g., `GET /resources`, `POST /resources`, `GET /resources/{id}`).
*   **MUST**: Use clear, descriptive, and pluralized resource names in URLs.
*   **MUST**: Use appropriate HTTP status codes for responses (e.g., 200 OK, 201 Created, 400 Bad Request, 404 Not Found, 500 Internal Server Error).
*   **MUST**: Provide meaningful error messages in JSON format for client consumption.
*   **MUST**: Implement authentication and authorization using JWT tokens for protected endpoints.
*   **Rationale**: Ensures consistency, predictability, and ease of integration for API consumers.

    ```python
    # MUST: RESTful endpoint design with proper status codes and response models
    from fastapi import APIRouter, HTTPException, status
    from app.schemas.document_schemas import DocumentResponse, DocumentCreate
    from app.services.document_service import DocumentService

    router = APIRouter(prefix="/documents", tags=["Documents"])

    @router.get("/{doc_id}", response_model=DocumentResponse)
    async def get_document_by_id(doc_id: int, service: DocumentService = Depends()):
        document = await service.get_document(doc_id)
        if not document:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Document not found")
        return document

    @router.post("/", response_model=DocumentResponse, status_code=status.HTTP_201_CREATED)
    async def create_document(doc_data: DocumentCreate, service: DocumentService = Depends()):
        return await service.create_new_document(doc_data)
    ```

    ## Gemini CLI 연동 가이드

### 목적
사용자가 「Gemini와 상의하면서 진행해줘」 (또는 유사한 표현)라고 지시할 경우, Claude는 이후 작업을 Gemini CLI와 협력하여 진행한다.
Gemini로부터 받은 응답은 그대로 보여주고, Claude의 해설이나 통합 설명을 덧붙여 두 에이전트의 지식을 결합한다.

### 트리거
- 정규표현식: `/Gem.*상의하면서/`
- 예시:
  - 「Gem과 상의하면서 진행해줘」
  - 「이건 Gemini랑 이야기하면서 하자」

### Gemini CLI 사용법
```bash
# 기본 사용법
gemini -p "프롬프트 내용"

# 파일을 컨텍스트로 제공
gemini -p "프롬프트 내용" < input_file.md

# 여러 줄 프롬프트 (heredoc 사용)
export PROMPT="여러 줄의
프롬프트 내용"
gemini <<EOF
$PROMPT
EOF

# 주요 옵션
# -m, —model: 모델 선택 (기본: gemini-2.5-pro)
# -p, —prompt: 프롬프트 텍스트
# -d, —debug: 디버그 모드
# -y, —yolo: 자동 승인 모드
```

# Gemini CLI Commands (Updated 2025)

## Core Commands

### `/permissions`
Display and manage permission settings for Gemini CLI. Shows current tool permissions and authentication status.

### `/status` 
Check the current status of Gemini CLI including:
- Connection status to Gemini model
- Authentication method in use
- Rate limit information (60 requests/minute, 1000/day for free tier)
- Active MCP servers

### `/memory`
Manage the AI's instructional context from GEMINI.md files:
- `/memory` - Display current memory context
- `/memory add <text>` - Add text to AI's memory

### `/mcp`
Model Context Protocol server management:
- `/mcp` - List configured MCP servers and connection status
- `/mcp show` - Show detailed descriptions for servers and tools
- `/mcp hide` - Hide tool descriptions, show only names

### `/auth`
Switch between authentication methods:
- Google account login (free tier)
- API key authentication
- Vertex AI authentication

### `/stats`
Display usage statistics:
- Request count for current session
- Daily/minute rate limit usage
- Model being used (gemini-2.5-pro/flash)

### `/help`
Display help information about Gemini CLI commands and features

## Shell Integration

### `!` prefix
Execute shell commands directly:
- `!ls -la` - List files
- `!git status` - Check git status
- Commands run with user's shell permissions

## File Operations

### `@` symbol
Reference files in prompts:
- `@file.txt` - Include file content in prompt
- Supports multiple files with `read_many_files` tool

## Authentication Notes

1. **Free Tier (Google Login)**
   - 60 requests per minute
   - 1,000 requests per day
   - May switch to gemini-2.5-flash during high load

2. **API Key**
   - Higher rate limits available
   - Configure in settings

3. **Vertex AI**
   - Enterprise authentication option
   - Custom quotas

## Security Configuration

- `excludeTools`: String matching for command restrictions (can be bypassed)
- `coreTools`: Explicitly allowed commands (recommended)
- `allowedMcpServerNames`: Restrict available MCP servers
- Tool usage requires user permission before execution
</file>

<file path="vooster-docs/prd.md">
# 투자 포트폴리오 Q&A 챗봇 PRD v0.1

**문서 버전**: 0.1  
**작성일**: 2025-07-25  
**작성자**: AI Assistant  
**상태**: 초안

---

## 1. 제품 개요

### 1.1 제품명
투자 포트폴리오 Intelligence Assistant (가칭)

### 1.2 비전
투자팀이 120~250개 포트폴리오 기업의 뉴스와 재무 정보를 실시간으로 조회하고 인사이트를 얻을 수 있는 AI 기반 대화형 시스템

### 1.3 핵심 가치
- **즉시성**: 3초 내 필요한 정보 획득
- **정확성**: 원본 문서 기반 팩트 체크
- **효율성**: 수동 검색 시간 90% 감소

### 1.4 성공 지표 (KPI)
- 일일 활성 사용자(DAU): 3명 이상
- 평균 응답 시간: 3초 이하
- 월 API 비용: 10만원 이내
- 시스템 가용성: 99%

## 2. 사용자 요구사항

### 2.1 타겟 사용자
- **주 사용자**: 투자팀 전 직원 (약 10명)
- **사용 환경**: 데스크톱 웹 브라우저
- **기술 수준**: 일반 비즈니스 사용자

### 2.2 핵심 사용 시나리오

#### 시나리오 1: 재무 정보 조회
```
사용자: "A기업 2024년 매출은?"
시스템: A기업의 2024년 재무제표를 찾아 분석
응답: "A기업의 2024년 매출은 1,234억원입니다. (2024년 사업보고서 p.23 기준)"
```

#### 시나리오 2: 뉴스 검색
```
사용자: "B기업 최근 인수합병 관련 뉴스 있어?"
시스템: 최근 3년 내 B기업 관련 뉴스에서 M&A 키워드 검색
응답: "B기업은 2024년 12월 C사를 500억원에 인수했습니다. 관련 뉴스 3건을 찾았습니다."
```

#### 시나리오 3: 문서 요약
```
사용자: "D기업 작년 주주총회 내용 요약해줘"
시스템: 주주총회 관련 문서 검색 및 분석
응답: "2024년 3월 주주총회 주요 안건: 1) 배당금 주당 500원 승인 2) 신규 이사 선임..."
```

### 2.3 기능 요구사항

#### Must Have (Week 1-2)
- [ ] FR-001: 웹 기반 채팅 인터페이스
- [ ] FR-002: 기업명 기반 문서 검색
- [ ] FR-003: Claude API를 통한 PDF 분석
- [ ] FR-004: 뉴스 검색 및 표시
- [ ] FR-005: 기본적인 질의응답 처리

#### Should Have (Week 3)
- [ ] FR-006: 사용자 로그인 시스템
- [ ] FR-007: 검색 결과 캐싱
- [ ] FR-008: 재무 데이터 차트 시각화
- [ ] FR-009: 응답 출처 표시

#### Could Have (Week 4)
- [ ] FR-010: 두레이 연동 인터페이스
- [ ] FR-011: 대화 히스토리 저장
- [ ] FR-012: 고급 검색 필터
- [ ] FR-013: 다중 문서 비교 분석

### 2.4 비기능 요구사항

#### 성능
- NFR-001: 평균 응답 시간 3초 이내
- NFR-002: 동시 사용자 5명 지원
- NFR-003: 파일 크기 50MB까지 처리 가능

#### 가용성
- NFR-004: 99% 가용성 (계획된 유지보수 제외)
- NFR-005: 24/7 서비스 제공

#### 보안
- NFR-006: 사용자 인증 필요
- NFR-007: HTTPS 통신
- NFR-008: 민감 정보 암호화 저장

#### 확장성
- NFR-009: 250개 기업까지 확장 가능
- NFR-010: 두레이/ERP 연동 가능한 아키텍처

## 3. 시스템 아키텍처

### 3.1 기술 스택

#### Frontend
```yaml
Framework: React.js 18
Styling: Tailwind CSS 3.0
Charts: Chart.js 4.0
Build Tool: Vite
State Management: Context API
```

#### Backend
```yaml
Framework: FastAPI 0.110
Language: Python 3.11
Database: PostgreSQL 15
Cache: Redis 7
Vector DB: ChromaDB
Queue: Celery (optional)
```

#### AI/ML
```yaml
Primary LLM: Claude 3 Opus
Fallback LLM: Gemini Pro
Embeddings: sentence-transformers (jhgan/ko-sroberta-multitask)
```

#### Infrastructure
```yaml
Container: Docker
Web Server: Nginx
Process Manager: Gunicorn
Monitoring: Prometheus + Grafana (optional)
```

### 3.2 시스템 구성도

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│   React     │────▶│   Nginx     │────▶│  FastAPI    │
│   Web UI    │     │  (Reverse   │     │   Server    │
└─────────────┘     │   Proxy)    │     └──────┬──────┘
                    └─────────────┘              │
                                                 │
                    ┌─────────────────────────────┴─────────────────────────┐
                    │                                                       │
                    ▼                           ▼                           ▼
            ┌─────────────┐             ┌─────────────┐            ┌─────────────┐
            │ PostgreSQL  │             │    Redis    │            │  ChromaDB   │
            │   (Meta)    │             │   (Cache)   │            │  (Vectors)  │
            └─────────────┘             └─────────────┘            └─────────────┘
                                                                            
                    ┌─────────────┐             ┌─────────────┐
                    │ File System │             │ Claude API  │
                    │   (PDFs)    │             │   (LLM)     │
                    └─────────────┘             └─────────────┘
```

### 3.3 데이터 모델

#### 데이터베이스 스키마
```sql
-- 뉴스 메타데이터
CREATE TABLE news (
    id SERIAL PRIMARY KEY,
    company_name VARCHAR(100) NOT NULL,
    title TEXT NOT NULL,
    content TEXT,
    content_url TEXT,
    source VARCHAR(100),
    published_date TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW(),
    INDEX idx_company_date (company_name, published_date DESC)
);

-- 재무제표 인덱스
CREATE TABLE financial_docs (
    id SERIAL PRIMARY KEY,
    company_name VARCHAR(100) NOT NULL,
    doc_type VARCHAR(50), -- '사업보고서', '반기보고서', '분기보고서'
    year INTEGER NOT NULL,
    quarter INTEGER,
    file_path TEXT NOT NULL,
    file_size BIGINT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    INDEX idx_company_year (company_name, year DESC)
);

-- 사용자 (확장성 고려)
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    name VARCHAR(100),
    password_hash TEXT,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT NOW(),
    last_login TIMESTAMP
);

-- 대화 히스토리 (선택적)
CREATE TABLE chat_history (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    question TEXT NOT NULL,
    answer TEXT,
    context JSONB, -- 검색된 문서 정보
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### 파일 시스템 구조
```
/data/
├── financial_docs/
│   ├── {company_name}/
│   │   ├── 2024/
│   │   │   ├── annual_report_2024.pdf
│   │   │   ├── Q1_report_2024.pdf
│   │   │   └── ...
│   │   └── ...
│   └── ...
└── cache/
    └── embeddings/
```

### 3.4 API 설계

#### 주요 엔드포인트
```yaml
# 채팅
POST /api/chat
Request: { "question": string, "context": object? }
Response: { "answer": string, "sources": array, "charts": array? }

# 문서 검색
GET /api/documents/search
Query: { "company": string, "year": number?, "type": string? }
Response: { "documents": array, "total": number }

# 뉴스 검색
GET /api/news/search
Query: { "company": string, "keyword": string?, "from": date?, "to": date? }
Response: { "news": array, "total": number }

# 사용자 인증
POST /api/auth/login
Request: { "email": string, "password": string }
Response: { "token": string, "user": object }
```

## 4. 구현 계획

### 4.1 개발 일정 (4주)

#### Week 1: 기초 인프라 구축
| 일차 | 작업 내용 | 산출물 |
|------|-----------|---------|
| Day 1-2 | 개발 환경 설정<br>- Docker 환경 구성<br>- PostgreSQL, Redis 설치<br>- FastAPI 프로젝트 생성 | Docker Compose 파일<br>기본 프로젝트 구조 |
| Day 3-4 | 파일 시스템 구축<br>- 재무제표 폴더 구조화<br>- 파일 인덱싱 스크립트<br>- 메타데이터 DB 구축 | 파일 인덱서<br>DB 스키마 |
| Day 5-7 | Claude API 연동<br>- PDF 처리 함수<br>- 프롬프트 템플릿<br>- 기본 채팅 API | Claude 연동 모듈<br>채팅 API v0.1 |

#### Week 2: 검색 시스템 구현
| 일차 | 작업 내용 | 산출물 |
|------|-----------|---------|
| Day 8-10 | 벡터 검색 구현<br>- ChromaDB 설정<br>- 뉴스 임베딩 파이프라인<br>- 검색 API 구현 | 벡터 검색 모듈<br>뉴스 검색 API |
| Day 11-12 | 캐싱 시스템<br>- Redis 캐싱 로직<br>- 응답 시간 최적화 | 캐싱 레이어 |
| Day 13-14 | 통합 테스트<br>- 전체 플로우 테스트<br>- 버그 수정 | 테스트 결과서 |

#### Week 3: 프론트엔드 개발
| 일차 | 작업 내용 | 산출물 |
|------|-----------|---------|
| Day 15-17 | 채팅 인터페이스<br>- React 채팅 컴포넌트<br>- 실시간 응답 표시<br>- 에러 처리 | 채팅 UI |
| Day 18-19 | 데이터 시각화<br>- Chart.js 통합<br>- 재무 데이터 차트 | 차트 컴포넌트 |
| Day 20-21 | 인증 시스템<br>- 로그인 페이지<br>- JWT 토큰 관리 | 인증 시스템 |

#### Week 4: 최적화 및 배포
| 일차 | 작업 내용 | 산출물 |
|------|-----------|---------|
| Day 22-23 | 성능 최적화<br>- 쿼리 최적화<br>- 동시성 처리 | 성능 개선 보고서 |
| Day 24-25 | 배포 준비<br>- 프로덕션 설정<br>- 배포 스크립트 | 배포 가이드 |
| Day 26-28 | 문서화<br>- 사용자 매뉴얼<br>- API 문서<br>- 운영 가이드 | 문서 세트 |

### 4.2 MVP 범위 (2주차 완료 목표)

#### 포함 기능
- ✅ 기본 채팅 인터페이스 (터미널/간단한 웹)
- ✅ 재무제표 PDF 검색 및 분석
- ✅ 뉴스 메타데이터 검색
- ✅ Claude API 연동
- ✅ 기본 캐싱

#### 제외 기능
- ❌ 고급 UI/UX
- ❌ 사용자 인증
- ❌ 차트/시각화
- ❌ 두레이 연동

## 5. 비용 관리

### 5.1 예상 사용량 계산
```
일일 예상 질문 수: 50개
평균 토큰/질문:
- 입력: 2,000 토큰 (컨텍스트 포함)
- 출력: 500 토큰

월간 토큰 사용량:
50 질문/일 × 30일 × 2,500 토큰 = 3,750,000 토큰

캐싱 적용 시 (50% 절감):
실제 API 호출: 1,875,000 토큰
```

### 5.2 API 비용 최적화 전략

#### 라우팅 로직
```python
def select_llm_model(question_type, complexity):
    if question_type == "simple_lookup":
        return "claude-3-haiku"  # 저렴
    elif complexity > 0.7:
        return "claude-3-opus"   # 고급 분석
    else:
        return "claude-3-sonnet" # 중간
```

#### 예상 월 비용 분배
- Claude Opus (30%): 6만원
- Claude Sonnet (50%): 3만원  
- Claude Haiku (20%): 1만원
- **총 예상: 10만원/월**

### 5.3 비용 모니터링
```python
# 일일 비용 한도 설정
DAILY_COST_LIMIT = 3500  # 원
current_cost = await redis.get("daily_api_cost")
if current_cost > DAILY_COST_LIMIT:
    return "일일 API 한도 초과. 내일 다시 시도해주세요."
```

## 6. 리스크 관리

### 6.1 기술적 리스크

| 리스크 | 영향도 | 발생확률 | 대응 방안 |
|--------|--------|----------|-----------|
| Claude API 장애 | 높음 | 낮음 | Gemini/GPT 폴백 구현 |
| 대용량 PDF 처리 실패 | 중간 | 중간 | 페이지 분할 처리 |
| 응답 시간 초과 | 중간 | 중간 | 프로그레시브 로딩 |
| 벡터 DB 성능 저하 | 낮음 | 낮음 | 인덱스 최적화 |

### 6.2 프로젝트 리스크

| 리스크 | 영향도 | 발생확률 | 대응 방안 |
|--------|--------|----------|-----------|
| 1인 개발 일정 지연 | 높음 | 중간 | MVP 범위 축소 |
| 요구사항 변경 | 중간 | 높음 | 애자일 접근, 주간 리뷰 |
| 서버 리소스 부족 | 중간 | 낮음 | 클라우드 이전 검토 |

## 7. 향후 확장 계획

### 7.1 Phase 2 (2개월 후)
- 두레이 메신저 통합
- 고급 분석 기능 (트렌드, 비교)
- 멀티 언어 지원 (영문 문서)

### 7.2 Phase 3 (6개월 후)
- KIIPS ERP 연동
- 자동 리포트 생성
- AI 기반 투자 인사이트 제공

### 7.3 확장성 고려사항
```python
# 메시징 인터페이스 추상화
class MessageInterface(ABC):
    @abstractmethod
    async def send_message(self, message: str) -> str:
        pass

class WebInterface(MessageInterface):
    # 현재 구현

class DoorayInterface(MessageInterface):
    # 향후 구현

class KakaoWorkInterface(MessageInterface):
    # 향후 구현
```

## 8. 성공 기준

### 8.1 단기 (1개월)
- [ ] 5명 이상의 활성 사용자
- [ ] 일일 50개 이상의 질문 처리
- [ ] 평균 만족도 4.0/5.0 이상

### 8.2 중기 (3개월)
- [ ] 전 직원 사용
- [ ] 월 API 비용 10만원 이내 유지
- [ ] 두레이 통합 완료

### 8.3 장기 (6개월)
- [ ] 250개 기업 커버리지
- [ ] 자동화된 인사이트 제공
- [ ] ROI 증명 (시간 절감 측정)

---

## 부록 A: 주요 기술 결정 사항

### A.1 Claude 선택 이유
- PDF 네이티브 지원
- 한국어 성능 우수
- 컨텍스트 윈도우 크기 (200K)
- 비용 대비 성능

### A.2 ChromaDB 선택 이유
- 설치 및 사용 간편
- 로컬 실행 가능
- 한국어 임베딩 지원
- 충분한 성능

### A.3 FastAPI 선택 이유
- 빠른 개발 속도
- 자동 API 문서화
- 비동기 지원
- Python 생태계 활용

---

**문서 끝**
</file>

<file path="vooster-docs/step-by-step.md">
## Core Directive
You are a senior software engineer AI assistant. For EVERY task request, you MUST follow the three-phase process below in exact order. Each phase must be completed with expert-level precision and detail.

## Guiding Principles
- **Minimalistic Approach**: Implement high-quality, clean solutions while avoiding unnecessary complexity
- **Expert-Level Standards**: Every output must meet professional software engineering standards
- **Concrete Results**: Provide specific, actionable details at each step

---

## Phase 1: Codebase Exploration & Analysis
**REQUIRED ACTIONS:**
1. **Systematic File Discovery**
   - List ALL potentially relevant files, directories, and modules
   - Search for related keywords, functions, classes, and patterns
   - Examine each identified file thoroughly

2. **Convention & Style Analysis**
   - Document coding conventions (naming, formatting, architecture patterns)
   - Identify existing code style guidelines
   - Note framework/library usage patterns
   - Catalog error handling approaches

**OUTPUT FORMAT:**
```
### Codebase Analysis Results
**Relevant Files Found:**
- [file_path]: [brief description of relevance]

**Code Conventions Identified:**
- Naming: [convention details]
- Architecture: [pattern details]
- Styling: [format details]

**Key Dependencies & Patterns:**
- [library/framework]: [usage pattern]
```

---

## Phase 2: Implementation Planning
**REQUIRED ACTIONS:**
Based on Phase 1 findings, create a detailed implementation roadmap.

**OUTPUT FORMAT:**
```markdown
## Implementation Plan

### Module: [Module Name]
**Summary:** [1-2 sentence description of what needs to be implemented]

**Tasks:**
- [ ] [Specific implementation task]
- [ ] [Specific implementation task]

**Acceptance Criteria:**
- [ ] [Measurable success criterion]
- [ ] [Measurable success criterion]
- [ ] [Performance/quality requirement]

### Module: [Next Module Name]
[Repeat structure above]
```

---

## Phase 3: Implementation Execution
**REQUIRED ACTIONS:**
1. Implement each module following the plan from Phase 2
2. Verify ALL acceptance criteria are met before proceeding
3. Ensure code adheres to conventions identified in Phase 1

**QUALITY GATES:**
- [ ] All acceptance criteria validated
- [ ] Code follows established conventions
- [ ] Minimalistic approach maintained
- [ ] Expert-level implementation standards met

---

## Success Validation
Before completing any task, confirm:
- ✅ All three phases completed sequentially
- ✅ Each phase output meets specified format requirements
- ✅ Implementation satisfies all acceptance criteria
- ✅ Code quality meets professional standards

## Response Structure
Always structure your response as:
1. **Phase 1 Results**: [Codebase analysis findings]
2. **Phase 2 Plan**: [Implementation roadmap]  
3. **Phase 3 Implementation**: [Actual code with validation]
</file>

<file path=".env.example">
# Database Configuration
DATABASE_URL=postgresql+asyncpg://portfolio_user:portfolio_pass@localhost:5432/portfolio_qa_db

# Redis Configuration
REDIS_URL=redis://localhost:6379

# ChromaDB Configuration
CHROMADB_URL=http://localhost:8000

# Claude API Configuration
CLAUDE_API_KEY=your_claude_api_key_here

# Application Settings
APP_NAME="Investment Portfolio Q&A Chatbot"
APP_VERSION="0.1.0"
DEBUG=True
ENVIRONMENT=development

# Security
SECRET_KEY=your-secret-key-here-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# API Rate Limiting
DAILY_COST_LIMIT=3500  # KRW

# File Storage
DATA_PATH=/data
FINANCIAL_DOCS_PATH=/data/financial_docs
CACHE_PATH=/data/cache

# Logging
LOG_LEVEL=INFO
</file>

<file path=".gitignore">
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
.python-version

# pipenv
Pipfile.lock

# poetry
poetry.lock

# PEP 582
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# IDE
.idea/
.vscode/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db

# Project specific
# Data directories (exclude actual data but keep structure)
/data/financial_docs/*
!/data/financial_docs/.gitkeep
/data/news_attachments/*
!/data/news_attachments/.gitkeep
/data/cache/*
!/data/cache/.gitkeep
!/data/README.md

# Keep sample data structure
!/data/samples/

# Database files
*.pdf
*.csv
*.xlsx
*.xls
chromadb_data/
postgres_data/
redis_data/

# Alembic versions (keep directory structure)
alembic/versions/*.py
!alembic/versions/.gitkeep

# Logs
logs/
*.log

# Temporary files
*.tmp
*.temp
.temp/

# Node modules (for frontend)
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Frontend build
frontend/dist/
frontend/build/

# Vooster
.vooster/
</file>

<file path="alembic.ini">
# A generic, single database configuration.

[alembic]
# path to migration scripts.
# this is typically a path given in POSIX (e.g. forward slashes)
# format, relative to the token %(here)s which refers to the location of this
# ini file
script_location = %(here)s/alembic

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.  for multiple paths, the path separator
# is defined by "path_separator" below.
prepend_sys_path = .


# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library and tzdata library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to <script_location>/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "path_separator"
# below.
# version_locations = %(here)s/bar:%(here)s/bat:%(here)s/alembic/versions

# path_separator; This indicates what character is used to split lists of file
# paths, including version_locations and prepend_sys_path within configparser
# files such as alembic.ini.
# The default rendered in new alembic.ini files is "os", which uses os.pathsep
# to provide os-dependent path splitting.
#
# Note that in order to support legacy alembic.ini files, this default does NOT
# take place if path_separator is not present in alembic.ini.  If this
# option is omitted entirely, fallback logic is as follows:
#
# 1. Parsing of the version_locations option falls back to using the legacy
#    "version_path_separator" key, which if absent then falls back to the legacy
#    behavior of splitting on spaces and/or commas.
# 2. Parsing of the prepend_sys_path option falls back to the legacy
#    behavior of splitting on spaces, commas, or colons.
#
# Valid values for path_separator are:
#
# path_separator = :
# path_separator = ;
# path_separator = space
# path_separator = newline
#
# Use os.pathsep. Default configuration used for new projects.
path_separator = os

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

# database URL.  This is consumed by the user-maintained env.py script only.
# other means of configuring database URLs may be customized within the env.py
# file.
sqlalchemy.url = postgresql://postgres:postgres@localhost:5432/portfolio_qa


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the module runner, against the "ruff" module
# hooks = ruff
# ruff.type = module
# ruff.module = ruff
# ruff.options = check --fix REVISION_SCRIPT_FILENAME

# Alternatively, use the exec runner to execute a binary found on your PATH
# hooks = ruff
# ruff.type = exec
# ruff.executable = ruff
# ruff.options = check --fix REVISION_SCRIPT_FILENAME

# Logging configuration.  This is also consumed by the user-maintained
# env.py script only.
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
</file>

<file path="BACKEND_FRONTEND_DEBUG_SUMMARY.md">
# Backend-Frontend Connection Debug Summary

## Issues Found and Fixed

### 1. **Claude API Credit Issue**
- **Problem**: The Claude API key provided doesn't have sufficient credits
- **Error**: `Your credit balance is too low to access the Anthropic API`
- **Solution**: Added `CLAUDE_TEST_MODE=true` to `.env` file to run in test mode

### 2. **Environment Variable Loading**
- **Problem**: Backend wasn't loading environment variables from `.env` file
- **Solution**: Updated `start_backend_8081.sh` to properly source the `.env` file:
```bash
if [ -f .env ]; then
    set -a
    source .env
    set +a
fi
```

### 3. **Missing Configuration Field**
- **Problem**: `CLAUDE_TEST_MODE` wasn't defined in the Settings class
- **Solution**: Added `CLAUDE_TEST_MODE: Optional[str] = None` to `app/core/config.py`

### 4. **API Endpoint Trailing Slash**
- **Problem**: FastAPI redirects `/api/chat` to `/api/chat/`
- **Solution**: Updated frontend to use `/chat/` with trailing slash

### 5. **Error Handling in Frontend**
- **Problem**: Generic error messages weren't helpful for debugging
- **Solution**: Enhanced error interceptor in `frontend/src/services/api.ts` to provide better error messages

## Current Status

✅ **Backend**: Running on `http://0.0.0.0:8081` (accessible from all interfaces)
✅ **Frontend**: Running on `http://localhost:4001`
✅ **CORS**: Properly configured to allow frontend origin
✅ **API Calls**: Working in test mode

## Testing Commands

### Test Backend Health
```bash
curl http://127.0.0.1:8081/health
```

### Test Chat Endpoint
```bash
curl -X POST http://127.0.0.1:8081/api/chat/ \
  -H "Content-Type: application/json" \
  -H "Origin: http://localhost:4001" \
  -d '{"question": "마인이스의 2024년 매출액은?"}'
```

### Test CORS Preflight
```bash
curl -X OPTIONS http://127.0.0.1:8081/api/chat/ \
  -H "Origin: http://localhost:4001" \
  -H "Access-Control-Request-Method: POST" \
  -H "Access-Control-Request-Headers: content-type"
```

## To Enable Real Claude API

1. Ensure you have sufficient credits in your Claude API account
2. Remove or set `CLAUDE_TEST_MODE=false` in `.env`
3. Restart the backend

## Updated Files

1. `/Users/mnemosyn1154/QnA_Agent/.env` - Added CLAUDE_TEST_MODE
2. `/Users/mnemosyn1154/QnA_Agent/app/core/config.py` - Added CLAUDE_TEST_MODE field
3. `/Users/mnemosyn1154/QnA_Agent/app/services/claude_service.py` - Improved API key loading
4. `/Users/mnemosyn1154/QnA_Agent/start_backend_8081.sh` - Fixed env loading
5. `/Users/mnemosyn1154/QnA_Agent/frontend/src/services/api.ts` - Added trailing slash and better error handling
</file>

<file path="CLAUDE.md">
## Gemini CLI 연동 가이드

### 목적
사용자가 「Gemini와 상의하면서 진행해줘」 (또는 유사한 표현)라고 지시할 경우, Claude는 이후 작업을 Gemini CLI와 협력하여 진행한다.
Gemini로부터 받은 응답은 그대로 보여주고, Claude의 해설이나 통합 설명을 덧붙여 두 에이전트의 지식을 결합한다.

### 트리거
- 정규표현식: `/Gem.*상의하면서/`
- 예시:
  - 「Gem과 상의하면서 진행해줘」
  - 「이건 Gemini랑 이야기하면서 하자」

### Gemini CLI 사용법
```bash
# 기본 사용법
gemini -p "프롬프트 내용"

# 파일을 컨텍스트로 제공
gemini -p "프롬프트 내용" < input_file.md

# 여러 줄 프롬프트 (heredoc 사용)
export PROMPT="여러 줄의
프롬프트 내용"
gemini <<EOF
$PROMPT
EOF

# 주요 옵션
# -m, —model: 모델 선택 (기본: gemini-2.5-pro)
# -p, —prompt: 프롬프트 텍스트
# -d, —debug: 디버그 모드
# -y, —yolo: 자동 승인 모드
```

# Gemini CLI Commands (Updated 2025)

## Core Commands

### `/permissions`
Display and manage permission settings for Gemini CLI. Shows current tool permissions and authentication status.

### `/status` 
Check the current status of Gemini CLI including:
- Connection status to Gemini model
- Authentication method in use
- Rate limit information (60 requests/minute, 1000/day for free tier)
- Active MCP servers

### `/memory`
Manage the AI's instructional context from GEMINI.md files:
- `/memory` - Display current memory context
- `/memory add <text>` - Add text to AI's memory

### `/mcp`
Model Context Protocol server management:
- `/mcp` - List configured MCP servers and connection status
- `/mcp show` - Show detailed descriptions for servers and tools
- `/mcp hide` - Hide tool descriptions, show only names

### `/auth`
Switch between authentication methods:
- Google account login (free tier)
- API key authentication
- Vertex AI authentication

### `/stats`
Display usage statistics:
- Request count for current session
- Daily/minute rate limit usage
- Model being used (gemini-2.5-pro/flash)

### `/help`
Display help information about Gemini CLI commands and features

## Shell Integration

### `!` prefix
Execute shell commands directly:
- `!ls -la` - List files
- `!git status` - Check git status
- Commands run with user's shell permissions

## File Operations

### `@` symbol
Reference files in prompts:
- `@file.txt` - Include file content in prompt
- Supports multiple files with `read_many_files` tool

## Authentication Notes

1. **Free Tier (Google Login)**
   - 60 requests per minute
   - 1,000 requests per day
   - May switch to gemini-2.5-flash during high load

2. **API Key**
   - Higher rate limits available
   - Configure in settings

3. **Vertex AI**
   - Enterprise authentication option
   - Custom quotas

## Security Configuration

- `excludeTools`: String matching for command restrictions (can be bypassed)
- `coreTools`: Explicitly allowed commands (recommended)
- `allowedMcpServerNames`: Restrict available MCP servers
- Tool usage requires user permission before execution

<vooster-docs>
- @vooster-docs/prd.md
- @vooster-docs/architecture.md
- @vooster-docs/guideline.md
- @vooster-docs/step-by-step.md
- @vooster-docs/clean-code.md
- @vooster-docs/git-commit-message.md
</vooster-docs>
</file>

<file path="docker-compose.yml">
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: portfolio_qa_postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: portfolio_user
      POSTGRES_PASSWORD: portfolio_pass
      POSTGRES_DB: portfolio_qa_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U portfolio_user -d portfolio_qa_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: portfolio_qa_redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  chromadb:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: portfolio_qa_chromadb
    restart: unless-stopped
    volumes:
      - chromadb_data:/chroma/chroma
    ports:
      - "8000:8000"
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma/chroma
      - ANONYMIZED_TELEMETRY=FALSE

  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: portfolio_qa_app
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      chromadb:
        condition: service_started
    environment:
      - DATABASE_URL=postgresql+asyncpg://portfolio_user:portfolio_pass@postgres:5432/portfolio_qa_db
      - REDIS_URL=redis://redis:6379
      - CHROMADB_URL=http://chromadb:8000
      - CLAUDE_API_KEY=${CLAUDE_API_KEY}
    volumes:
      - ./app:/app
      - ./data:/data
    ports:
      - "8080:8080"
    command: uvicorn app.main:app --host 0.0.0.0 --port 8080 --reload

  nginx:
    image: nginx:alpine
    container_name: portfolio_qa_nginx
    restart: unless-stopped
    depends_on:
      - app
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
    ports:
      - "80:80"
      - "443:443"

volumes:
  postgres_data:
  redis_data:
  chromadb_data:
</file>

<file path="Dockerfile">
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first to leverage Docker cache
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY ./app /app

# Create data directory
RUN mkdir -p /data/financial_docs /data/cache/embeddings

# Run the application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
</file>

<file path="README.md">
# 투자 포트폴리오 Q&A 챗봇

AI 기반 투자 포트폴리오 Q&A 시스템으로, 투자팀이 포트폴리오 기업의 재무 정보와 뉴스를 실시간으로 조회하고 분석할 수 있는 대화형 챗봇입니다.

## 주요 기능

- 📊 재무제표 PDF 문서 분석 및 검색
- 📰 기업 관련 뉴스 검색 및 요약
- 💬 자연어 기반 질의응답 시스템
- 🚀 Claude AI를 활용한 지능형 응답 생성
- 📈 벡터 데이터베이스를 활용한 의미 기반 검색

## 기술 스택

### Backend
- **Framework**: FastAPI 0.110
- **Language**: Python 3.11
- **Database**: PostgreSQL 15
- **Cache**: Redis 7
- **Vector DB**: ChromaDB
- **AI/LLM**: Claude 3 (Opus/Sonnet/Haiku)

### Infrastructure
- **Container**: Docker & Docker Compose
- **Web Server**: Nginx
- **Process Manager**: Gunicorn

## 시작하기

### 사전 요구사항

- Docker & Docker Compose
- Claude API Key

### 설치 및 실행

1. 저장소 클론
```bash
git clone <repository-url>
cd QnA_Agent
```

2. 환경 변수 설정
```bash
cp .env.example .env
# .env 파일을 열어 CLAUDE_API_KEY 설정
```

3. Docker 컨테이너 실행
```bash
docker-compose up -d
```

4. API 문서 확인
- Swagger UI: http://localhost/docs
- ReDoc: http://localhost/redoc

## 프로젝트 구조

```
QnA_Agent/
├── app/                    # FastAPI 애플리케이션
│   ├── api/               # API 엔드포인트
│   ├── core/              # 핵심 설정 및 유틸리티
│   ├── crud/              # 데이터베이스 CRUD 작업
│   ├── models/            # SQLAlchemy 모델
│   ├── schemas/           # Pydantic 스키마
│   └── services/          # 비즈니스 로직
├── docker-compose.yml     # Docker 구성
├── Dockerfile            # 애플리케이션 Docker 이미지
├── requirements.txt      # Python 의존성
└── init-db/             # PostgreSQL 초기화 스크립트
```

## API 엔드포인트

### 채팅
- `POST /api/chat` - 질문에 대한 AI 응답 생성
- `GET /api/chat/history` - 대화 기록 조회

### 문서
- `GET /api/documents/search` - 재무 문서 검색
- `GET /api/documents/{id}` - 특정 문서 조회
- `POST /api/documents/index` - 문서 인덱싱

### 뉴스
- `GET /api/news/search` - 뉴스 검색
- `GET /api/news/{id}` - 특정 뉴스 조회
- `POST /api/news/index` - 뉴스 인덱싱

### 헬스체크
- `GET /health` - 기본 헬스체크
- `GET /health/detailed` - 상세 헬스체크

## 개발 가이드

### 로컬 개발 환경 설정

1. Python 가상환경 생성
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

2. 의존성 설치
```bash
pip install -r requirements.txt
```

3. 개발 서버 실행
```bash
uvicorn app.main:app --reload --port 8080
```

### 코드 스타일

- Python: PEP 8 준수
- 타입 힌트 사용 필수
- Docstring 작성 (Google 스타일)

## 라이센스

이 프로젝트는 비공개 소프트웨어입니다.

## 문의

프로젝트 관련 문의사항은 투자팀으로 연락주세요.
</file>

<file path="requirements.txt">
# FastAPI and dependencies
fastapi==0.110.0
uvicorn[standard]==0.27.0
python-multipart==0.0.9

# Database
sqlalchemy==2.0.25
asyncpg==0.29.0
alembic==1.13.1
psycopg2-binary==2.9.9

# Redis
redis==5.0.1
aioredis==2.0.1

# Vector Database
chromadb==0.4.22

# AI/ML
anthropic==0.18.1
sentence-transformers==2.3.1
langchain==0.1.6
langchain-community==0.0.16

# Data Processing
pandas==2.2.0
numpy==1.26.3
PyPDF2==3.0.1
pdfplumber==0.10.3
PyMuPDF==1.23.8
pdf2image==1.16.3
Pillow==10.1.0
pytesseract==0.3.10

# API & Validation
pydantic==2.5.3
pydantic-settings==2.1.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4

# Utilities
python-dotenv==1.0.0
httpx==0.26.0
aiofiles==23.2.1

# Logging & Monitoring
loguru==0.7.2

# Testing
pytest==7.4.4
pytest-asyncio==0.23.3
pytest-cov==4.1.0

# Development
black==24.1.1
isort==5.13.2
flake8==7.0.0
mypy==1.8.0
</file>

<file path="run_backend.py">
#!/usr/bin/env python3
"""
Run the FastAPI backend server
"""

import uvicorn

if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8081,
        reload=True
    )
</file>

<file path="start_backend_8081.sh">
#!/bin/bash
cd /Users/mnemosyn1154/QnA_Agent
source venv/bin/activate

# Load environment variables from .env file
if [ -f .env ]; then
    set -a
    source .env
    set +a
fi

python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8081
</file>

<file path="start_backend.sh">
#!/bin/bash
source venv/bin/activate
uvicorn app.main:app --reload --port 8080
</file>

<file path="test_backend_connection.py">
#!/usr/bin/env python3
"""Test backend connection and diagnose issues"""

import requests
import json
import sys
from pathlib import Path

# Test configurations
BASE_URL = "http://127.0.0.1:8081"
FRONTEND_ORIGIN = "http://localhost:4001"

def test_health():
    """Test health endpoint"""
    print("1. Testing health endpoint...")
    try:
        response = requests.get(f"{BASE_URL}/health")
        print(f"   Status: {response.status_code}")
        print(f"   Response: {response.json()}")
        return response.status_code == 200
    except Exception as e:
        print(f"   Error: {e}")
        return False

def test_cors_preflight():
    """Test CORS preflight request"""
    print("\n2. Testing CORS preflight...")
    try:
        response = requests.options(
            f"{BASE_URL}/api/chat/",
            headers={
                "Origin": FRONTEND_ORIGIN,
                "Access-Control-Request-Method": "POST",
                "Access-Control-Request-Headers": "content-type"
            }
        )
        print(f"   Status: {response.status_code}")
        print(f"   CORS Headers:")
        for header in ["Access-Control-Allow-Origin", "Access-Control-Allow-Methods", 
                      "Access-Control-Allow-Headers", "Access-Control-Allow-Credentials"]:
            value = response.headers.get(header, "Not present")
            print(f"     {header}: {value}")
        return response.status_code == 200
    except Exception as e:
        print(f"   Error: {e}")
        return False

def test_chat_endpoint():
    """Test chat endpoint with actual request"""
    print("\n3. Testing chat endpoint...")
    
    # Test with test mode first
    import os
    os.environ["CLAUDE_TEST_MODE"] = "true"
    
    try:
        response = requests.post(
            f"{BASE_URL}/api/chat/",
            json={"question": "마인이스의 2024년 매출액은 얼마입니까?"},
            headers={
                "Content-Type": "application/json",
                "Origin": FRONTEND_ORIGIN
            }
        )
        print(f"   Status: {response.status_code}")
        if response.status_code == 200:
            print(f"   Response: {json.dumps(response.json(), indent=2, ensure_ascii=False)}")
        else:
            print(f"   Error Response: {response.text}")
        return response.status_code == 200
    except Exception as e:
        print(f"   Error: {e}")
        return False

def test_from_frontend_perspective():
    """Test exactly how frontend would call the API"""
    print("\n4. Testing from frontend perspective...")
    try:
        # Simulate axios request
        response = requests.post(
            f"{BASE_URL}/api/chat",  # Without trailing slash first
            json={"question": "테스트 질문입니다"},
            headers={
                "Content-Type": "application/json",
                "Origin": FRONTEND_ORIGIN,
                "Referer": f"{FRONTEND_ORIGIN}/chat",
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"
            },
            allow_redirects=True  # Follow redirects automatically
        )
        print(f"   Status: {response.status_code}")
        print(f"   Final URL: {response.url}")
        if response.status_code == 200:
            print(f"   Response: {json.dumps(response.json(), indent=2, ensure_ascii=False)}")
        else:
            print(f"   Error Response: {response.text}")
        return response.status_code == 200
    except Exception as e:
        print(f"   Error: {e}")
        return False

def check_file_system():
    """Check if required files exist"""
    print("\n5. Checking file system...")
    data_path = Path("data/financial_docs")
    if data_path.exists():
        print(f"   Data directory exists: {data_path}")
        pdf_files = list(data_path.glob("*.pdf"))
        print(f"   PDF files found: {len(pdf_files)}")
        for pdf in pdf_files[:3]:  # Show first 3
            print(f"     - {pdf.name}")
    else:
        print(f"   Data directory not found: {data_path}")
    
    return data_path.exists()

def main():
    """Run all tests"""
    print("=== Backend Connection Diagnostics ===\n")
    
    results = {
        "Health Check": test_health(),
        "CORS Preflight": test_cors_preflight(),
        "Chat Endpoint": test_chat_endpoint(),
        "Frontend Simulation": test_from_frontend_perspective(),
        "File System": check_file_system()
    }
    
    print("\n=== Summary ===")
    for test, passed in results.items():
        status = "✓ PASSED" if passed else "✗ FAILED"
        print(f"{test}: {status}")
    
    if not all(results.values()):
        print("\n⚠️  Some tests failed. Please check the output above for details.")
        sys.exit(1)
    else:
        print("\n✅ All tests passed!")

if __name__ == "__main__":
    main()
</file>

<file path="test_chat_service.py">
#!/usr/bin/env python3
"""Test chat service directly to identify issues"""

import os
import asyncio
from app.db.session import SessionLocal
from app.services.chat_service import ChatService
from loguru import logger

# Enable test mode
os.environ["CLAUDE_TEST_MODE"] = "true"

async def test_chat_service():
    """Test the chat service directly"""
    db = SessionLocal()
    try:
        # Create chat service
        chat_service = ChatService(db=db)
        
        # Test questions
        test_questions = [
            "마인이스의 2024년 매출액은 얼마입니까?",
            "우나스텔라의 최근 실적은 어떻습니까?",
            "설로인의 사업 현황을 알려주세요"
        ]
        
        for question in test_questions:
            print(f"\n{'='*50}")
            print(f"Testing question: {question}")
            print('='*50)
            
            try:
                response = await chat_service.process_query(
                    question=question,
                    context=None
                )
                
                print(f"✓ Success!")
                print(f"Answer: {response.answer[:200]}...")
                print(f"Sources: {response.sources}")
                print(f"Processing time: {response.processing_time:.2f}s")
                
            except Exception as e:
                print(f"✗ Error: {type(e).__name__}: {str(e)}")
                import traceback
                traceback.print_exc()
    
    finally:
        db.close()

def test_document_service():
    """Test document service separately"""
    from app.services.document_service import DocumentService
    
    db = SessionLocal()
    try:
        doc_service = DocumentService(db)
        
        # Test company extraction
        test_questions = [
            "마인이스의 2024년 매출액은?",
            "우나스텔라 최근 실적",
            "설로인 사업 현황"
        ]
        
        print("\n=== Testing Document Service ===")
        for question in test_questions:
            company = doc_service.extract_company_from_question(question)
            year = doc_service.extract_year_from_question(question)
            print(f"Question: {question}")
            print(f"  - Extracted company: {company}")
            print(f"  - Extracted year: {year}")
            
            if company:
                document, pdf_content = doc_service.get_document_for_question(question)
                if document:
                    print(f"  - Found document: {document.file_path}")
                    print(f"  - PDF content size: {len(pdf_content) if pdf_content else 0} bytes")
                else:
                    print("  - No document found")
            print()
    
    finally:
        db.close()

def test_claude_service():
    """Test Claude service initialization"""
    print("\n=== Testing Claude Service ===")
    from app.services.claude_service import ClaudeService
    
    try:
        claude = ClaudeService()
        print(f"✓ Claude service initialized successfully")
        print(f"  - Test mode: {claude.test_mode}")
        print(f"  - API key present: {bool(claude.api_key)}")
        print(f"  - Client initialized: {claude.client is not None}")
    except Exception as e:
        print(f"✗ Failed to initialize Claude service: {e}")
        import traceback
        traceback.print_exc()

async def main():
    """Run all tests"""
    # Test individual components
    test_document_service()
    test_claude_service()
    
    # Test full chat service
    await test_chat_service()

if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="test_claude_direct.py">
#!/usr/bin/env python3
"""Test Claude API directly"""

import os
from anthropic import Anthropic
from dotenv import load_dotenv

# Load environment
load_dotenv()

# Get API key
api_key = os.getenv("CLAUDE_API_KEY")
if not api_key:
    from app.core.config import settings
    api_key = settings.CLAUDE_API_KEY

print(f"API Key present: {bool(api_key)}")
print(f"API Key starts with: {api_key[:10] if api_key else 'None'}")

# Test simple message
try:
    client = Anthropic(api_key=api_key)
    
    message = client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=100,
        messages=[
            {
                "role": "user",
                "content": "Hello, can you respond with a simple test message?"
            }
        ]
    )
    
    print("\n✓ Claude API call successful!")
    print(f"Response: {message.content[0].text}")
    
except Exception as e:
    print(f"\n✗ Claude API call failed: {type(e).__name__}: {e}")
    import traceback
    traceback.print_exc()
</file>

<file path="test_env_loading.py">
#!/usr/bin/env python3
"""Test environment variable loading"""

import os
import sys
from pathlib import Path

# Load .env file
from dotenv import load_dotenv
load_dotenv()

print("=== Environment Variable Test ===\n")

# Check critical environment variables
env_vars = [
    "CLAUDE_API_KEY",
    "DATABASE_URL",
    "REDIS_URL",
    "CHROMADB_URL",
    "SECRET_KEY"
]

for var in env_vars:
    value = os.getenv(var)
    if value:
        # Show only first 10 chars for sensitive data
        display_value = value[:10] + "..." if len(value) > 10 else value
        print(f"✓ {var}: {display_value}")
    else:
        print(f"✗ {var}: NOT SET")

# Test loading through pydantic settings
print("\n=== Testing Pydantic Settings ===")
try:
    from app.core.config import settings
    print(f"✓ Settings loaded successfully")
    print(f"  - APP_NAME: {settings.APP_NAME}")
    print(f"  - CLAUDE_API_KEY present: {bool(settings.CLAUDE_API_KEY)}")
    print(f"  - DEBUG: {settings.DEBUG}")
except Exception as e:
    print(f"✗ Failed to load settings: {e}")

# Test Claude service initialization
print("\n=== Testing Claude Service ===")
try:
    from app.services.claude_service import ClaudeService
    claude = ClaudeService()
    print(f"✓ Claude service initialized")
    print(f"  - Test mode: {claude.test_mode}")
    print(f"  - API key present: {bool(claude.api_key)}")
    print(f"  - Client initialized: {claude.client is not None}")
except Exception as e:
    print(f"✗ Failed to initialize Claude service: {e}")
    import traceback
    traceback.print_exc()

print("\n=== Test Complete ===")
</file>

<file path="test_fastapi_direct.py">
#!/usr/bin/env python3
"""Test FastAPI endpoint directly"""

import os
os.environ["CLAUDE_TEST_MODE"] = "true"

from fastapi.testclient import TestClient
from app.main import app
import json

# Create test client
client = TestClient(app)

def test_health():
    """Test health endpoint"""
    print("=== Testing Health Endpoint ===")
    response = client.get("/health")
    print(f"Status: {response.status_code}")
    print(f"Response: {response.json()}")
    print()

def test_chat_endpoint():
    """Test chat endpoint"""
    print("=== Testing Chat Endpoint ===")
    
    # Test with trailing slash
    response = client.post(
        "/api/chat/",
        json={"question": "마인이스의 2024년 매출액은?"},
        headers={"Origin": "http://localhost:4001"}
    )
    
    print(f"Status: {response.status_code}")
    if response.status_code == 200:
        print(f"Response: {json.dumps(response.json(), indent=2, ensure_ascii=False)}")
    else:
        print(f"Error: {response.text}")
        # Print full error details
        if response.status_code == 500:
            print("\nDetailed error information:")
            import traceback
            # Try to get exception details from FastAPI
            try:
                detail = response.json()
                print(f"Detail: {detail}")
            except:
                print("Could not parse error detail")
    
    # Also check CORS headers
    print(f"\nCORS Headers:")
    for header in ["Access-Control-Allow-Origin", "Access-Control-Allow-Credentials"]:
        value = response.headers.get(header, "Not present")
        print(f"  {header}: {value}")

def test_cors_preflight():
    """Test CORS preflight"""
    print("\n=== Testing CORS Preflight ===")
    response = client.options(
        "/api/chat/",
        headers={
            "Origin": "http://localhost:4001",
            "Access-Control-Request-Method": "POST",
            "Access-Control-Request-Headers": "content-type"
        }
    )
    
    print(f"Status: {response.status_code}")
    print("CORS Headers:")
    for header in ["Access-Control-Allow-Origin", "Access-Control-Allow-Methods", 
                  "Access-Control-Allow-Headers", "Access-Control-Allow-Credentials"]:
        value = response.headers.get(header, "Not present")
        print(f"  {header}: {value}")

if __name__ == "__main__":
    test_health()
    test_cors_preflight()
    test_chat_endpoint()
</file>

<file path="test_server.py">
#!/usr/bin/env python3
"""
Simple test server for frontend testing
"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

app = FastAPI(title="Portfolio Q&A Test Server", version="0.1.0")

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {"message": "Portfolio Q&A Test Server", "status": "running"}

@app.get("/api/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "Portfolio Q&A Test Server",
        "version": "0.1.0"
    }

@app.get("/api/health/detailed")
async def detailed_health_check():
    return {
        "status": "healthy",
        "service": "Portfolio Q&A Test Server",
        "version": "0.1.0",
        "dependencies": {
            "database": {"status": "healthy"},
            "redis": {"status": "healthy"},
            "vector_db": {"status": "healthy"}
        }
    }

@app.post("/api/chat")
async def chat_endpoint(request: dict):
    question = request.get("question", "")
    return {
        "answer": f"테스트 응답: '{question}'에 대한 답변입니다. 실제 AI는 연결되지 않았습니다.",
        "sources": ["테스트 문서 1", "테스트 문서 2"],
        "processing_time": 1.5
    }

@app.get("/api/documents/search")
async def search_documents(company: str = "마인이스", limit: int = 5):
    return [
        {
            "id": 1,
            "companyName": company,
            "docType": "사업보고서",
            "year": 2024,
            "filePath": f"/test/{company}_2024.pdf",
            "createdAt": "2024-01-01T00:00:00",
            "updatedAt": "2024-01-01T00:00:00"
        }
    ]

@app.get("/api/news/search")
async def search_news(company: str = "마인이스", limit: int = 5):
    return [
        {
            "id": 1,
            "companyName": company,
            "title": f"{company} 테스트 뉴스",
            "content": "테스트 뉴스 내용입니다.",
            "source": "테스트 신문",
            "publishedDate": "2024-01-01T00:00:00",
            "createdAt": "2024-01-01T00:00:00",
            "updatedAt": "2024-01-01T00:00:00"
        }
    ]

if __name__ == "__main__":
    print("🚀 Starting Portfolio Q&A Test Server...")
    print("📍 Frontend: http://localhost:4001")
    print("📍 Backend: http://localhost:8080")
    print("📍 API Docs: http://localhost:8080/docs")
    
    uvicorn.run(app, host="0.0.0.0", port=8080)
</file>

</files>
