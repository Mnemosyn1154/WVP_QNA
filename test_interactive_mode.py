#!/usr/bin/env python3
"""
Test script for interactive Claude mode
"""

import asyncio
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.db.session import SessionLocal
from app.services.interactive_claude_service import InteractiveClaudeService
from loguru import logger


async def test_interactive_mode():
    """Test the interactive mode with various questions"""
    
    # Initialize service
    service = InteractiveClaudeService()
    db = SessionLocal()
    
    try:
        # Test cases
        test_questions = [
            # Simple single company question
            "ë§ˆì¸ì´ìŠ¤ì˜ 2024ë…„ ë§¤ì¶œì€ ì–¼ë§ˆì¸ê°€ìš”?",
            
            # Comparison question that should trigger multiple requests
            "ë§ˆì¸ì´ìŠ¤ì™€ ì„¤ë¡œì¸ì˜ 2024ë…„ ë§¤ì¶œì„ ë¹„êµí•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”.",
            
            # Complex question requiring multiple documents
            "ë§ˆì¸ì´ìŠ¤ì˜ 2023ë…„ê³¼ 2024ë…„ ë§¤ì¶œ ì„±ì¥ë¥ ì„ ê³„ì‚°í•´ì£¼ì„¸ìš”.",
            
            # Question without specifying company
            "2024ë…„ ë§¤ì¶œì´ ê°€ì¥ ë†’ì€ íšŒì‚¬ëŠ” ì–´ë””ì¸ê°€ìš”?"
        ]
        
        for i, question in enumerate(test_questions, 1):
            print(f"\n{'='*60}")
            print(f"Test {i}: {question}")
            print(f"{'='*60}")
            
            try:
                result = await service.interactive_chat(
                    question=question,
                    db=db,
                    max_iterations=5
                )
                
                print(f"\nğŸ“ Answer:")
                print(result["answer"])
                
                print(f"\nğŸ“Š Metadata:")
                print(f"- Model: {result['model_used']}")
                print(f"- Iterations: {result['usage']['iterations']}")
                print(f"- Total tokens: {result['usage']['total_tokens']}")
                print(f"- Documents provided: {result['documents_provided']}")
                print(f"- Processing time: {result['processing_time']:.2f}s")
                
                if result.get("provided_documents"):
                    print(f"\nğŸ“š Documents used:")
                    for doc in result["provided_documents"]:
                        print(f"  - {doc['company']} {doc['year']}ë…„ {doc['type']}")
                
            except Exception as e:
                print(f"âŒ Error: {e}")
                logger.exception("Test failed")
            
            # Wait a bit between tests
            await asyncio.sleep(2)
            
    finally:
        db.close()


async def test_protocol_parsing():
    """Test the protocol parsing functionality"""
    from app.core.llm_protocol import LLMProtocol
    
    protocol = LLMProtocol()
    
    # Test response with document request
    test_response = """
    ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    
    <request_document>
    {
      "type": "financial_report",
      "company_name": "ë§ˆì¸ì´ìŠ¤",
      "year": 2024,
      "doc_type": "ì¬ë¬´ì œí‘œ"
    }
    </request_document>
    
    ë¬¸ì„œë¥¼ í™•ì¸í•œ í›„ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
    """
    
    requests = protocol.parse_response_for_requests(test_response)
    print(f"Found {len(requests)} requests")
    for req in requests:
        print(f"- Type: {req.request_type.value}")
        print(f"  Company: {req.company_name}")
        print(f"  Year: {req.year}")
        print(f"  Doc type: {req.doc_type}")
    
    # Test final answer extraction
    clean_answer = protocol.extract_final_answer(test_response)
    print(f"\nClean answer:\n{clean_answer}")


if __name__ == "__main__":
    print("ğŸ§ª Testing Interactive Claude Mode")
    print("==================================\n")
    
    # Test protocol parsing first
    print("1. Testing Protocol Parsing")
    print("-" * 30)
    asyncio.run(test_protocol_parsing())
    
    print("\n\n2. Testing Interactive Chat")
    print("-" * 30)
    asyncio.run(test_interactive_mode())