#!/usr/bin/env python3
"""
ë¬¸ì„œ íŒŒì¼ ì •ë¦¬ ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸
- ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì˜ ì´ë¦„ì„ ë¶„ì„í•˜ì—¬ ì •ë¦¬
- ë°ì´í„°ë² ì´ìŠ¤ì— ë©”íƒ€ë°ì´í„° ì €ì¥
"""

import os
import sys
import re
import shutil
from pathlib import Path
from datetime import datetime
import hashlib

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent))

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.models.financial_doc import FinancialDoc

# SQLiteë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ì„¤ì •
DATABASE_URL = "sqlite:///./portfolio_qa.db"


class DocumentOrganizer:
    """ë¬¸ì„œ íŒŒì¼ ì •ë¦¬ ë° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.base_path = Path("data/financial_docs")
        self.engine = create_engine(DATABASE_URL)
        self.Session = sessionmaker(bind=self.engine)
        
        # í…Œì´ë¸” ìƒì„± (ì—†ì„ ê²½ìš°)
        from app.models.base import Base
        Base.metadata.create_all(bind=self.engine)
        
        # ë¬¸ì„œ íƒ€ì… ë§¤í•‘
        self.doc_type_patterns = {
            "ì‚¬ì—…ë³´ê³ ì„œ": ["ì‚¬ì—…ë³´ê³ ì„œ", "annual", "ì—°ê°„"],
            "ë¶„ê¸°ë³´ê³ ì„œ": ["ë¶„ê¸°", "quarter", r"\dQ", "1Q", "2Q", "3Q", "4Q"],
            "ë°˜ê¸°ë³´ê³ ì„œ": ["ë°˜ê¸°", "half"],
            "ì¬ë¬´ì œí‘œ": ["ì¬ë¬´ì œí‘œ", "financial", "ê°€ê²°ì‚°"],
        }
        
    def analyze_filename(self, filename):
        """íŒŒì¼ëª… ë¶„ì„í•˜ì—¬ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {
            "doc_type": None,
            "year": None,
            "quarter": None,
            "original_filename": filename
        }
        
        # ì—°ë„ ì¶”ì¶œ (2023, 2024, 23, 24 ë“±)
        year_patterns = [
            r"20(\d{2})",  # 2023, 2024
            r"(\d{2})ë…„",   # 23ë…„, 24ë…„
            r"_(\d{2})\.",  # _23., _24.
            r"(\d{4})\.?(?:12|Q|q)",  # 202312, 2024Q
        ]
        
        for pattern in year_patterns:
            match = re.search(pattern, filename)
            if match:
                year_str = match.group(1)
                if len(year_str) == 2:
                    metadata["year"] = 2000 + int(year_str)
                else:
                    metadata["year"] = int(year_str)
                break
        
        # ë¬¸ì„œ íƒ€ì… ì¶”ì¶œ
        filename_lower = filename.lower()
        for doc_type, patterns in self.doc_type_patterns.items():
            for pattern in patterns:
                if isinstance(pattern, str):
                    if pattern.lower() in filename_lower:
                        metadata["doc_type"] = doc_type
                        break
                else:  # regex pattern
                    if re.search(pattern, filename, re.IGNORECASE):
                        metadata["doc_type"] = doc_type
                        break
            if metadata["doc_type"]:
                break
        
        # ë¶„ê¸° ì¶”ì¶œ
        quarter_match = re.search(r"(\d)[Qq]|Q(\d)|(\d)ë¶„ê¸°", filename)
        if quarter_match:
            quarter_num = quarter_match.group(1) or quarter_match.group(2) or quarter_match.group(3)
            metadata["quarter"] = int(quarter_num)
        
        # 4Qê°€ ìˆìœ¼ë©´ ì‚¬ì—…ë³´ê³ ì„œë¡œ ë¶„ë¥˜
        if "4Q" in filename or "4q" in filename:
            metadata["doc_type"] = "ì‚¬ì—…ë³´ê³ ì„œ"
            metadata["quarter"] = None
        
        return metadata
    
    def generate_new_filename(self, company, metadata):
        """í‘œì¤€í™”ëœ íŒŒì¼ëª… ìƒì„±"""
        year = metadata["year"]
        doc_type = metadata["doc_type"] or "ê¸°íƒ€ë¬¸ì„œ"
        quarter = metadata["quarter"]
        
        if quarter and doc_type != "ì‚¬ì—…ë³´ê³ ì„œ":
            new_name = f"{company}_{year}_Q{quarter}_{doc_type}.pdf"
        else:
            new_name = f"{company}_{year}_{doc_type}.pdf"
        
        return new_name
    
    def calculate_file_hash(self, filepath):
        """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
        hash_md5 = hashlib.md5()
        with open(filepath, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def process_company_documents(self, company_name):
        """íŠ¹ì • íšŒì‚¬ì˜ ë¬¸ì„œë“¤ ì²˜ë¦¬"""
        company_path = self.base_path / company_name
        if not company_path.exists():
            print(f"âš ï¸  {company_name} í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“ {company_name} ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
        processed = 0
        
        session = self.Session()
        
        try:
            # ëª¨ë“  PDF íŒŒì¼ ì°¾ê¸°
            for year_dir in company_path.iterdir():
                if not year_dir.is_dir():
                    continue
                    
                year = year_dir.name
                
                for file_path in year_dir.glob("*.[pP][dD][fF]"):
                    print(f"\n  íŒŒì¼: {file_path.name}")
                    
                    # íŒŒì¼ëª… ë¶„ì„
                    metadata = self.analyze_filename(file_path.name)
                    
                    # ì—°ë„ê°€ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œë˜ì§€ ì•Šìœ¼ë©´ í´ë”ëª… ì‚¬ìš©
                    if not metadata["year"]:
                        try:
                            metadata["year"] = int(year)
                        except ValueError:
                            print(f"    âš ï¸  ì—°ë„ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {year}")
                            continue
                    
                    print(f"    ë¶„ì„ ê²°ê³¼: ì—°ë„={metadata['year']}, "
                          f"íƒ€ì…={metadata['doc_type']}, ë¶„ê¸°={metadata['quarter']}")
                    
                    # ìƒˆ íŒŒì¼ëª… ìƒì„±
                    new_filename = self.generate_new_filename(company_name, metadata)
                    new_path = file_path.parent / new_filename
                    
                    # íŒŒì¼ëª… ë³€ê²½ (í•„ìš”í•œ ê²½ìš°)
                    if file_path.name != new_filename:
                        if new_path.exists():
                            print(f"    âš ï¸  ëŒ€ìƒ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {new_filename}")
                        else:
                            shutil.move(str(file_path), str(new_path))
                            print(f"    âœ… íŒŒì¼ëª… ë³€ê²½: {file_path.name} â†’ {new_filename}")
                            file_path = new_path
                    
                    # DBì— ì €ì¥
                    existing = session.query(FinancialDoc).filter_by(
                        company_name=company_name,
                        year=metadata["year"],
                        doc_type=metadata["doc_type"],
                        quarter=metadata["quarter"]
                    ).first()
                    
                    if existing:
                        print(f"    â„¹ï¸  ì´ë¯¸ DBì— ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                    else:
                        # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
                        file_size = file_path.stat().st_size
                        file_hash = self.calculate_file_hash(file_path)
                        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
                        relative_path = str(file_path).replace(str(Path.cwd()) + "/", "")
                        
                        doc = FinancialDoc(
                            company_name=company_name,
                            doc_type=metadata["doc_type"] or "ê¸°íƒ€ë¬¸ì„œ",
                            year=metadata["year"],
                            quarter=metadata["quarter"],
                            file_path=str(relative_path),
                            file_size=file_size,
                            # file_hash=file_hash  # ëª¨ë¸ì— ì¶”ê°€ í•„ìš”ì‹œ
                        )
                        
                        session.add(doc)
                        print(f"    âœ… DBì— ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    
                    processed += 1
            
            session.commit()
            print(f"\nâœ… {company_name}: {processed}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            session.rollback()
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
        finally:
            session.close()
    
    def process_excel_files(self):
        """ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ (ë³„ë„ í´ë”ë¡œ ì´ë™)"""
        excel_dir = self.base_path.parent / "excel_files"
        excel_dir.mkdir(exist_ok=True)
        
        moved = 0
        for company_path in self.base_path.iterdir():
            if not company_path.is_dir():
                continue
                
            for excel_file in company_path.rglob("*.xlsx"):
                target = excel_dir / company_path.name / excel_file.parent.name / excel_file.name
                target.parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(excel_file), str(target))
                print(f"  ğŸ“Š ì—‘ì…€ íŒŒì¼ ì´ë™: {excel_file} â†’ {target}")
                moved += 1
        
        if moved > 0:
            print(f"\nâœ… {moved}ê°œ ì—‘ì…€ íŒŒì¼ì„ ë³„ë„ í´ë”ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.")
    
    def run(self):
        """ì „ì²´ ë¬¸ì„œ ì •ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸš€ ë¬¸ì„œ ì •ë¦¬ ë° DB ë“±ë¡ ì‹œì‘...\n")
        
        # ì—‘ì…€ íŒŒì¼ ë³„ë„ ì²˜ë¦¬
        self.process_excel_files()
        
        # ê° íšŒì‚¬ë³„ ì²˜ë¦¬
        companies = ["ë§ˆì¸ì´ìŠ¤", "ì„¤ë¡œì¸", "ìš°ë‚˜ìŠ¤í…”ë¼"]
        for company in companies:
            self.process_company_documents(company)
        
        print("\nâœ… ëª¨ë“  ë¬¸ì„œ ì •ë¦¬ ì™„ë£Œ!")
        print("\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. ë¬¸ì„œ ì¸ë±ì‹±: python scripts/index_documents.py")
        print("2. ì„œë²„ ì‹¤í–‰: python test_server.py")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    organizer = DocumentOrganizer()
    organizer.run()


if __name__ == "__main__":
    main()